<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[nginx安装（linux环境）]]></title>
    <url>%2F2020%2F02%2F21%2Fnginx%E5%AE%89%E8%A3%85%EF%BC%88linux%E7%8E%AF%E5%A2%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Nginx 是一款高性能的 Web 和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。它的开发者是俄罗斯工程师：Igor Sysoev。这篇是针对 Linux 操作系统的安装。 在 linux 下安装 nginx 有两种方式：一种是源码编译，一种是yum安装。 一、通过源码编译方式的安装步骤step1: wget下载nginx源码1wget https://nginx.org/download/nginx-1.17.1.tar.gz step2: tar命令解压1tar zxvf nginx-1.17.1.tar.gz step3: 安装gcc编译工具1yum install gcc gcc-c++ step4: 安装其他库跟工具1yum install pure pure-devel openssl openssl-devel zlib zlib-devel step5: 编译源码并安装12cd nginx-1.17.1make &amp;&amp; make install step6: 启动niginx1/usr/local/nginx/sbin/nginx Done！ 但是，我觉得步骤实在太繁琐，个人不喜欢这种方式。 二、通过 yum 安装的步骤 （推荐）这也是官方推荐的安装方式nginx官网文档 step1: 进入 yum repos 配置目录1cd /etc/yum.repos.d step2: 配置 nginx.repo从官网提供的稳定版和最新版的repo信息(如下)复制一下123456789101112131415[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true 然后在ssh终端配置 nginx.repo12vi nginx.repo # 新建 nginx.repo 文件，将官网提供的稳定版和最新版的repo信息粘贴进去:wq # 保存并退出 vi step3: 安装1yum install nginx -y step4: 启动nginx1nginx Done！ 在浏览器输入服务器公网ip，回车，即可看到 nginx 欢迎文字，nginx安装启动成功！ 三、其他命令查看ngix安装路径1whereis nginx 测试nginx1nginx -t 修改nginx.conf配置后，重载nginx1nginx -s reload]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘webpack loader]]></title>
    <url>%2F2020%2F01%2F28%2F%E6%8F%AD%E7%A7%98webpack-loader%2F</url>
    <content type="text"><![CDATA[Loader(加载器) 是 webpack 的核心之一。它用于将不同类型的文件转换为 webpack 可识别的模块。本文将尝试深入探索 webpack 中的 loader，揭秘它的工作原理，以及如何开发一个 loader。 一、Loader 工作原理webpack 只能直接处理 javascript 格式的代码。任何非 js 文件都必须被预先处理转换为 js 代码，才可以参与打包。loader（加载器）就是这样一个代码转换器。它由 webpack 的 loader runner 执行调用，接收原始资源数据作为参数（当多个加载器联合使用时，上一个loader的结果会传入下一个loader），最终输出 javascript 代码（和可选的 source map）给 webpack 做进一步编译。 二、 Loader 执行顺序1. 分类 pre： 前置loader normal： 普通loader inline： 内联loader post： 后置loader 2. 执行优先级 4类 loader 的执行优级为：pre &gt; normal &gt; inline &gt; post 。 相同优先级的 loader 执行顺序为：从右到左，从下到上。 3. 前缀的作用内联 loader 可以通过添加不同前缀，跳过其他类型 loader。 ! 跳过 normal loader。 -! 跳过 pre 和 normal loader。 !! 跳过 pre、 normal 和 post loader。 这些前缀在很多场景下非常有用。 三、如何开发一个loaderloader 是一个导出一个函数的 node 模块。 1. 最简单的 loader当只有一个 loader 应用于资源文件时，它接收源码作为参数，输出转换后的 js 代码。123456// loaders/simple-loader.jsmodule.exports = function loader (source) &#123; console.log('simple-loader is working'); return source;&#125; 这就是一个最简单的 loader 了，这个 loader 啥也没干，就是接收源码，然后原样返回，为了证明这个loader被调用了，我在里面打印了一句话‘simple-loader is working’。 测试这个 loader：需要先配置 loader 路径若是使用 npm 安装的第三方 loader，直接写 loader 的名字就可以了。但是现在用的是自己开发的本地 loader，需要我们手动配置路径，告诉 webpack 这些 loader 在哪里。12345678910111213141516// webpack.config.jsconst path = require('path');module.exports = &#123; entry: &#123;...&#125;, output: &#123;...&#125;, module: &#123; rules: [ &#123; test: /\.js$/, // 直接指明 loader 的绝对路径 use: path.resolve(__dirname, 'loaders/simple-loader') &#125; ] &#125;&#125; 如果觉得这样配置本地 loader 并不优雅，可以在 webpack配置本地loader的四种方法 中挑一个你喜欢的。 执行webpack编译可以看到，控制台输出 ‘simple-loader is working’。说明 loader 成功被调用。 2. 带 pitch 的 loaderpitch 是 loader 上的一个方法，它的作用是阻断 loader 链。 123456789101112// loaders/simple-loader-with-pitch.jsmodule.exports = function (source) &#123; console.log('normal excution'); return source;&#125;// loader上的pitch方法，非必须module.exports.pitch = function() &#123; console.log('pitching graph'); // todo&#125; pitch 方法不是必须的。如果有 pitch，loader 的执行则会分为两个阶段：pitch 阶段 和 normal execution 阶段。webpack 会先从左到右执行 loader 链中的每个 loader 上的 pitch 方法（如果有），然后再从右到左执行 loader 链中的每个 loader 上的普通 loader 方法。 假如配置了如下 loader 链：1use: ['loader1', 'loader2', 'loader3'] 真实的 loader 执行过程是： 在这个过程中如果任何 pitch 有返回值，则 loader 链被阻断。webpack 会跳过后面所有的的 pitch 和 loader，直接进入上一个 loader 的 normal execution。 假设在 loader2 的 pitch 中返回了一个字符串，此时 loader 链发生阻断： 3. 写一个简版的 style-loaderstyle-loader 通常不会独自使用，而是跟 css-loader 连用。css-loader 的返回值是一个 js 模块，大致长这样：123456789// 打印 css-loader 的返回值// Importsvar ___CSS_LOADER_API_IMPORT___ = require("../node_modules/css-loader/dist/runtime/api.js");exports = ___CSS_LOADER_API_IMPORT___(false);// Moduleexports.push([module.id, "\nbody &#123;\n background: yellow;\n&#125;\n", ""]);// Exportsmodule.exports = exports; 这个模块在运行时上下文中执行后返回 css 代码 &quot;\nbody {\n background: yellow;\n}\n&quot;。 style-loader 的作用就是将这段 css 代码转成 style 标签插入到 html 的 head 中。 设计思路 style-loader 最终需返回一个 js 脚本：在脚本中创建一个 style 标签，将 css 代码赋给 style 标签，再将这个 style 标签插入 html 的 head 中。 难点是获取 css 代码，因为 css-loader 的返回值只能在运行时的上下文中执行，而执行 loader 是在编译阶段。换句话说，css-loader 的返回值在 style-loader 里派不上用场。 曲线救国方案：使用获取 css 代码的表达式，在运行时再获取 css (类似 require(&#39;css-loader!index.css&#39;)）。 在处理 css 的 loader 中又去调用 inline loader require css 文件，会产生循环执行 loader 的问题，所以我们需要利用 pitch 方法，让 style-loader 在 pitch 阶段返回脚本，跳过剩下的 loader，同时还需要内联前缀 !! 的加持。 注：pitch 方法有3个参数： remainingRequest：loader链中排在自己后面的 loader 以及资源文件的绝对路径以!作为连接符组成的字符串。 precedingRequest：loader链中排在自己前面的 loader 的绝对路径以!作为连接符组成的字符串。 data：每个 loader 中存放在上下文中的固定字段，可用于 pitch 给 loader 传递数据。 可以利用 remainingRequest 参数获取 loader 链的剩余部分。 实现12345678910111213141516171819202122232425262728// loaders/simple-style-loader.jsconst loaderUtils = require('loader-utils');module.exports = function(source) &#123; // do nothing&#125;module.exports.pitch = function(remainingRequest) &#123; console.log('simple-style-loader is working'); // 在 pitch 阶段返回脚本 return ( ` // 创建 style 标签 let style = document.createElement('style'); /** * 利用 remainingRequest 参数获取 loader 链的剩余部分 * 利用 ‘!!’ 前缀跳过其他 loader * 利用 loaderUtils 的 stringifyRequest 方法将模块的绝对路径转为相对路径 * 将获取 css 的 require 表达式赋给 style 标签 */ style.innerHTML = require($&#123;loaderUtils.stringifyRequest(this, '!!' + remainingRequest)&#125;); // 将 style 标签插入 head document.head.appendChild(style); ` )&#125; 一个简易的 style-loader 就完成了。 试用webpack 配置 123456789101112131415161718192021222324252627// webpack.config.jsconst path = require('path');const HtmlWebpackPlugin = require('html-webpack-plugin');module.exports = &#123; entry: &#123;...&#125;, output: &#123;...&#125;, // 手动配置 loader 路径 resolveLoader: &#123; modules: [path.resolve(__dirname, 'loaders'), 'node_modules'] &#125;, module: &#123; rules: [ &#123; // 配置处理 css 的 loader test: /\.css$/, use: ['simple-style-loader', 'css-loader'] &#125; ] &#125;, plugins: [ // 渲染首页 new HtmlWebpackPlugin(&#123; template: './src/index.html' &#125;) ]&#125; 在 index.js 中引入一个 css 样式文件 1234// src/index.jsrequire('./index.css');console.log('Brovo!'); 样式文件中将 body 的背景色设置为黄色 12345/* src/index.css */body &#123; background-color: yellow;&#125; 执行webpack 1npm run build 可以看到命令行控制台打印了 ‘simple-style-loader is working’，说明 webpack 成功调用了我们编写的 loader。 在浏览器打开 dist 下的 index.html 页面，可以看到样式生效，而且成功插入到了页面头部！ 说明我们编写的 loader 发挥作用了。 成功！ 三、一些 tips推荐2个工具包开发 loader 必备： 1. loader-utils这个模块中常用的几个方法： getOptions 获取 loader 的配置项。 interpolateName 处理生成文件的名字。 stringifyRequest 把绝对路径处理成相对根目录的相对路径。 2. schema-utils这个模块可以帮你验证 loader option 配置的合法性。用法：1234567891011121314151617181920// loaders/simple-loader-with-validate.jsconst loaderUtils = require('loader-utils');const validate = require('schema-utils');module.exports = function(source) &#123; // 获取 loader 配置项 let options = loaderUtils.getOptions(this) || &#123;&#125;; // 定义配置项结构和类型 let schema = &#123; type: 'object', properties: &#123; name: &#123; type: 'string' &#125; &#125; &#125; // 验证配置项是否符合要求 validate(schema, options); return source;&#125; 当配置项不符合要求，编译就会中断并在控制台打印错误信息： 开发异步 loader异步 loader 的开发（例如里面有一些需要读取文件的操作的时候），需要通过 this.async() 获取异步回调，然后手动调用它。用法：1234567891011// loaders/simple-async-loader.jsmodule.exports = function(source) &#123; console.log('async loader'); let cb = this.async(); setTimeout(() =&gt; &#123; console.log('ok'); // 在异步回调中手动调用 cb 返回处理结果 cb(null, source); &#125;, 3000);&#125; 注： 异步回调 cb() 的第一个参数是 error，要返回的结果放在第二个参数。 raw loader如果是处理图片、字体等资源的 loader，需要将 loader 上的 raw 属性设置为 true，让 loader 支持二进制格式资源（webpack默认是以 utf-8 的格式读取文件内容给 loader）。用法：12345678910111213// loaders/simple-raw-loader.jsmodule.exports = function(source) &#123; // 将输出 buffer 类型的二进制数据 console.log(source); // todo handle source let result = 'results of processing source' return ` module.exports = '$&#123;result&#125;' `;&#125;// 告诉 wepack 这个 loader 需要接收的是二进制格式的数据module.exports.raw = true; 注：通常 raw 属性会在有文件输出需求的 loader 中使用。 输出文件在开发一些处理资源文件（比如图片、字体等）的 loader 中，需要拷贝或者生成新的文件，可以使用内部的 this.emitFile() 方法.用法：123456789101112131415// loaders/simple-file-loader.jsconst loaderUtils = require('loader-utils');module.exports = function(source) &#123; // 获取 loader 的配置项 let options = loaderUtils.getOptions(this) || &#123;&#125;; // 获取用户设置的文件名或者制作新的文件名 // 注意第三个参数，是计算 contenthash 的依据 let url = loaderUtils.interpolateName(this, options.filename || '[contenthash].[ext]', &#123;content: source&#125;); // 输出文件 this.emitFile(url, source); // 返回导出文件地址的模块脚本 return `module.exports = '$&#123;JSON.stringify(url)&#125;'`;&#125;module.exports.raw = true; 在这个例子中，loader 读取图片内容（buffer），将其重命名，然后调用 this.emitFile() 输出到指定目录，最后返回一个模块，这个模块导出重命名后的图片地址。于是当 require 图片的时候，就相当于 require 了一个模块，从而得到最终的图片路径。（这就是 file-loader 的基本原理） 开发约定为了让我们的 loader 具有更高的质量和复用性，记得保持简单。也就是尽量保持让一个 loader 专注一件事情，如果发现你写的 loader 比较庞大，可以试着将其拆成几个 loader 。 在 webpack 社区，有一份 loader 开发准则，我们可以去参考它来指导我们的 loader 设计： 保持简单。 利用多个loader链。 模块化输出。 确保loader是无状态的。 使用 loader-utils 包。 标记加载程序依赖项。 解析模块依赖关系。 提取公共代码。 避免绝对路径。 使用 peerDependency 对等依赖项。 四、总结 loader 的本质是一个 node 模块，这个模块导出一个函数，这个函数上可能还有一个 pitch 方法。 了解了 loader 的本质和 loader 链的执行机制，其实就已经具备了 loader 开发基础了。 开发 loader 不难上手，但是要开发一款高质量的 loader，仍需不断实践。 尝试自己开发维护一个小 loader 吧～ 没准以后可以通过自己编写 loader 来解决项目中的一些实际问题。 文章源码获取：https://github.com/yc111/webpack-loader 欢迎交流～ Happy New Year！ – 参考https://webpack.js.org/concepts/#loadershttps://webpack.js.org/api/loaders/https://webpack.js.org/contribute/writing-a-loader/https://github.com/webpack/webpack/blob/v4.41.5/lib/NormalModuleFactory.jshttps://github.com/webpack-contrib/style-loader/blob/master/src/index.jshttps://www.npmjs.com/package/loader-utilshttps://www.npmjs.com/package/schema-utils]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《新型冠状病毒肺炎预防手册》电子书]]></title>
    <url>%2F2020%2F01%2F27%2F%E3%80%8A%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%E8%82%BA%E7%82%8E%E9%A2%84%E9%98%B2%E6%89%8B%E5%86%8C%E3%80%8B%E7%94%B5%E5%AD%90%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[没想到这次爆发的肺炎疫情这么严重。 这个是从湘雅医学院老师那获取的 新型冠状病毒肺炎预防手册 普及扩散之。 电子书预览： 若无法预览可以直接到github下载pdf：https://github.com/yc111/ebooks/tree/master/medical-science 另附小贴士：为什么外面没有人也要戴口罩 耳戴式口罩佩戴方法 医院标准七步洗手法: 内、外、夹、弓、大、指、腕 友情链接：实时疫情地图-丁香园最新疫情地图及动态2019新型冠状病毒-百度百科新型冠状病毒肺炎-百科医典]]></content>
      <categories>
        <category>电子书</category>
      </categories>
      <tags>
        <tag>ebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘webpack plugin]]></title>
    <url>%2F2020%2F01%2F12%2F%E6%8F%AD%E7%A7%98webpack-plugin%2F</url>
    <content type="text"><![CDATA[Plugin(插件) 是 webpack 生态的的一个关键部分。它为社区提供了一种强大的方法来扩展 webpack 和开发 webpack 的编译过程。本文将尝试探索 webpack plugin，揭秘它的工作原理，以及如何开发一个 plugin。 一、Plugin 的作用关于 Plugin 的作用，引用一下 webpack 官方的介绍： Plugins expose the full potential of the webpack engine to third-party developers. Using staged build callbacks, developers can introduce their own behaviors into the webpack build process. 我把它通俗翻译了下：我们可以通过插件，扩展 webpack，加入自定义的构建行为，使 webpack 可以执行更广泛的任务，拥有更强的构建能力。 二、Plugin 工作原理 webpack 就像一条生产线，要经过一系列处理流程后才能将源文件转换成输出结果。 这条生产线上的每个处理流程的职责都是单一的，多个流程之间有存在依赖关系，只有完成当前处理后才能交给下一个流程去处理。 插件就像是一个插入到生产线中的一个功能，在特定的时机对生产线上的资源做处理。webpack 通过 Tapable 来组织这条复杂的生产线。 webpack 在运行过程中会广播事件，插件只需要监听它所关心的事件，就能加入到这条生产线中，去改变生产线的运作。 webpack 的事件流机制保证了插件的有序性，使得整个系统扩展性很好。——「深入浅出 Webpack」 站在代码逻辑的角度就是：webpack 在编译过代码程中，会触发一系列 Tapable 钩子事件，插件所做的，就是找到相应的钩子，往上面挂上自己的任务，也就是注册事件，这样，当 webpack 构建的时候，插件注册的事件就会随着钩子的触发而执行了。 三、webpack 的一些底层逻辑开发一个 plugin 比开发一个 loader 更高级一些（关于 loader 的开发，可以看我的另一篇文章「揭秘webpack loader」），因为我们会用到一些 webpack 比较底层的内部组件。因此我们需要了解一些 webpack 的底层逻辑。 webpack 内部执行流程一次完整的 webpack 打包大致是这样的过程： 将命令行参数与 webpack 配置文件 合并、解析得到参数对象。 参数对象传给 webpack 执行得到 Compiler 对象。 执行 Compiler 的 run方法开始编译。每次执行 run 编译都会生成一个 Compilation 对象。 触发 Compiler 的 make方法分析入口文件，调用 compilation 的 buildModule 方法创建主模块对象。 生成入口文件 AST(抽象语法树)，通过 AST 分析和递归加载依赖模块。 所有模块分析完成后，执行 compilation 的 seal 方法对每个 chunk 进行整理、优化、封装。 最后执行 Compiler 的 emitAssets 方法把生成的文件输出到 output 的目录中。 webpack 底层基本流程图 webpack 内部的一些钩子什么是钩子钩子的本质就是：事件。为了方便我们直接介入和控制编译过程，webpack 把编译过程中触发的各类关键事件封装成事件接口暴露了出来，这些接口被很形象地称做：hooks（钩子）。开发插件，离不开这些钩子。 TapableTapable 为 webpack 提供了统一的插件接口（钩子）类型定义，它是 webpack 的核心功能库。webpack 中目前有十种 hooks，在 Tapable 源码中可以看到，他们是： 123456789101112// https://github.com/webpack/tapable/blob/master/lib/index.jsexports.SyncHook = require("./SyncHook");exports.SyncBailHook = require("./SyncBailHook");exports.SyncWaterfallHook = require("./SyncWaterfallHook");exports.SyncLoopHook = require("./SyncLoopHook");exports.AsyncParallelHook = require("./AsyncParallelHook");exports.AsyncParallelBailHook = require("./AsyncParallelBailHook");exports.AsyncSeriesHook = require("./AsyncSeriesHook");exports.AsyncSeriesBailHook = require("./AsyncSeriesBailHook");exports.AsyncSeriesLoopHook = require("./AsyncSeriesLoopHook");exports.AsyncSeriesWaterfallHook = require("./AsyncSeriesWaterfallHook"); Tapable 还统一暴露了三个方法给插件，用于注入不同类型的自定义构建行为： tap：可以注册同步钩子和异步钩子。 tapAsync：回调方式注册异步钩子。 tapPromise：Promise方式注册异步钩子。 webpack 里的几个非常重要的对象，Compiler, Compilation 和 JavascriptParser 都继承了 Tapable 类，它们身上挂着丰富的钩子。 Compiler HooksCompiler 编译器模块是创建编译实例的主引擎。大多数面向用户的插件都首先在 Compiler 上注册。 compiler上暴露的一些常用的钩子： 钩子 类型 什么时候调用 run AsyncSeriesHook 在编译器开始读取记录前执行 compile SyncHook 在一个新的compilation创建之前执行 compilation SyncHook 在一次compilation创建后执行插件 make AsyncParallelHook 完成一次编译之前执行 emit AsyncSeriesHook 在生成文件到output目录之前执行，回调参数： compilation afterEmit AsyncSeriesHook 在生成文件到output目录之后执行 assetEmitted AsyncSeriesHook 生成文件的时候执行，提供访问产出文件信息的入口，回调参数：file，info done AsyncSeriesHook 一次编译完成后执行，回调参数：stats Compilation HooksCompilation 是 Compiler 用来创建一次新的编译过程的模块。一个 Compilation 实例可以访问所有模块和它们的依赖。在一次编译阶段，模块被加载、封装、优化、分块、散列和还原。Compilation 也继承了 Tapable 并提供了很多生命周期钩子。 Compilation 上暴露的一些常用的钩子： 钩子 类型 什么时候调用 buildModule SyncHook 在模块开始编译之前触发，可以用于修改模块 succeedModule SyncHook 当一个模块被成功编译，会执行这个钩子 finishModules AsyncSeriesHook 当所有模块都编译成功后被调用 seal SyncHook 当一次compilation停止接收新模块时触发 optimizeDependencies SyncBailHook 在依赖优化的开始执行 optimize SyncHook 在优化阶段的开始执行 optimizeModules SyncBailHook 在模块优化阶段开始时执行，插件可以在这个钩子里执行对模块的优化，回调参数：modules optimizeChunks SyncBailHook 在代码块优化阶段开始时执行，插件可以在这个钩子里执行对代码块的优化，回调参数：chunks optimizeChunkAssets AsyncSeriesHook 优化任何代码块资源，这些资源存放在 compilation.assets 上。一个 chunk 有一个 files 属性，它指向由一个chunk创建的所有文件。任何额外的 chunk 资源都存放在 compilation.additionalChunkAssets 上。回调参数：chunks optimizeAssets AsyncSeriesHook 优化所有存放在 compilation.assets 的所有资源。回调参数：assets JavascriptParser HooksParser 解析器实例在 Compiler 编译器中产生，用于解析 webpack 正在处理的每个模块。我们可以用它提供的 Tapable 钩子自定义解析过程。 JavascriptParser 上暴露的一些常用的钩子： 钩子 类型 什么时候调用 evaluate SyncBailHook 在计算表达式的时候调用。 statement SyncBailHook 为代码片段中每个已解析的语句调用的通用钩子 import SyncBailHook 为代码片段中每个import语句调用，回调参数：statement,source export SyncBailHook 为代码片段中每个export语句调用，回调参数：statement call SyncBailHook 解析一个call方法的时候调用，回调参数：expression program SyncBailHook 解析一个表达式的时候调用，回调参数：expression 对webpack底层逻辑和tapable钩子有了这些了解后，我们就可以进一步尝试开发一个插件了。 四、如何开发一个webpack pluginplugin 的基本结构一个 webpack plugin 由如下部分组成： 一个命名的 Javascript 方法或者 JavaScript 类。 它的原型上需要定义一个叫做 apply 的方法。 注册一个事件钩子。 操作webpack内部实例特定数据。 功能完成后，调用webpack提供的回调。 一个基本的 plugin 代码结构大致长这个样子： 1234567891011// plugins/MyPlugin.jsclass MyPlugin &#123; apply(compiler) &#123; compiler.hooks.done.tap('My Plugin', (stats) =&gt; &#123; console.log('Bravo!'); &#125;); &#125;&#125;module.exports = MyPlugin; 这就是一个最简单的 webpack 插件了，它注册了 Compiler 上的异步串行钩子 done，在钩子中注入了一条控制台打印的语句。根据上文钩子的介绍我们可以知道，done 会在一次编译完成后执行。所以这个插件会在每次打包结束，向控制台首先输出这句 Bravo!。 开发一个文件清单插件我希望每次webpack打包后，自动产生一个打包文件清单，上面要记录文件名、文件数量等信息。 思路： 显然这个操作需要在文件生成到dist目录之前进行，所以我们要注册的是Compiler上的emit钩子。 emit 是一个异步串行钩子，我们用 tapAsync 来注册。 在 emit 的回调函数里我们可以拿到 compilation 对象，所有待生成的文件都在它的 assets 属性上。 通过 compilation.assets 获取我们需要的文件信息，并将其整理为新的文件内容准备输出。 然后往 compilation.assets 添加这个新的文件。 插件完成后，最后将写好的插件放到 webpack 配置中，这个包含文件清单的文件就会在每次打包的时候自动生成了。 实现：123456789101112131415161718192021222324252627282930313233343536373839404142// plugins/FileListPlugin.jsclass FileListPlugin &#123; constructor (options) &#123; // 获取插件配置项 this.filename = options &amp;&amp; options.filename ? options.filename : 'FILELIST.md'; &#125; apply(compiler) &#123; // 注册 compiler 上的 emit 钩子 compiler.hooks.emit.tapAsync('FileListPlugin', (compilation, cb) =&gt; &#123; // 通过 compilation.assets 获取文件数量 let len = Object.keys(compilation.assets).length; // 添加统计信息 let content = `# $&#123;len&#125; file$&#123;len&gt;1?'s':''&#125; emitted by webpack\n\n`; // 通过 compilation.assets 获取文件名列表 for(let filename in compilation.assets) &#123; content += `- $&#123;filename&#125;\n`; &#125; // 往 compilation.assets 中添加清单文件 compilation.assets[this.filename] = &#123; // 写入新文件的内容 source: function() &#123; return content; &#125;, // 新文件大小（给 webapck 输出展示用） size: function() &#123; return content.length; &#125; &#125; // 执行回调，让 webpack 继续执行 cb(); &#125;) &#125;&#125;module.exports = FileListPlugin; 测试：在 webpack.config.js 中配置我们自己写的plugin：123456plugins: [ new MyPlugin(), new FileListPlugin(&#123; filename: '_filelist.md' &#125;)] npm run build 执行，可以看到生成了 _filelist.md 文件： 打开 dist 目录，可以看到_filelist.md 文件中列出了 webpack 打包后的文件： 成功！ 总结本文总结了 webpack plugin 的工作原理、wepack底层执行的基本流程以及介绍了 tapable 和常用的 hooks，最后通过两个小例子演示了如何自己开发一个webpack插件。 开发插件并非难如登天的事情，当遇到通过配置无法解决的问题，又一时找不到好的插件时，不如试试自己编写一个插件来解决，相信我，你会越来越强的！ 本文的源码均可在这里获取：https://github.com/yc111/webpack-plugin 欢迎交流～ Happy New Year！ – 参考https://webpack.js.org/api/compiler-hooks/https://webpack.js.org/api/compilation-hooks/https://webpack.js.org/api/parser/https://github.com/yc111/webpack/tree/master/libhttps://webpack.js.org/contribute/writing-a-plugin/https://github.com/webpack/tapable#tapablehttps://webpack.js.org/concepts/#pluginshttps://webpack.js.org/api/plugins/]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack配置本地loader的四种方法]]></title>
    <url>%2F2020%2F01%2F04%2Fwebpack%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0loader%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[通常我们配置 loader 只需直接使用 loader 的名字，不用关心 loader 的路径。那是因为通过 npm 或者 yarn 安装的 loader 都会安装在 node_modules 目录下，而 webpack 默认所有第三方模块都会去 node_modules 里找。 当我们要使用本地 loader (例如测试自己开发的loader)，而这些模块不在 node_modules 里的时候，就需要告诉 webpack 存放 loader 的位置。 在 webpack4.0 里，一共有四种方法配置本地loader： 1. 在配置 rules 的时候直接指定 loader 的绝对路径123456789101112module.exports = &#123; // xxx module: &#123; rules: [ &#123; test: /\.js$/, // 在这里配置绝对路径 use: path.resolve(__dirname, 'loaders/myLoader.js') &#125; ] &#125;&#125; 2. 或者在 resolveLoader 里配置 alias 别名1234567891011121314151617module.exports = &#123; // xxx resolveLoader: &#123; // 配置 resolveLoader.alias alias: &#123; myLoader: path.resolve(__dirname, 'loaders/myLoader.js') &#125; &#125;, module: &#123; rules: [ &#123; test: /\.js$/, use: 'myLoader' &#125; ] &#125;&#125; 3. 还可以在 resolveLoader 里配置 modules 属性将放置 loader 的目录告诉 webpack。当 webpack 在默认目录下找不到指定 loader 时，会自动去这个目录查找。resolveLoader.modules 是个数组，可以配置多个路径。12345678910111213141516module.exports = &#123; // xxx resolveLoader: &#123; // 配置 resolveLoader.modules modules: ['node_modules', path.resolve(__dirname, 'loaders'] &#125;, module: &#123; rules: [ &#123; test: /\.js$/, use: 'myLoader' &#125; ] &#125;&#125; 4. 还可以使用 npm link 把 loader 从当前项目抽离出来，构建独立工程。 在 loader 工程目录下执行 npm link; 回到原项目目录，执行 npm link xxx (xxx为loader的名称)。 最后，在原项目使用时，直接使用名称即可 (跟 npm install 的 loader 一样使用)。 如果对 npm link 原理感兴趣，可以看一看这篇文章 npm link详解。 –GOOD LUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[封装axios]]></title>
    <url>%2F2019%2F12%2F23%2F%E5%B0%81%E8%A3%85axios%2F</url>
    <content type="text"><![CDATA[axios 是一个轻量的 HTTP客户端，它基于 XMLHttpRequest 服务来执行 HTTP 请求，支持丰富的配置，支持 Promise，支持浏览器端和 Node.js 端。自Vue2.0起，尤大大（Vue作者尤雨溪）宣布取消对 vue-resource 的官方推荐，转而推荐 axios。现在 axios 已经成为大部分 Vue 开发者的首选。（ 如果你还不熟悉 axios，可以在这里查看它的API。） axios 的API很友好，你完全可以很轻松地在项目中直接使用。不过随着项目规模增大，如果每发起一次HTTP请求，就要把这些比如设置超时时间、设置请求头、根据项目环境判断使用哪个请求地址、错误处理等等操作，都就地写一遍，得疯！这种重复劳动不仅浪费时间，而且让代码变得冗余不堪，难以维护。 为了提高我们的代码质量，我们应该在项目中二次封装一下 axios 再使用。 那么，怎么封装 axios 呢？ 原来的样子封装前，先来看下，不封装的情况下，一个实际项目中axios请求的样子。大概是长这样：1234567891011121314151617181920212223242526axios(&apos;http://localhost:3000/data&apos;, &#123; method: &apos;GET&apos;, timeout: 1000, withCredentials: true, headers: &#123; &apos;Content-Type&apos;: &apos;application/json&apos;, Authorization: &apos;xxx&apos;, &#125;, transformRequest: [function (data, headers) &#123; return data; &#125;], // 其他请求配置...&#125;).then((data) =&gt; &#123; // todo: 真正业务逻辑代码 console.log(data);&#125;, (err) =&gt; &#123; if (err.response.status === 401) &#123; // handle authorization error &#125; if (err.response.status === 403) &#123; // handle server forbidden error &#125; // 其他错误处理..... console.log(err);&#125;); 可以看到在这段代码中，页面代码逻辑只在第15行处，上方的一大块请求配置代码和下方一大块响应错误处理代码，几乎跟页面功能没有关系，而且每个请求中这些内容都差不多，甚至有的部分完全一样。想象一下，每发一次请求都来这么一下，十几个请求一写，会是什么盛况？ 封装步骤封装的本质就是在待封装的内容外面添加各种东西，然后把它们作为一个新的整体呈现给使用者，以达到扩展和易用的目的。 封装axios要做的事情，就是把所有HTTP请求共用的配置，事先都在axios上配置好，预留好必要的参数和接口，然后把它作为新的axios返回。 接下来我们借助一个demo实现一个具有良好扩展性的axios封装。 demo目录结构如下(由Vue-cli 3.0 生成)：123456789101112131415|--public/|--mock/| |--db.json # 我新建的接口模拟数据|--src/| |--assets/| |--components/| |--router/| |--store/| |--views/| |--Home.Vue| |--App.vue| |--main.js| |--theme.styl|--package.json|... 封装目标我希望在 Home 页，发起 axios 请求时就像调用一个只有少量参数的方法一样简单，这样我就可以专注业务代码了。 1. 将 axios 封装到一个独立的文件 在src下创建 utils/http.js 文件 123cd srcmkdir utilstouch http.js 引入 axios 123// src/utils/http.jsimport axios from &apos;axios&apos;; 创建一个类你也可以用函数来封装，我只是觉得类更语义化而已。 123456//src/utils/http.js//...class NewAxios &#123;&#125; 给不同环境配置不同请求地址根据 process.env.NODE_ENV 配置不同的 baseURL，使项目只需执行相应打包命令，就可以在不同环境中自动切换请求主机地址。 1234567891011121314151617181920// src/utils/http.js//...const getBaseUrl = (env) =&gt; &#123; let base = &#123; production: &apos;/&apos;, development: &apos;http://localhost:3000&apos;, test: &apos;http://localhost:3001&apos;, &#125;[env]; if (!base) &#123; base = &apos;/&apos;; &#125; return base;&#125;;class NewAxios &#123; constructor() &#123; this.baseURL = getBaseUrl(process.env.NODE_ENV); &#125;&#125; 配置超时时间timeout属性，我一般设置10秒。 123456789// src/utils/http.js//...class NewAxios &#123; constructor() &#123; //... this.timeout = 10000; &#125;&#125; 配置允许携带凭证widthCredentials属性设为true。 123456789// src/utils/http.js//...class NewAxios &#123; constructor() &#123; //... this.withCredentials = true; &#125;&#125; 给这个类创建实例上的方法request在 request 方法里，创建新的axios实例，接收请求配置参数，处理参数，添加配置，返回axios实例的请求结果（一个promise对象）。你也可以不创建，直接使用默认导出的axios实例，然后把所有配置都放到它上面，不过这样一来整个项目就会共用一个axios实例。虽然大部分项目下这样够用没问题，但是有的项目中不同服务地址的请求和响应结构可能完全不同，这个时候共用一个实例就没办法支持了。所以为了封装可以更通用，更具灵活性，我会使用axios的create方法，使每次发请求都是新的axios实例。 12345678910111213141516171819// src/utils/http.js//...class NewAxios &#123; //... request(options) &#123; // 每次请求都会创建新的axios实例。 const instance = axios.create(); const config = &#123; // 将用户传过来的参数与公共配置合并。 ...options, baseURL: this.baseURL, timeout: this.timeout, withCredentials: this.withCredentials, &#125;; // 配置拦截器，支持根据不同url配置不同的拦截器。 this.setInterceptors(instance, options.url); return instance(config); // 返回axios实例的执行结果 &#125;&#125; 因为拦截器配置内容比较多，所以封装成一个内部函数了。 配置请求拦截器在发送请求前对请求参数做的所有修改都在这里统一配置。比如统一添加token凭证、统一设置语言、统一设置内容类型、指定数据格式等等。做完后记得返回这个配置，否则整个请求不会进行。我这里就配置一个token。 123456789101112131415// src/utils/http.js//...class NewAxios &#123; //... // 这里的url可供你针对需要特殊处理的接口路径设置不同拦截器。 setInterceptors = (instance, url) =&gt; &#123; instance.interceptors.request.use((config) =&gt; &#123; // 请求拦截器 // 配置token config.headers.AuthorizationToken = localStorage.getItem(&apos;AuthorizationToken&apos;) || &apos;&apos;; return config; &#125;, err =&gt; Promise.reject(err)); &#125; //...&#125; 配置响应拦截器在请求的then或catch处理前对响应数据进行一轮预先处理。比如过滤响应数据，更多的，是在这里对各种响应错误码进行统一错误处理，还有断网处理等等。我这里就判断一下403、请求超时和断网。 123456789101112131415161718192021222324252627282930313233343536373839404142// src/utils/http.js//...class NewAxios &#123; //... setInterceptors = (instance, url) =&gt; &#123; //... instance.interceptors.response.use((response) =&gt; &#123; // 响应拦截器 // todo: 想根据业务需要，对响应结果预先处理的，都放在这里 console.log(); return response; &#125;, (err) =&gt; &#123; if (err.response) &#123; // 响应错误码处理 switch (err.response.status) &#123; case &apos;403&apos;: // todo: handler server forbidden error break; // todo: handler other status code default: break; &#125; console.log(&apos;err.response: &apos;, err); return Promise.reject(err.response); &#125; if (err.request) &#123; // 请求超时处理 if (err.request.readyState === 4 &amp;&amp; err.request.status === 0) &#123; // 当一个请求在上面的timeout属性中设置的10秒内还没结束，则触发超时错误 // todo handler request timeout error &#125; console.log(&apos;err.request: &apos;, err); return Promise.reject(err.request); &#125; if (!window.navigator.online) &#123; // 断网处理 // todo: jump to offline page return -1; &#125; console.log(&apos;err: &apos;, err); return Promise.reject(err); &#125;); &#125; //...&#125; 另外，在拦截器里，还适合放置loading等缓冲效果：在请求拦截器里显示loading，在响应拦截器里移除loading。这样所有请求就都有了一个统一的loading效果。 默认导出新的实例1234// src/utils/http.js//...export default new NewAxios(); 最后完整的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// src/utils/http.jsimport axios from &apos;axios&apos;;const getBaseUrl = (env) =&gt; &#123; let base = &#123; production: &apos;/&apos;, development: &apos;http://localhost:3000&apos;, test: &apos;http://localhost:3001&apos;, &#125;[env]; if (!base) &#123; base = &apos;/&apos;; &#125; return base;&#125;;class NewAxios &#123; constructor() &#123; this.baseURL = getBaseUrl(process.env.NODE_ENV); this.timeout = 10000; this.withCredentials = true; &#125; setInterceptors = (instance, url) =&gt; &#123; instance.interceptors.request.use((config) =&gt; &#123; // 在这里添加loading // 配置token config.headers.AuthorizationToken = localStorage.getItem(&apos;AuthorizationToken&apos;) || &apos;&apos;; return config; &#125;, err =&gt; Promise.reject(err)); instance.interceptors.response.use((response) =&gt; &#123; // 在这里移除loading // todo: 想根据业务需要，对响应结果预先处理的，都放在这里 return response; &#125;, (err) =&gt; &#123; if (err.response) &#123; // 响应错误码处理 switch (err.response.status) &#123; case &apos;403&apos;: // todo: handler server forbidden error break; // todo: handler other status code default: break; &#125; return Promise.reject(err.response); &#125; if (!window.navigator.online) &#123; // 断网处理 // todo: jump to offline page return -1; &#125; return Promise.reject(err); &#125;); &#125; request(options) &#123; // 每次请求都会创建新的axios实例。 const instance = axios.create(); const config = &#123; // 将用户传过来的参数与公共配置合并。 ...options, baseURL: this.baseURL, timeout: this.timeout, withCredentials: this.withCredentials, &#125;; // 配置拦截器，支持根据不同url配置不同的拦截器。 this.setInterceptors(instance, options.url); return instance(config); // 返回axios实例的执行结果 &#125;&#125;export default new NewAxios(); 现在 axios 封装算是完成了80%。我们还需要再进一步把axios和接口结合再封装一层，才能达到我在一开始定的封装目标。 2. 使用新的 axios 封装API 在 src 目录下新建 api 文件夹。把所有涉及HTTP请求的接口统一集中到这个目录来管理。 新建 home.js。我们需要把接口根据一定规则分好类，一类接口对应一个js文件。这个分类可以是按页面来划分，或者按模块等等。为了演示更直观，我这里就按页面来划分了。实际根据自己的需求来定。 使用新的 axios 封装API（固定url的值，合并用户传过来的参数），然后命名导出这些函数。 12345678// src/api/home.js import axios from &apos;@/utils/http&apos;;export const fetchData = options =&gt; axios.request(&#123; ...options, url: &apos;/data&apos;,&#125;);export default &#123;&#125;; 在 api 目录下新建 index.js，把其他文件的接口都在这个文件里汇总导出。 123// src/api/index.jsexport * from &apos;./home&apos;; 这层封装将我们的新的axios封装到了更简洁更语义化的接口方法中。 现在我们的目录结构长这样：1234567891011121314151617181920|--public/|--mock/| |--db.json # 接口模拟数据|--src/| |--api/ # 所有的接口都集中在这个目录下| |--home.js # Home页面里涉及到的接口封装在这里| |--index.js # 项目中所有接口调用的入口| |--assets/| |--components/| |--router/| |--store/| |--utils/| |--http.js # axios封装在这里| |--views/| |--Home.Vue| |--App.vue| |--main.js| |--theme.styl|--package.json|... 使用封装后的axios现在我们要发HTTP请求时，只需引入 api 下的 index.js 文件就可以调用任何接口了，并且用的是封装后的 axios。12345678910111213141516171819202122232425// src/views/Home.vue&lt;template&gt; &lt;div class=&quot;home&quot;&gt; &lt;h1&gt;This is home page&lt;/h1&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;// @ is an alias to /srcimport &#123; fetchData &#125; from &apos;@/api/index&apos;;export default &#123; name: &apos;home&apos;, mounted() &#123; fetchData() // axios请求在这里 .then((data) =&gt; &#123; console.log(data); &#125;) .catch((err) =&gt; &#123; console.log(err); &#125;); &#125;,&#125;;&lt;/script&gt; axios请求被封装在fetchData函数里，页面请求压根不需要出现任何axios API，悄无声息地发起请求获取响应，就像在调用一个简单的 Promise 函数一样轻松。并且在页面中只需专注处理业务功能，不用被其他事物干扰。 运行运行 npm run serve 启动项目，执行 npm run mock 启动服务mock接口。 现在打开 localhost:8080 可以看到home页面。打开浏览器控制台，可以看到打印的请求响应结果： 简洁，优雅。 总结 封装思想是前端技术中很有用的思想，简单的axios及接口封装，就可以让我们可以领略到它的魅力。 封装 axios 没有一个绝对的标准，只要你的封装可以满足你的项目需求，并且用起来方便，那就是一个好的封装方案。 BTW：以上封装给大家提供了一个封装好的axios和api框架，经过以上过程封装好的 axios，可以不局限于 Vue，React 项目同样可以拿去使用，它适用任何前端项目。 本文的代码可以在这里获取：https://github.com/yc111/wrap-axios 欢迎交流～]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>axios</tag>
        <tag>full stack</tag>
        <tag>http</tag>
        <tag>vue</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ajax vs Axios vs Fetch]]></title>
    <url>%2F2019%2F12%2F20%2FAjax-vs-Axios-vs-Fetch%2F</url>
    <content type="text"><![CDATA[发HTTP请求是JS前端应用最常见的任务之一。实现HTTP请求有非常多解决方案，目前主流的几个解决方案有 ajax、axios 和 fetch。哪个好？如何选？下面对这几个方案进行一个简单的对比分析。 ajax： jQuery库中的异步HTTP请求API。基本语法： 1$.ajax(url[, settings]) axios： 轻量的HTTP客户端，支持浏览器端和 Node.js 端。基本语法: 1axios(url[, options]).then().catch() fetch： Web原生的HTTP请求API。基本语法: 1fetch(url[, options]).then().catch() 可以看到 axios 和 fetch 的基本用法非常一致，不过在面对稍复杂一些的需求时使用还是有差别的。 性能 ajax 和 axios 属于第三方库，它们底层都是基于 XMLHttpRequest，而 fetch 是web原生的 JS API，是 web标准 的一部分。从性能上讲，原生API fetch 有天然的性能优势：1fetch &gt; axios = ajax 简洁性在处理异步的方式上，ajax 基于回调，axios 和 fetch 都是基于 Promise，因此代码会比 ajax 更简洁，更优雅。1axios = fetch &gt; ajax jQuery3.0之后，$.ajax()也支持了$.ajax().done().fail().always()的链式调用方式（内部基于Defferred对象实现）。 易用性在功能上，axios 支持了很多实用的功能封装，比如请求和响应拦截器等等。fetch 则是纯粹的HTTP请求API，不支持额外的功能，你需要自己重写 fetch方法 来实现请求拦截。ajax 也不支持额外的功能。从易用和实用上讲，axios 无疑是占优势的：1axios &gt; fetch &gt; ajax 兼容性兼容性方面，jQuery 是比较早期的库，所以 ajax 对低版本的浏览器支持较好。axios 由于使用了 Promise (ECMAScript2015特性)，在一些低版本浏览器中支持的不好，比如IE8和更低的IE浏览器。fetch 只在比较新的现代浏览器中支持，并且所有IE都不支持。从浏览器兼容上讲：1ajax &gt; axios &gt; fetch 不过现在旧版本浏览器以及IE浏览器已经在慢慢淘汰，浏览器兼容的顾虑会越来越少，兼容性越来越不重要。所以就放心大胆地使用新的技术吧。 一些不成熟的建议和看法 ajax 依然有它的市场，现在依然有很多的依赖 jQuery 库的项目，在 $.ajax 就够用了的情况下，没必要非要引入 axios。 在尤大大的推荐下，Vue 项目一般都搭配 axios 使用，但是不要陷入 “Vue 只能使用 axios”，或者 “axios 只能在 Vue 中使用” 的误区。 以后的大趋势依然是原生web。使用原生的好处之一就是，不依赖外部，不必再加载额外模块，效率高。所以当原生web标准支持越来越多草案后，第三方的库也就没有存在的必要了，以后 fetch 的使用率会越来越高。 不过从历史规律看来，第三方永远比标准发展的快… 最后我想说，没有最好，只有最合适。而只有了解这些技术的特点，才可以让技术选型不再随意或者跟风。 –FIGHTING！ 参考：jQuery ajax APIAxios 官网Fetch API MDN]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>ajax</tag>
        <tag>axios</tag>
        <tag>fetch</tag>
        <tag>full stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack中的publicPath]]></title>
    <url>%2F2019%2F12%2F05%2Fwebpack%E4%B8%AD%E7%9A%84publicPath%2F</url>
    <content type="text"><![CDATA[webpack的常用基本配置我们可能已经耳熟能详，比如 input,output,module,plugins,devServer的配置等等。而在这些基本配置中，其实还有一些细节参数，它可以帮助我们更好的定制化打包的目录结构，但它可能并不是那么好理解，比如publicPath。 webpack官网这么解释：publicPath配置项在很多场景下都非常有用，它允许你给你的应用中的所有静态资源指定一个基本路径。 The publicPath configuration option can be quite useful in a variety of scenarios. It allows you to specify the base path for all the assets within your application. 有些抽象，我总结了下，它大概做的事情就是：可以帮我们处理资源引用的url路径问题：为生成的资源自动添加特定路径前缀。 什么时候需要使用publicPath?1. 打包出来的文件有特定目录结构划分时webpack打包出来的文件，默认都统一放在output配置的path路径下，项目稍大一点，这个目录中的文件就比较杂乱了，我们可能会希望给这些文件进行归类。当然我们可以粗暴一点通过filename来指定一个子目录。但是，如果在这这个子目录中，文件还有层级，就需要配置相应 plugin 或者 loader 的 publicPath 了。 例如file-loader，我们可以配置它的outputPath 自定义生成文件存放在output.path的哪个子目录，并且配置它的 publicPath 指定资源路径前缀：在file-loader中publicPath的值可以是string和function123456789101112module: &#123; rules: [ &#123; test: /\.(png|jpe?g|gif)$/i, loader: &apos;file-loader&apos;, options: &#123; outputPath: &apos;media&apos;, // string publicPath: &apos;media&apos;, // string &#125; &#125; ]&#125; 这样，编译打包后的图片资源就会放在dist/media目录下（假设你设置的output path为dist），并且所有引用到图片的资源路径都会自动加上前缀 media/。 如果想对不同的图片添加不同的路径前缀，可以使用函数来定义publicPath:123456789101112131415161718192021222324252627module: &#123; rules: [ &#123; test: /\.(png|jpe?g|gif)$/i, loader: &apos;file-loader&apos;, options: &#123; publicPath: (url, resourcePath, context) =&gt; &#123; // `resourcePath` 是这个资源的本地绝对路径 // `context` 是存放这个资源的目录，或者是`context`配置项的值 // 想获取相对路径可以这样： // const relativePath = path.relative(context, resourcePath); // 将符合下面条件的png图片url添加前缀 `other_public_path` if (/my-custom-image\.png/.test(resourcePath)) &#123; return `other_public_path/$&#123;url&#125;`; &#125; // 将符合下面条件的图片url添加前缀 `image_output_path` if (/images/.test(context)) &#123; return `image_output_path/$&#123;url&#125;`; &#125; // 其他图片url添加前缀 `public_path` return `public_path/$&#123;url&#125;`; &#125; &#125; &#125; ]&#125; 这样编译打包出来的图片url，就会根据你的设置，分别加上 other_public_path、image_output_path和public_path前缀了（当然这几个目录的名称你自己来定），是不是很不错？ 2. 生产模式要求index首页不在根目录下例如在某些生产模式下，要求产出的文件目录类似这样：12345|--assets/| |--index.js| |--vendor.js|--page/ |--index.html 那么可以这么配置webpack：123456789101112// webpack.prod.js fileoutput: &#123; filename: &apos;assets/[name].js&apos;, path: resolve(__dirname, &apos;../&apos;, &apos;dist&apos;), publicPath: &apos;../&apos; // 相对HTML页面的路径&#125;,plugins: [ new HtmlWebpackPlugin(&#123; template: &apos;../public/index.html&apos;, filename: &apos;pages/index.html&apos; &#125;)], 编译后，在index.html中index.js的引用就会变成这样：1&lt;script src=../assets/index.js&gt;&lt;/script&gt; 在output中publicPath的值可以是以下几种：123456789101112module.exports = &#123; //... output: &#123; // 以下几种之一 publicPath: &apos;https://cdn.example.com/assets/&apos;, // CDN (一定是HTTPS) publicPath: &apos;//cdn.example.com/assets/&apos;, // CDN (HTTPS协议) publicPath: &apos;/assets/&apos;, // 相对服务端跟目录 publicPath: &apos;assets/&apos;, // 相对 HTML 页面文件 publicPath: &apos;../assets/&apos;, // 相对 HTML 页面文件 publicPath: &apos;&apos;, // 相对 HTML 页面文件 (与HTML同一目录) &#125;&#125;; 3. 生产模式下的静态资源在CDN上托管时例如在某些生产模式下，静态文件都由www.xx.com/assets来托管那么可以在 webpack 中这么配置 publicPath：123456// webpack.prod.js fileoutput: &#123; filename: &apos;assets/[name].js&apos;, path: resolve(__dirname, &apos;../&apos;, &apos;dist&apos;), publicPath: &apos;https://www.xx.com/assets&apos; // CDN URL&#125;, 编译后，在 index.html 中 index.js 的引用就会变成这样：1&lt;script src=https://www.xx.com/assets/index.js&gt;&lt;/script&gt; 其他在devServer中也有publicPath配置，默认它是获取output的publicPath的值。要提一下，webpack-dev-server生成的文件是不会放在硬盘的，而是在内存中，所以看不到。只有在请求资源的时候，可以证明文件的存在。。。123devServer &#123; publicPath: &apos;/assets/&apos;&#125; 一定要在string的前后都放上/。 需要注意的是，devServer中还有一个叫做contentBase的参数，这个参数如果配置的不好，跟publicPath一搭配，很可能会导致请求不到页面（我也是被这个坑了很久）。这个地方如果出问题，基本上原因在于contentBase设置的路径范围太小了，去掉contentBase配置，或者给它配置多个路径，把输出目录包含进来，就可以解决问题。 1234devServer &#123; contentBase: [path.resolve(__dirname, &apos;../assets&apos;), path.resolve(__dirname, &apos;../dist&apos;)], // contentBase可以放多个路径 publicPath: &apos;/assets/&apos;&#125; –GOOD LUCK! 参考：https://webpack.js.org/guides/public-path/https://www.npmjs.com/package/file-loader]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack优化之happypack]]></title>
    <url>%2F2019%2F11%2F29%2Fwebpack%E4%BC%98%E5%8C%96%E4%B9%8Bhappypack%2F</url>
    <content type="text"><![CDATA[上篇文章webpack优化之玩转代码分割和公共代码提取从代码维度出发，为生产环节进行了优化（通过提取公用代码减小打包结果体积，提升线上体验）。而在开发大型前端项目时，经过一段时间的开发维护和不断迭代，随着业务功能增多，就算提取了公共代码，项目体积仍会越来越大（如果不从产品层面优化，这是无法避免的），这意味着编译打包时间会越来越久、从修改代码到看到效果的等待时间越来越长。为了更好的开发体验，这次我们来为开发环节做一些事情。 How？我们可以试试使用happypack。虽然这个包有点老了，作者也不怎么维护了（汗。。（因为他不怎么使用javascript了，他推荐了thread-loader，有空研究下） HappypackHappypack 是一个webpack插件，它可以帮助我们实现多线程打包，提升webpack打包性能，减少开发者等待打包的时间，从而提升开发体验，提高开发效率。 使用Happypack的使用非常简单，只需3步： 安装happypack 1npm i -D happypack 修改rules配置 1234&#123; rest: /\.js$/, use: &apos;Happypack/loader?id=js&apos; //id用于在接下来的插件中引用，便于识别对谁进行多线程打包&#125; 在webpack插件中 new happypack把原来在rules中配置的use参数放到happypack插件参数中。 123456new Happypack(&#123; id: &apos;js&apos;, use :[&#123; loader: &apos;babel-loader&apos; &#125;]&#125;) 最后大致长这样：12345678910111213141516171819202122const Happypack = require(&apos;happypack&apos;);module.exports = &#123; mode: &apos;development&apos;, entry: xxx, output: xxx, module: &#123; rules: [ &#123; rest: /\.js$/, use: &apos;Happypack/loader?id=js&apos; &#125; ] &#125;, plugins: [ new Happypack(&#123; id: &apos;js&apos;, use :[&#123; loader: &apos;babel-loader&apos; &#125;] &#125;) ]&#125; 如果还要对其他类型的文件进行多线程打包，可以继续替换和new就行（注意id的对应）。 happypack适用于比较大的项目，如果项目比较小，使用happypack可能会花更长时间，因为开线程需要消耗一些性能。 –GOOD LUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack优化之玩转代码分割和公共代码提取]]></title>
    <url>%2F2019%2F11%2F15%2Fwebpack%E4%BC%98%E5%8C%96%E4%B9%8B%E7%8E%A9%E8%BD%AC%E4%BB%A3%E7%A0%81%E5%88%86%E5%89%B2%E5%92%8C%E5%85%AC%E5%85%B1%E4%BB%A3%E7%A0%81%E6%8F%90%E5%8F%96%2F</url>
    <content type="text"><![CDATA[开发多页应用的时候，如果不对webpack打包进行优化，当某个模块被多个入口模块引用时，它就会被打包多次（在最终打包出来的某几个文件里，它们都会有一份相同的代码）。当项目业务越来越复杂，打包出来的代码会非常冗余，文件体积会非常庞大。大体积文件会增加编译时间，影响开发效率；如果直接上线，还会拉长请求和加载时长，影响网站体验。作为一个追求极致体验的攻城狮，是不能忍的。所以在多页应用中优化打包尤为必要。那么如何优化webpack打包呢？ 一、概念在一切开始前，有必要先理清一下这三个概念： module: 模块，在webpack眼里，任何可以被导入导出的文件都是一个模块。 chunk: chunk是webpack拆分出来的： 每个入口文件都是一个chunk 通过 import、require 引入的代码也是 通过 splitChunks 拆分出来的代码也是 bundle: webpack打包出来的文件，也可以理解为就是对chunk编译压缩打包等处理后的产出。 二、问题分析首先，简单分析下，我们刚才提到的打包问题： 核心问题就是：多页应用打包后代码冗余，文件体积大。 究其原因就是：相同模块在不同入口之间没有得到复用，bundle之间比较独立。 弄明白了问题的原因，那么大致的解决思路也就出来了： 我们在打包的时候，应该把不同入口之间，共同引用的模块，抽离出来，放到一个公共模块中。这样不管这个模块被多少个入口引用，都只会在最终打包结果中出现一次。————解决代码冗余。 另外，当我们把这些共同引用的模块都堆在一个模块中，这个文件可能异常巨大，也是不利于网络请求和页面加载的。所以我们需要把这个公共模块再按照一定规则进一步拆分成几个模块文件。————减小文件体积。 至于如何拆分，方式因人而异，因项目而异。我个人的拆分原则是： 业务代码和第三方库分离打包，实现代码分割； 业务代码中的公共业务模块提取打包到一个模块； 第三方库最好也不要全部打包到一个文件中，因为第三方库加起来通常会很大，我会把一些特别大的库分别独立打包，剩下的加起来如果还很大，就把它按照一定大小切割成若干模块。 optimization.splitChunkswebpack提供了一个非常好的内置插件帮我们实现这一需求：CommonsChunkPlugin。不过在 webpack4 中CommonsChunkPlugin被删除，取而代之的是optimization.splitChunks, 所幸的是optimization.splitChunks更强大！ 三、 实现通过一个多页应用的小demo，我们一步一步来实现上述思路的配置。 demo目录结构：12345678910|--public/| |--a.html| |--index.html|--src/| |--a.js| |--b.js| |--c.js| |--index.js|--package.json|--webpack.config.js 代码逻辑很简单，index模块中引用了 a 和 b 2个模块，a 模块中引用了 c 模块和 jquery库，b 模块中也引用了 c 模块和 jquery 库，c 是一个独立的模块没有其他依赖。 index.js代码如下：1234567//index.jsimport a from &apos;./a.js&apos;;import b from &apos;./b.js&apos;;function fn() &#123; console.log(&apos;index-------&apos;);&#125;fn(); a.js代码如下：1234567//a.jsrequire(&apos;./c.js&apos;);const $ = require(&apos;jquery&apos;)function fn() &#123; console.log(&apos;a-------&apos;);&#125;module.exports = fn(); b.js代码如下：1234567//b.jsrequire(&apos;./c.js&apos;);const $ = require(&apos;jquery&apos;)function fn() &#123; console.log(&apos;b-------&apos;);&#125;module.exports = fn(); c.js代码如下：12345//c.jsfunction fn() &#123; console.log(&apos;c-------&apos;);&#125;module.exports = fn(); 1. 基本配置webpack先不做优化，只做基本配置看看效果。项目配置了2个入口，搭配html-webpack-plugin实现多页打包：1234567891011121314151617181920212223const path = require(&apos;path&apos;);const HtmlWebpackPlugin = require(&apos;html-webpack-plugin&apos;);module.exports = &#123; entry: &#123; index: &apos;./src/index.js&apos;, a: &apos;./src/a.js&apos; &#125;, output: &#123; path: path.resolve(__dirname, &apos;dist&apos;), filename: &apos;[name].js&apos; &#125;, plugins: [ new HtmlWebpackPlugin(&#123; template: &apos;./public/index.html&apos;, filename: &apos;index.html&apos; &#125;), new HtmlWebpackPlugin(&#123; template: &apos;./public/a.html&apos;, filename: &apos;a.html&apos; &#125;) ]&#125; 在开发模式下运行webpack： 可以看到，打包出两个html和两个体积很大的（300多K）的文件a.js,index.js。 进入dist目录检查js文件： a.js里包含c模块代码和jquery代码 index.js里包含a模块、b模块、c模块和jquery代码 看，同样的代码c和jquery被打包了2遍。 2. 初步添加splitChunks优化配置首先解决相同代码打包2次的问题，我们需要让webpack把c和jquery提取出来打包为公共模块。 在webpack配置文件添加splitChunks：123456789101112//webpack.config.jsoptimization: &#123; splitChunks: &#123; cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos; &#125; &#125; &#125;&#125; - cacheGroups cacheGroups是splitChunks配置的核心，对代码的拆分规则全在cacheGroups缓存组里配置。 缓存组的每一个属性都是一个配置规则，我这里给他的default属性进行了配置，属性名可以不叫default可以自己定。属性的值是一个对象，里面放的我们对一个代码拆分规则的描述。 - name name：提取出来的公共模块将会以这个来命名，可以不配置，如果不配置，就会生成默认的文件名，大致格式是index～a.js这样的。 - chunks chunks：指定哪些类型的chunk参与拆分，值可以是string可以是函数。如果是string，可以是这个三个值之一：all,async,initial，all代表所有模块，async代表只管异步加载的, initial代表初始化时就能获取的模块。如果是函数，则可以根据chunk参数的name等属性进行更细致的筛选。 再次打包： 可以看到a.js,index.js从300多K减少到6点几K。同时增加了一个common.js文件，并且两个打包入口都自动添加了common.js这个公共模块： 进入dist目录，依次查看这3个js文件： a.js里不包含任何模块的代码了，只有webpack生成的默认代码。 index.js里同样不包含任何模块的代码了，只有webpack生成的默认代码。 common.js里有a,b,c,index,jquery代码。 发现，提是提取了，但是似乎跟我们预料的不太一样，所有的模块都跑到common.js里去了。 这是因为我们没有告诉webpack（splitChunks）什么样的代码为公共代码，splitChunks默认任何模块都会被提取。 - minChunkssplitChunks是自带默认配置的，而缓存组默认会继承这些配置，其中有个minChunks属性： 它控制的是每个模块什么时候被抽离出去：当模块被不同entry引用的次数大于等于这个配置值时，才会被抽离出去。 它的默认值是1。也就是任何模块都会被抽离出去（入口模块其实也会被webpack引入一次）。 我们上面没有配置minChunks，只配置了name和chunk两个属性，所以minChunks的默认值 1 生效。也难怪所有的模块都被抽离到common.js中了。 优化一下，在缓存组里配置minChunks覆盖默认值：12345678910111213//webpack.config.jsoptimization: &#123; splitChunks: &#123; cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos;, minChunks: 2 //模块被引用2次以上的才抽离 &#125; &#125; &#125;&#125; 然后运行webpack 可以看到有2个文件的大小发生了变化：common.js由314K减小到311K，index.js由6.22K增大到7.56K。 进入dist目录查看： a.js里依然不包含任何模块的代码（正常，因为a作为模块被index引入了一次，又作为入口被webpack引入了一次，所以a是有2次引用的）。 index.js里出现了b和index模块的代码了。 common.js里只剩a,c,和jquery模块的代码。 现在我们把共同引用的模块a, c, jquery，从a和index这两个入口模块里抽取到common.js里了。有点符合我们的预期了。 3. 配置多个拆分规则3.1 实现代码分离，拆分第三方库接下来，我希望公共模块common.js中，业务代码和第三方模块jquery能够剥离开来。 我们需要再添加一个拆分规则。123456789101112131415161718192021//webpack.config.jsoptimization: &#123; splitChunks: &#123; minSize: 30, //提取出的chunk的最小大小 cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos;, minChunks: 2, //模块被引用2次以上的才抽离 priority: -20 &#125;, vendors: &#123; //拆分第三方库（通过npm|yarn安装的库） test: /[\\/]node_modules[\\/]/, name: &apos;vendor&apos;, chunks: &apos;initial&apos;, priority: -10 &#125; &#125; &#125;&#125; 我给cacheGroups添加了一个vendors属性（属性名可以自己取，只要不跟缓存组下其他定义过的属性同名就行，否则后面的拆分规则会把前面的配置覆盖掉）。 - minSizeminSize设置的是生成文件的最小大小，单位是字节。如果一个模块符合之前所说的拆分规则，但是如果提取出来最后生成文件大小比minSize要小，那它仍然不会被提取出来。这个属性可以在每个缓存组属性中设置，也可以在splitChunks属性中设置，这样在每个缓存组都会继承这个配置。这里由于我的demo中文件非常小，为了演示效果，我把minSize设置为30字节，好让公共模块可以被提取出来，正常项目中不用设这么小。 - prioritypriority属性的值为数字，可以为负数。作用是当缓存组中设置有多个拆分规则，而某个模块同时符合好几个规则的时候，则需要通过优先级属性priority来决定使用哪个拆分规则。优先级高者执行。我这里给业务代码组设置的优先级为-20，给第三方库组设置的优先级为-10，这样当一个第三方库被引用超过2次的时候，就不会打包到业务模块里了。 - testtest属性用于进一步控制缓存组选择的模块，与chunks属性的作用有一点像，但是维度不一样。test的值可以是一个正则表达式，也可以是一个函数。它可以匹配模块的绝对资源路径或chunk名称，匹配chunk名称时，将选择chunk中的所有模块。我这里用了一个正则/[\\/]node_modules[\\/]/来匹配第三方模块的绝对路径，因为通过npm或者yarn安装的模块，都会存放在node_modules目录下。 运行一下webpack： 可以看到新产生了一个叫vendor.js的文件（name属性的值），同时common.js文件体积由原来的311k减少到了861bytes！ 进入dist目录，检查js文件： a.js里不包含任何模块代码。 common.js只包含a和c模块的代码。 index.js只包含b和index模块的代码。 vendor.js只包含jquery模块的代码。 现在，我们在上一步的基础上，成功从common.js里把第三方库jquery抽离出来放到了vendor.js里。 3.2 拆分指定文件如果我们还想把项目中的某一些文件单独拎出来打包（比如工程本地开发的组件库），可以继续添加拆分规则。比如我的src下有个locallib.js文件要单独打包，假设a.js中引入了它。12345678//a.jsrequire(&apos;./c.js&apos;);require(&apos;./locallib.js&apos;); //引入自己本地的库const $ = require(&apos;jquery&apos;)function fn() &#123; console.log(&apos;a-------&apos;);&#125;module.exports = fn(); 可以这么配置：123456789101112131415161718192021222324252627//webpack.config.jsoptimization: &#123; splitChunks: &#123; minSize: 30, //提取出的chunk的最小大小 cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos;, minChunks: 2, //模块被引用2次以上的才抽离 priority: -20 &#125;, vendors: &#123; //拆分第三方库（通过npm|yarn安装的库） test: /[\\/]node_modules[\\/]/, name: &apos;vendor&apos;, chunks: &apos;initial&apos;, priority: -10 &#125;, locallib: &#123; //拆分指定文件 test: /(src\/locallib\.js)$/, name: &apos;locallib&apos;, chunks: &apos;initial&apos;, priority: -9 &#125; &#125; &#125;&#125; 我在缓存组下又新增了一个拆分规则，通过test正则指定我就要单独打包src/locallib.js文件，并且把优先级设置为-9，这样当它被多次引用时，不会进入其他拆分规则组，因为另外两个规则的优先级都比它要低。 运行webpack打包后： 可以看到新产生了一个locallib.js文件。进入dist目录查看： a.js里不包含任何模块代码。 common.js只包含a和c模块的代码。 index.js只包含b和index模块的代码。 vendor.js只包含jquery模块的代码。 locallib.js里只包含locallib模块的代码。 现在我们又在上一步的基础上独立打包了一个指定的模块locallib.js。 至此，我们就成功实现了抽离公共模块、业务代码和第三方代码剥离、独立打包指定模块。 对比一下，优化前，打包出来js一共有633KB： 优化后，打包出来js一共不到330KB： 优化打包后的文件分类清晰，体积比优化前缩小了几乎50%，有点小完美是不是！击掌！这还只是我举的一个简单例子，在实际多页应用中，优化力度说不定还不止这么多。 总结webpack很强大，以上只是冰山一角，但是只要掌握了上述optimization.splitChunks的核心配置，我们就可以几乎随心所欲地按照自己的想法来拆分优化代码控制打包文件了，是不是很酷？ 用webpack玩转代码拆分，你也可以！ 本文的完整webpack配置和demo源码可以在这里获取：https://github.com/yc111/webpack-optimize-demo 欢迎一起探讨～ 如果觉得这些依然不能满足你的需求，还想更精(bian)细(tai)地定制打包规则，可以到webpack官网查看optimization.splitChunks的更多配置。 –GOODLUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>splitChunks</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack如何不打包第三方模块]]></title>
    <url>%2F2019%2F11%2F13%2Fwebpack%E5%A6%82%E4%BD%95%E4%B8%8D%E6%89%93%E5%8C%85%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[在一些前端工程中，不是所有的模块都需要打包到最终的生产中，例如开发UI库，我们不需要把依赖的基础框架和库打进去（比如vue，react，jquery等），因为它们在业务工程中会肯定会被引入，没必要在UI库中打包，而且打包进来不仅让UI库体积庞大，还可能在业务工程中引发版本依赖冲突。那么如何让工程在打包中避开某些不希望被打包的第三方模块呢？ webpack的externals可以帮到你，它的配置非常简单。 external的配置在webpack的配置文件中添加externals属性，把你不希望打包在最终结果中的包写进去就行了，你的其他代码不需要任何更改，头部的 import、require 什么的都不用变。12345678// webpack.config.jsmodule.exports = &#123; externals: &#123; jquery: &apos;jquery&apos;, react: &apos;react&apos;, &apos;react-dom&apos;: &apos;react-dom&apos; &#125;&#125; 然后再build打包的时候，你会发现打包出来的文件体积小了很多很多，打开编译后的文件看就会发现指定的第三方库都从代码中剔除了。 –GOODLUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cookie、session]]></title>
    <url>%2F2019%2F11%2F09%2Fcookie%E3%80%81session%2F</url>
    <content type="text"><![CDATA[Cookie是什么？它的工作原理是什么？Session是什么？它跟Cookie有什么区别？ Web应用是基于Http协议的，Http协议是无状态协议，因此没办法把同一个用户的两次请求关联起来，用户必须每操作一次就要登录一次。为了支持客户端与服务器之间的交互，我们需要一种技术为交互存储状态，Cookie和Session就应运而生。 一、概念 Cookie：Cookie由W3C组织提出。Cookie属于http协议标准，它是一段小信息，由服务器创建，以文本形式存储在客户端（浏览器）。用于存储一些服务器需要的用户信息数据，最大4KB。 Session：Session不属于任何协议，只是一个域对象，由服务器创建，保存在服务器上（默认是服务器内存，也可以存存redies或其他数据库如mogo等）。用于存储一些客户端会话数据，没有大小限制。 会话：用户打开浏览器访问某个网站，在这个网站上浏览任意页面，访问完成后将浏览器关闭的过程称为一次会话。Cookie和Session都属于常见的会话技术。会话技术是用于解决在会话过程中数据的保存问题。 二、Cookie的工作原理服务器收到客户端请求，如果服务器需要记录该用户状态： 则可以创建一个Cookie，放上用户信息，然后把Cookie信息附在Response Header（响应头）里，传给客户端（浏览器）。 浏览器收到响应后，会自动把这个Cookie保存到本地。 当客户端再次向该网站发出http请求时，浏览器会自动往Request Header（请求头）里添加这个Cookie。 服务器收到后，就可以根据请求里的Cookie字段，辨认用户状态等，也可以根据需要修改Cookie的内容。 另外： JavaScript能够任意读写Cookie，所以浏览器也可以改Cookie的内容，因此Cookie被视为不安全的。 Cookie中的信息一般都需要先经过加密。 Cookie不能跨域，但可以通过设置Cookie的domain参数来支持跨子域名（注意domain必须以.开头）。 很多浏览器都限制一个站点最多保存20个Cookie。 在浏览器想获取Cookie，可以通过document.cookie，获取该网站的所有Cookie。 Cookie生命周期只要设置了正常的有效期，浏览器会把Cookie保存到硬盘，关闭再打开浏览器，Cookie依然有效，直到超过设定的失效时间。Cookie有两种方式设置有效期，也可以称为生命周期。 maxAge 单位秒，设置的是从现在起，往后多久失效。 如果为正数，则该Cookie在maxAge秒后失效。 如果为负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。这种称为会话Cookie。 如果为0，表示删除该Cookie。 默认为-1，即默认在浏览器关闭后，Cookie就失效。 expires 可以设置一个绝对时间点，到达时间点即失效。 可以设置为整天数，表示expires天后失效。 如果设置的是一个过去的时间，那么这个Cookie会被立即删掉，立即失效。 三、Session的工作原理服务器收到客户端请求，如果服务器需要记录该用户状态： 则服务器可以产生一个Session，同时会生成一个唯一的sessionId， 服务器将这个sesionId通过set-cookie的放到Cookie中，借用Cookie的方式传给客户端， 客户端接收到响应后，浏览器会把Cookie保存，也就同时保存了sessionId。 当用户再次向该网站发出http请求时，浏览器的自动附加Cookie机制，让服务器收到带sessionId的Cookie，然后服务器通过sessionId来匹配用户状态，比如是否登录等。 另外： 因为Session存在服务端，所以它不能被客户端获取和修改，因此比Cookie安全些。 因为在服务端，Session没有跨域问题。 如果客户端禁用了Cookie的话，服务器还可以通过重写URL的方式把Session传给客户端。 由浏览器窗口内的链接、脚本等打开的新窗口，这类子窗口会共享父窗口的Cookie，因此也会共享一个Session。 Session生命周期 Session在用户第一次访问服务器的时候创建。 Session生成后，只要用户继续访问，服务器就会认为该用户的Session活跃（active）了一次，然后更新Session的最后访问时间，维护该Session。 如果正常关闭服务器，Session会序列化到硬盘。当服务器重新启动时，会执行反序列化。 一般包含Session信息的Cookie会设置失效时间为0，即浏览器进程有效时间，这种情况当浏览器关闭，Cookie失效，服务器在收到下一次请求后，就会销毁Session。 为了获取更高的存取速度，服务器一般把Session存在内存里。每个用户都有一个独立的Seesion，为了防止内存溢出，服务器会把长时间没有活跃的Session从内存中删除。这个时间就是Session的超时时间。另外，如果服务器宕机，Session也就销毁了 当Session被存在了数据库，则它的生命周期由Cookie的失效时间决定：如果此时服务器宕机，只要开机后数据库没有发生不可逆的破坏，Cookie时间没过期，那么Session继续保持；当Cookie过期，服务器将Session从数据库移除。 –参考：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Cookieshttps://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Set-Cookiehttps://blog.csdn.net/fangaoxin/article/details/6952954https://www.cnblogs.com/zhuanzhuanfe/p/8010854.htmlhttp://www.itheima.com/news/20180831/150322.htmlhttps://blog.csdn.net/pingfan592/article/details/88388045]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>cookie</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过webpack定义全局模块]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87webpack%E5%AE%9A%E4%B9%89%E5%85%A8%E5%B1%80%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[不知道大家在开发中有没有遇到这种情况，就是在很多模块里都要用到某一个库，于是在这些模块里都要不厌其烦地import一遍。页面少也还好，当项目庞大到一定程度，就有些讨厌了。有没有办法不要每次使用前都import，而是有个全局的引入，在其他任何地方直接使用就行了呢？有，webpack可以帮我们，它的内置插件ProvidePlugin就是为这个而生的。 1. 用法在webpack配置文件中配置plugins属性。语法：123new webpack.ProvidePlugin(&#123; identifier: &apos;modulename&apos;&#125;) 如果像上面一样，直接指定模块名，确保你的模块就在当前目录下，或者是通过npm、yarn安装的。因为这么写，默认模块路径为当前目录./**和node_modules，webpack只会从这两个目录去加载模块（先找当前目录，找不到找node_modules目录）。 另外如果是导入ES6modules，需要指定模块的默认导出属性：123new webpack.ProvidePlugin(&#123; identifier: [&apos;modulename&apos;,&apos;propertyname&apos;]&#125;) 你也可以自己指定模块的完整绝对路径。这样你的模块可以放在工程的任何目录：123new webpack.ProvidePlugin(&#123; identifier: path.resolve(__dirname, somepath ,&apos;modulename&apos;)&#125;) 例如我在项目中要用到jQuery, Vue, mili(项目中的自己开发的工具模块)，这几个模块在很多地方都要使用，我就可以把他们申明在ProvidePligin中：12345678plugins: [ new webpack.ProvidePlugin(&#123; $: &apos;jquery&apos;, &apos;window.$&apos;: &apos;jquery&apos;, Vue: [&apos;vue/dist/vue.esm.js&apos;, &apos;default&apos;], mili: path.resolve(__dirname, &apos;src&apos;, &apos;mili&apos;) &#125;)] 2. 原理ProvidePlugin是webpack内置的插件，在里面申明过的模块变量名，都可以在工程中任何模块中直接独立使用。因为webpack编译后，在代码中遇到独立出现的这些全局变量名时，会去自动加载它对应的模块，并把这个模块导出的内容（或者导出的某个指定的属性）赋给这个模块变量名。 3. 应用当我在ProvidePlugin中申明过全局模块变量后，在其他模块，我可以直接使用它们，而不用在头部import了。例如就上面例子中我申明了$, window.$, Vue, mili 四个全局模块变量，我就可以直接这么使用了：1234567// any module file// free to use $, window.$, Vue, mili，without importing them.let &#123;Message&#125; = mili;let $toot = $(&apos;#root&apos;);let $ele = window.$(&apos;#container&apos;);Vue.prototype.$bus = new Vue; 番外除了webpack.ProvidePlugin，还有其他方法实现全局模块变量，当作番外简单介绍一下吧。 1. html引用我们还可以通过在index.html模版中通过script标签引入全局模块。这个模块的路径可以是CDN地址，也可以是本地路径。然后在每个模块中就都能使用这个模块了。 引用CDN1234//index.html file&lt;head&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.js&quot;&gt;&lt;/script&gt;&lt;/head&gt; 引用本地前提是这个文件在项目发布的时候服务器上要有，所以记得在webpack上配置 copy-webpack-plugin 插件。1234//index.html file&lt;head&gt; &lt;script src=&quot;/vendor/jquery_3.4.1.js&quot;&gt;&lt;/script&gt;&lt;/head&gt; 这样在其他模块都可以直接使用window.$和$了。12console.log(window.$);console.log($); 2. expose-loaderexpose-loader 虽然是一个比较老的包，但是依然可用。它的作用是给全局对象window添加模块。 先安装：npm i -S expose-loader 可以内联使用在入口文件导入全局模块：1require(&apos;expose-loader?$!jquery&apos;); 或则1import $ from &apos;expose-loader?$!jquery&apos;; 也可以在webpack中配置1234567891011module: &#123; rulers: [ &#123; test: require.resolve(&apos;jquery&apos;), use: &#123; loader: &apos;expose-loader&apos;, options: &apos;$&apos; &#125; &#125; ]&#125; 不论使用哪种方式，最后在任何模块都可以通过window.$来使用jquery了：1console.log(window.$); –GOODLUCK!]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何利用webpack定义全局常量]]></title>
    <url>%2F2019%2F11%2F06%2F%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8webpack%E5%AE%9A%E4%B9%89%E5%85%A8%E5%B1%80%E5%B8%B8%E9%87%8F%2F</url>
    <content type="text"><![CDATA[在前端开发过程中，我们在不同的工程阶段，对代码会有不同的要求。比如在开发阶段，我们希望代码能更快地实时编译，自动刷新，可以调试定位源码；在接口测试阶段，我们希望可以不修改源码，只通过修改某个配置，就可以无缝切换接口地址或者上下文，以及决定请求是否携带token；在发布代码时，我们希望输出的代码体积尽可能小，代码可以各种压缩，各种分离打包等等。为了让一套代码适应不同工程阶段的需求，我们通常会刻意制造开发、测试、生产几种编译模式。然后我们通过webpack做一些配置，使得webpack在编译阶段可以识别出当前是什么模式，从而产生不同的编译行为，达到不同的编译效果。而这个配置，就是webpack.DefinePlugin。它是webpack的内置插件，用于提供自定义全局常量功能。 1. 配置方法1234567// webpack.config.js fileplugins: [ new webpack.DifinePlugin(&#123; DEVELOPMENT: &apos;&quot;dev&quot;&apos;, // JSON.stringify(&apos;dev&apos;) &apos;process.env.NODE_ENV&apos;: JSON.stringify(process.env.NODE_ENV) &#125;)] tip1: 定义全局常量时，常量的值会需要被字符串化，需要注意的是，如果写成字符串格式，必须在单引号内再套一对双引号（或者反过来在双引号内套单引号），才能彻底字符串化，或者直接使用JSON.stringify。 tip2: 如果要为process的某个属性定义值，尽量使用&#39;process.env.NODE_ENV&#39;: JSON.stringify(process.env.NODE_ENV)而不要使用process: { env: { NODE_ENV: JSON.stringify(&#39;production&#39;) } }，因为后面的做法会覆盖process对象，会影响其他模块的兼容性（因为其他模块也可能会对它赋值）。 2. 原理webpack.DefinePlugin中定义的常量，它会在编译时，内联地加入代码中，相当于原地替换，所以在项目的源码任何js模块中都可以直接使用这些常量。 3. 全局常量使用场景通过webpack.DefinePlugin配置常量的意义在于，我们可以保存一些在编译时产生的变量的值，然后在编译完的运行态中，获取和使用这个常量，来做一些事情。 ‘process.env.NODE_ENV’是比较常用的常量，它是我们区分不同编译模式的关键，在编译以外的代码中，我们很多时候也需要拿这个值来实现一些切换，主要目的是为了让开发、测试更方便和高效。 场景举例：定义’process.env.NODE_ENV’常量，在前端发请求的时候，根据’process.env.NODE_ENV’这个常量设置不同的请求路径格式。1234567891011switch(process.env.NODE_ENV) &#123; case &apos;dev&apos;: baseUrl = &apos;localhost:8000&apos;; return; case &apos;test&apos;: baseUrl = &apos;10.22.22.21:3000&apos;; return; case &apos;prod&apos;: baseUrl = &apos;10.69.32.101&apos;; return;&#125; –GOODLUCK!]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack解决跨域的几种方法]]></title>
    <url>%2F2019%2F11%2F05%2Fwebpack%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[作为前端攻城狮，经常要面临的问题就是跨域，不论是调自己mock服务的数据，还是真实前后台联调。因为接口服务与前端工程通常都是独立的工程，而前端有很多协议需要遵循同源策略（后端则不需要）。解决跨域的方法有很多，可以在服务端配置，也可以在前端解决。作为前端开发者，我更偏向在前端把跨域解决掉，别问我为什么，我就是喜欢这种不依赖后端的感觉[傲娇脸]。 PS：我使用webpack构建工程，我的方法都是基于webpack的大前提下。如果你是用的其他构建工具，或者是没有使用构建工具的工程环境，我的方法可能不能适用。 不能操控服务端代码的情况当你不能操控服务端代码时（比如前后端联调），你可以通过webpack配置代理。 1. 通过 http-proxy 代理在webpack配置文件 webpack.config.js 中添加 devServer 配置。然后配置它的 proxy 属性，webpack-dev-server 在起服务后，会把匹配的本地请求转到 proxy 里配置的服务器上去请求，通过服务端的转发，实现跨域。 有点抽象，举个栗子： 我的前端工程服务端口8000。我要联调的服务端口3000，域名‘champyin.com’。 我在前端这么发请求：xhr.open(‘GET, ‘/api/students’, true);那么我其实发的请求完整url为 http://localhost:8000/api/students,直接发肯定是报错的，因为我的本地是没有这个接口的。 现在我在webpack这么配置代理，给/api配置一个映射 12345devServer: &#123; proxy: &#123; &apos;/api&apos;: &apos;http://champyin.com:3000&apos; &#125;&#125; npm run dev 重启下前端工程，webpack-dev-server 在遇到’/api/students’这种以/api开头的请求的时候，它不再往本地发了，而是向对应的http://champyin.com:3000发请求。这是一种后端的请求转发，而后端没有跨域问题。这个时候，虽然在浏览器查看网络请求的时候，会看到前端发的请求地址是http://localhost:8000/api/students，但其实它的背后真正获取响应的请求是http://champyin.com:3000/api/students。 灵活的proxy配置很多时候，后端的接口不一定都有一个统一的前缀，这个时候，如果还按照上面的方法，那就要对每个不同的接口名配置一个映射，而且后台一旦增加接口，这里也要跟着加，每个映射的值还都是一样的，又麻烦又冗余。其实，webpack已经考虑了这一点，每一个映射规则的value可以是一个对象，并提供 pathRewrite 参数来重置请求的上下文。 复用一下上面的例子，只不过服务端稍有不同，服务端提供的接口没有统一的/api前缀，而是直接的接口名：/students、/classes、/grades 这个时候，proxy 可以这么配置： 12345678910devServer: &#123; proxy: &#123; &apos;/api&apos;: &#123; target: &apos;http://champyin.com:3000&apos;, pathRewrite: &#123; &apos;/api&apos;: &apos;&apos; &#125; &#125; &#125;&#125; 这样我们的前端请求依然保留/api前缀不用变，而在转发之前，这个前缀会自动被重置去掉。 现在我在前端依然这么发请求：xhr.open(‘GET, ‘/api/students’, true);即我发的请求完整url为 http://localhost:8000/api/students,而经过代理后的最终url为 http://champyin.com:3000/students 这样，就不用因为后台接口不规范，而影响我们的前端代码的质量了。 当然，这个只是在联调模式可以这么做，真正生产环境的时候，还是要后台统一规范，或者部署一个中间层做这种代理转发。 可以操控服务端代码的情况当你可以控制服务端代码时（比如自己mock数据），你还可以通过以下的方法避免跨域（变相地解决跨域） 2. 在dev-server内mock数据webpack-dev-server内部其实是自己起了一个express来做服务。webpack的devServer配置提供了一个before方法，在启动服务之前，这个方法会被执行，我们可以把我们mock数据的逻辑写在这里面。1234567devServer: &#123; before(app) &#123; app.get(&apos;/api/sdutents&apos;, (req, res) =&gt; &#123; res.json(&#123;name: &apos;zs&apos;, score: 100&#125;) &#125;) &#125;&#125; 这个before方法会传一个参数供我们使用，这个参数就是webpack-dev-server内部起的express对象。 重启前端工程时，我们的mock服务也就启动了。这时，我们的mock接口跟前端其实在同一服务也就是webpack-dev-server的express服务下，也就不存在跨域了。 2. 在服务端启动webpack假设后端我们的express mock接口代码长这样：12345678const express = require(&apos;express&apos;);let app = express();app.get(&apos;/api/students&apos;, (req, res) =&gt; &#123; res.json(&#123;name: &apos;zs&apos;, score: 100&#125;)&#125;)app.listen(3000, () =&gt; &#123; console.log(&apos;server is on 3000&apos;);&#125;); 现在我们要把webpack构建放到后端来起。在后端起webpack需要用到叫做webpack-dev-middleware的中间件，整体逻辑大致是：获取webpack模块 -&gt; 获取webpack配置文件 -&gt; 将配置文件传给webpack执行，获得compiler实例 -&gt; 把compiler实例传给webpack-dev-middleware中间件，然后整个交给express作为express中间件执行 -&gt; done!1234567891011121314// bin/www.js fileconst express = require(&apos;express&apos;);const webpack = require(&apos;webpack&apos;);const webpackDevMiddleware = require(&apos;webpack-dev-middleware&apos;);let webpackConf = require(&apos;../webpack.config.js&apos;);let compiler = webpack(webpackConf);let app = express();app.use(webpackDevMiddleWare(compiler));app.listen(3000, () =&gt; &#123; console.log(&apos;server is on 3000&apos;);&#125;); 现在启动前端工程就不是npm run dev了，而是node bin/www.js。 这时，我们的前端就跟后端复用了同一个服务，自然也就不存在跨域了。 其实这相当于在改后端了，不过这个后端是前端可以控制的，所以也算是前端的扩展了。不过，如果可以改后端的话，其实还可以直接在express里面通过设置请求头来实现跨域，不过这个就跟webpack没有关系了，就不在这里细讲了。 总结第一种方法是我们提倡的跨域配置，配置代理。首选推荐。第二和第三种方法其实是在你能控制后端工程的情况下，把前后端工程合并成一个工程了，区别是第二种方法相当于把后端接口移到前端工程来起，第三种方法是把前端工程构建移到后端工程来起。避免了跨域，也算是变相地解决跨域的方案吧，在某些轻量的工程里可以快速搭建调试环境。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es6-promise]]></title>
    <url>%2F2019%2F11%2F05%2Fes6-promise%2F</url>
    <content type="text"><![CDATA[自从2015年 ES6（ECMAScript 6）正式发布以来，许多JS新特性让我们的前端开发更加语意化，更加高效。在享受新特性给我们带来的便利的同时，在各类前端框架和业务代码满天飞的同时，我觉得仍有必要不间断地去了解和总结原生JS的底层机制、原理及其优缺点。就从Promise开始。 Promise总结基本语法123456789101112131415161718192021let p = new Promise((resolve, reject) =&gt; &#123; console.log(1) setTimeout(() =&gt; &#123; resolve(2); &#125;, 1000);&#125;)p.then(data =&gt; &#123; console.log(data); &#125;, err =&gt; &#123; console.log(err);&#125;)console.log(3);//输出：132其中 1 和 3 是立即输出，2 是1秒后输出。 Promise的本质它是一个类。它是异步编程的一种解决方案。它的链式调用方式，在一定程度上可以解决JS中的多层异步回调嵌套问题（也叫回调地狱）。 Promise的特征1 . 一个Promise对象有三个状态：pending，fulfilled，rejected。 只能当状态是pending时，这个状态才能改变，并且状态一旦发生改变，就不能再改变。 2 . Promise实例化时接受一个函数作为参数，这个函数会立即执行。 这个函数暴露两个参数，分别是resolve，reject，这两个参数同样也是函数。 3 . 每个Promise对象都有一个then方法。 4 . resolve和reject都接收一个参数，这个参数将被在内部进行一些必要处理，其返回结果会传到下一个then中。 5 . 必须在这个Promise实例中调用resolve或则reject或者throw new Error，才会往下走，即then中的方法才会被执行。 6 . 一个Promise对象可以多次then，也可以连续then（链式调用），每次then都会返回一个新的Promise对象。 7 . then也接收两个参数，是两个回调函数，分别对应处理成功和失败的业务。 8 . then的回调函数中，使用return进入下一个then的成功、使用throw new Error 等报错，进入下一个then的失败。不显示写return，则默认return undefined，也是进入下一个then的成功。 9 . then是微任务，所以then中的方法会在同步代码执行后再执行。 10 . 如果Promise实例中resolve了一个Promise，Promise内部会取这个Promise的then的结果，如果还是一个Promise，继续取，直到获得一个非Promise的值，然后把这个值返回。 11 . Promise的then可以穿透，即如果中间的then没有写成功或者失败的处理，则结果会一直往下传，直到有then处理。 Promise实例上的方法和静态方法Promise实例上的方法： then处理回调的函数。then的链式调用，是异步有序的，写在前面的会先执行。 catch本质是 .then(null, rejectCallback) 的别名，用于处理错误。 finallyES2018 中的新特性。不管Promise成功还是失败，都会执行的操作。 Promise静态方法： resolve将现有对象转为Promise对象的快捷方法。 reject产生一个状态为 rejected 的Promise实例。 all将多个Promise实例装包成一个Promise实例，同步获取多个异步操作的结果，只有所有Promise实例的状态都为 fulfilled，这个Promise才会成功，并且返回一个数组，里面按序存放异步操作的结果。只要一个Promise被reject，整个Promise都reject。 race将多个Promise实例包装成一个Promise实例，谁先改变状态，整个Promise就采用谁的状态和返回值。 any目前是一个stage3提案。接受一组Promise实例，如果谁先变成 fulfilled，整个Promise fulfilled，如果都 rejected，整个都失败。 Promise的缺点Promise不能彻底解决回调地狱，因为它也是基于回调来实现的。 解决方案：结合async+await，彻底解决异步回调地狱问题。 自己实现一版Promise现在的大部分IDE和浏览器都已经内置原生Promise，不过你也可以不使用原生Promise，选择自己写一个Promise。 但如果你的Promise想跟原生Promise混用，或者想让别人使用，最好先通过 promiseA+规范 的测试。 如何测试自己的Promise是否符合PromiseA+规范 step1. 在代码中添加测试代码在自己的 Promise.js 里，给Promise添加一个deferred静态方法，在里面new一个自己的Promise 实例，把自己的Promise实例和实例上的resolve、reject挂上去： 12345678Promise.deferred = () =&gt; &#123; let dfd = &#123;&#125;; dfd.promise = new Promise((resolve, reject) =&gt; &#123; dfd.resolve = resolve; dfd.reject = reject; &#125;) return dfd;&#125; step2. 安装 promsises-aplus-tests 插件 1npm i -D primises-aplus-tests step3. 运行脚本 123 npx promises-aplus-test ./ Promise.js &gt; npx 是 npm 8.5 以上具有的功能。 如果一切顺利，会在一片绿勾之后，得到872 passing (16s)这样的信息，这说明，你的Promise已经符合PromiseA+规范，即符合基本要求，可以放心使用了。 不间断补充更新中。 –GoodLuck!]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>promise</tag>
        <tag>es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git进阶之合并多次commit]]></title>
    <url>%2F2019%2F10%2F28%2Fgit%E8%BF%9B%E9%98%B6%E4%B9%8B%E5%90%88%E5%B9%B6%E5%A4%9A%E6%AC%A1commit%2F</url>
    <content type="text"><![CDATA[有的时候，完成一个功能，不是一时半会就可以完成的，但是为了保护代码不丢失，我们会把这次的修改先commit，而不着急push到远程。等到这个功能完全做好，再push。但是这样一来，就会有很多零碎的commit，这会使远程的commit显得很杂乱。于是必要的时候，我们会合并这些相近的commit为一个commit再push。当然了，如果你想合并远程的commit也是可以的，只是要跟团队提前说一声，免得有其他人也在跟你做同样的事情，那远程仓库就不知道会乱成什么样了。所以建议合并commit，尽量在push前。 Step： 1. git log 查看commit节点id1git log --oneline 参数--oneline可以让你的commit log在一行输出，比较紧凑，coimmit id也以简短的位数展示，比较便于查看。找到你要保留的那条commit的上一条commit（这样可以保证你要保留的那一条commit出现在pick清单的顶部），复制这条commit的id。 2. git rebase 变基1git rebase -i [commit_id] [commit_id]就放你在第1步复制的那个值。然后就会进入rebase界面，类似这样： 注意：观察头部的commit清单，确保你要保留的那条commit出现在内。一切顺利的话，它会出现在顶部第一条。 3. 修改 pick 为 squashvi指令i进入编辑模式，修改你不想保留的commit记录前的 pick 为 squash(或者s)。git 会把前面为 squash的commit记录与它的上一条记录合并为一条。 注意要确保第一条为 pick，因为squash的作用是把commit合并到上一个提交，所以必须保证至少第一个提交被pick。 如果你不小心把所有的pick都改为了s，然后保存退出，会收到一个错误提示：cannot &#39;squash&#39; without a previous commit。不要怕，根据它的下一个提示操作就可以了：12You can fix this with &apos;git rebase --edit-todo&apos; and then run &apos;git rebase --continue&apos;.Or you can abort the rebase with &apos;git rebase --abort&apos;. 尽管它提示了2种方法来处理，我还是推荐你使用git rebase --abort，然后重来一次rebase，这样最稳妥。 4. 处理合并后的commit message如果第3步顺利的话，esc之后，:进入指令模式，输入vi指令wq，保存并退出vi界面，然后会进入另一个vi界面，在这里它会把你合并的这些commit的日志列出来，便于你编辑。同样使用vi指令i进入编辑模式，编辑完后，esc+:+wq回车退出。然后会出现Successfully rebased and updated refs/heads/xxx.说明commit合并成功了。 5. 如果修改的是远程的commit，则强制push一把1git push -f 如果你还没push，只是处理本地的commit，则不需要这一步。否则，就需要把这次的rebase强制覆盖远程分支。 done！现在可以git log --oneline看下，是不是commit数量已经减少了，并且你指定的那些commit都合并为了一条，message就是你在第4步处理的内容。 GoodLuck！]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>rebase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Webpack error 之 TypeError: Cannot read property 'properties' of undefined]]></title>
    <url>%2F2019%2F10%2F17%2FWebpack-error-%E4%B9%8B-TypeError-Cannot-read-property-properties-of-undefined%2F</url>
    <content type="text"><![CDATA[老项目重新 npm install 的坑，问题原因比较隐蔽，记录一下。 操作背景 去年建的项目，webpack4.4.1，webpack-cli2.0.12。 今天在另一台电脑，把项目clone下来，然后npm install, 执行build打包的时候，立即报错。 两台电脑node环境相同。完整报错如下：123456789101112131415/node_modules/webpack-cli/bin/config-yargs.js:89 describe: optionsSchema.definitions.output.properties.path.description, ^TypeError: Cannot read property &apos;properties&apos; of undefined at module.exports (/Users/yinchuan/Documents/学习/学习笔记/test/code-lib/webpack-library-example/node_modules/webpack-cli/bin/config-yargs.js:89:48) at /Users/yinchuan/Documents/学习/学习笔记/test/code-lib/webpack-library-example/node_modules/webpack-cli/bin/webpack.js:60:27 at Object.&lt;anonymous&gt; (/Users/yinchuan/Documents/学习/学习笔记/test/code-lib/webpack-library-example/node_modules/webpack-cli/bin/webpack.js:515:3) at Module._compile (module.js:652:30) at Object.Module._extensions..js (module.js:663:10) at Module.load (module.js:565:32) at tryModuleLoad (module.js:505:12) at Function.Module._load (module.js:497:3) at Module.require (module.js:596:17) at require (internal/module.js:11:18) 问题分析 看提示，是webpack-cli报错，于是进webpack-cli相应目录查看 不知为啥没有获得 webapack 配置参数的 output 属性。 简单百度了一下，有人说是webpack和webpack-cli版本不对应导致，安装一下最新的webpack-cli即可解决。也没太注意，就直接重新安装了webpack-cli，为了webpack也跟它匹配，连webpack一起重装了： 1npm i --save-dev webpack webpack-cli 安装完就直接build了，但是还是报同样的错。 于是开始各种尝试，直接npx webpack用默认配置打包、用配置文件webpack.config.js打包、把工程简化到就一句console.log、把webpack配置精简到就entry和output… 排除了文件路径，代码逻辑问题，webpack和webpack-cli也都是最新的，还是没用。 最后再次百度，发现有人提到他把 webpack-cli 从2.x升级到3.x就好了，原因是 webpack 在 4.20.0 之后，需要 webpack-cli3.1.1 搭配使用。。。 https://github.com/webpack/webpack/releases/tag/v4.20.0 我突然想到 npm package 的版本前面的那个符号有限制版本的作用，可能我以为我的webpack-cli是最新的，但其实并没有呢？ 赶紧去检查了下我的本地webpack和webpack-cli版本，OHG！果然！12&quot;webpack&quot;: &quot;^4.41.2&quot;,&quot;webpack-cli&quot;: &quot;^2.1.5&quot; 刚才的重新安装后，webpack-cli并没有更新到3.x。 问题原因所以问题原因终于找到：webpack4.20.0之后，需要 webpack-cli3.1.1 搭配使用，而现在是webpack4.41.2 + webpack-cli2.1.5，所以开始报开头贴出来的错。 而我以为我装了最新的实际却没有给我装最新的cli，原因是：坑爹的 ^ ，这个符号会限制你在不指定package版本的install时，安装的是不超过当前大版本的最新版本。所以&quot;webpack-cli&quot;: &quot;^2.0.12&quot;这句，限制了我直接install的webpack-cli版本不会超过3.0.0 。 更多npm包版本的语意可以到官网 https://docs.npmjs.com/misc/semver 查阅。 解决强制安装：npm i -D webpack-cli@latest或者在 package.json 删除&quot;webpack-cli&quot;: &quot;^2.0.12&quot;这句后，再使用普通安装：npm i -D webpack-cli。 再运行npm run build 打包，OK了～ 总结 不要以为重新安装一下就一定是安装最新的包。 不要忽视 npm package 的版本号前缀，它的语意很重要。 一定要关注webpack这些打包工具的release动态和特性变化，这对你的项目中如果改变了webpack的版本导致的问题很有帮助。 webpack 4.20.0 以上，需要 webpack-cli3.1.1 搭配使用。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>webpack-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node.js操作数据库之MongoDB+mongoose篇]]></title>
    <url>%2F2019%2F10%2F10%2Fnode.js%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8BMongoDB%2Bmongoose%E7%AF%87%2F</url>
    <content type="text"><![CDATA[node.js 的出现，使得用前端语法(javascript)开发后台服务成为可能，越来越多的前端因此因此接触后端，甚至转向全栈发展。后端开发少不了数据库的操作。MongoDB 是一个基于分布式文件存储的开源数据库系统。本文为大家详细介绍了如何用 node.js + mongoose 玩转 MongoDB 。希望能帮到有需要的人。 由于我用Mac开发，以下所有操作都是在Mac下进行。 一、 环境搭建安装Node.js 有 node 环境的可以跳过。 nodejs官网提供了 macOS 安装包，直接下载安装即可。现在 nodejs 稳定版已经到了 12.11.1 。 安装MongoDBMongoDB 是为现代应用程序开发人员和云时代构建的基于文档的通用分布式数据库。 上个月（9月） macOS 包管理器 Homebrew 宣布移除 MongoDB 。原因是去年10月 MongoDB 宣布将其开源许可证从 GNU AGPLv3 切换到 SSPL（Server Side Public License），以此回应 AWS 等云厂商将 MongoDB 以服务的形式提供给用户而没有回馈社区的行为，MongoDB 希望从软件即服务上获取收入。Homebrew 认为 MongoDB 已经不再属于开源范畴… 言归正传，由于上述原因，我们不能直接使用 brew install mongodb 来安装 MongoDB 了。好在 MongoDB 自己维护了一个定制化的 Homebrew tap。并在 Install MongoDB Community Edition 更新了安装步骤。 Mac下 MongoDB 的最新安装步骤如下： 1. 首先安装 HomebrewHomebrew 是 macOS 的包管理器。因为 OSX 默认不包含 Homebrew brew 包，所以要先安装，已经安装过的可以跳过。1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装过程会有点长，终端输出信息超过一屏，这里我只截取了头尾两部分。 2. 然后获取下 MongoDB Homebrew Tap1brew tap mongodb/brew 3. 最后安装 MongoDB CE（社区版）1brew install mongodb-community@4.2 现在你的 Mac 上就已经安装好 MongoDB 环境了。 安装mongoose node.js 是可以直接操作 MongoDB 的，但是通过 MongoDB 命令语法直接编写 MongoDB 验证、数据类型转换和业务逻辑模版比较繁琐。所以我们使用了 mongoose。 mongoose 是 MongoDB 的一个对象模型工具，它对 MongoDB 的常用方法进行了封装，让 node.js 操作 MongoDB 更加优雅简洁。 刚才的 node.js 和 MongoDB 都是安装在全局环境，mongoose 则是安装在你的项目下：12cd your-projectnpm i -S mongoose 现在，你的开发环境就已经全部安装好了。 二、启动MongoDB服务要操作 MongoDB ，首先要启动它。有两种方式启动 MongoDB 服务： 1. 在前台运行1mongod --config /usr/local/etc/mongod.conf 前台运行的好处就是，可以查看一些反馈和日志，便于调试。另外如果要关闭服务，只需要在终端按 control + c 键即可。 2. 也可以作为 macOS 服务，在后台运行1brew services start mongodb-community@4.2 后台运行的好处是开机就自动启动，随时可以使用。 这种启动方式，如果要关闭服务，可以通过 stop 命令： 1brew services stop mongodb-community@4.2 现在，你的 MongoDB 数据库已经开启了。 三、操作MongoDB操作之前先解释一下MongoDB和mongoose里的一些核心概念。MongoDB MongoDB 中的数据记录是一种 BSON 格式的文件（BSON是一种用二进制描述的JSON文件格式）。 MongoDB 将文件存储在集合中，将集合存储在数据库中。 MongoDB 的数据库、集合都不用手动创建。 集合collection: 相当于关系型数据库中的表table。 文件document: MongoDB 的数据记录单位，相当于关系型数据库中的记录row。 mongoose schema: 在 mongoose 中，所有的东西都来源于一个 schema，每个schema 映射了一个 MongoDB 的集合，它定义了这个集合中的文档的骨架。 model: 一个文件的构造器，通过编译schema得到，一个model的实例就是一个文件，model负责从 MongoDB 数据库中创建和读取文档。 更多mongoose概念可以在mongoose guide中查阅。 数据库操作： 1. 使用 mongoose 连接 MongoDB在项目中创建 connection.js 文件1234567891011121314151617181920// connection.js fileconst mongoose = require(&apos;mongoose&apos;);const conn = mongoose.createConnection( // 连接地址，MongoDB 的服务端口为27017 // dbtest是我要使用的数据库名，当往其中写数据时，MongoDB 会自动创建一个名为dbtest的数据库，不用事先手动创建。 &apos;mongodb://127.0.0.1:27017/dbtest&apos;, // 一些兼容配置，必须加，你不写运行的时候会提示你加。 &#123; useNewUrlParser: true, useUnifiedTopology: true &#125;)conn.on(&apos;open&apos;, () =&gt; &#123; console.log(&apos;打开 mongodb 连接&apos;);&#125;)conn.on(&apos;err&apos;, (err) =&gt; &#123; console.log(&apos;err:&apos; + err);&#125;) 运行：1node conection.js 可以看到打印出“打开 mongodb 连接”，并且运行一直在等待。 这说明现在已经成功连接上 MongoDB 了，接下来可以开始操作数据库了。 为了方便扩展起见，我们先对 connection.js 改造一下，让它作为模块导出，这样就可以在其他地方导入复用了。1234567891011121314151617// connection.js fileconst mongoose = require(&apos;mongoose&apos;);const conn = mongoose.createConnection( &apos;mongodb://127.0.0.1:27017/dbtest&apos;, &#123; useNewUrlParser: true, useUnifiedTopology: true &#125;)conn.on(&apos;open&apos;, () =&gt; &#123; console.log(&apos;打开 mongodb 连接&apos;);&#125;)conn.on(&apos;err&apos;, (err) =&gt; &#123; console.log(&apos;err:&apos; + err);&#125;)module.exports = conn; //commonJs 语法，导出conn模块。 2. 添加操作 save | create 方法新建insert.js文件1234567891011121314151617181920212223242526// insert.js filelet mongoose = require(&apos;mongoose&apos;);// 导入连接模块let connection = require(&apos;./connection&apos;);// 创建schemalet StudentSchema = new mongoose.Schema(&#123; name: String, age: Number&#125;)// 通过connection和schema创建modellet StudentModel = connection.model(&apos;Student&apos;, StudentSchema);// 通过实例化model创建文档let studentDoc = new StudentModel(&#123; name: &apos;zhangsan&apos;, age: 20&#125;)// 将文档插入到数据库，save方法返回一个Promise对象。studentDoc.save().then((doc) =&gt; &#123; console.log(doc)&#125;) 运行：1node insert.js 为了更直观看到操作数据库的结果，推荐大家安装一个数据库可视化工具：Robo3T，下载mac版安装即可。 点击 Robo3T 左上角连接我们的数据库后，可以看到 MongoDB 自动帮我们生成了数据库和集合，并且已经插入了一条记录： 或者还可以直接通过Model的create方法直接插入数据，返回的也是一个Promise：123456StudentModel.create(&#123; name: &apos;lisi&apos;, age: 19&#125;).then((doc) =&gt; &#123; console.log(doc)&#125;) 3. 读取操作 find 方法为更加合理复用代码，我们先把 StudentSchema 和 StudentModel 抽离出来： 新建StudentSchema.js文件123456789// StudentSchema.js fileconst mongoose = require(&apos;mongoose&apos;);let StudentSchema = mongoose.Schema(&#123; name: String, age: Number&#125;)module.exports = StudentSchema; 新建StudentModel.js文件1234567// StudentModel.js fileconst connection = require(&apos;./connection&apos;);const StudentSchema = require(&apos;./StudentSchema&apos;);let StudentModel = connection.model(&apos;Student&apos;, StudentSchema);module.exports = StudentModel; 然后新建query.js文件1234567// query.js fileconst StudentModel = require(&apos;./StudentModel&apos;);// 富查询条件，对象格式，键值对，下面为查询 name 为 lisi 的记录StudentModel.find(&#123;name: &apos;lisi&apos;&#125;).then(doc =&gt; &#123; console.log(doc);&#125;) 运行1node query.js 可以看到name为“lisi”的记录被打印了出来。 如果想查询整个集合：1234// 不放查询条件即查询所有的记录StudentModel.find(&#123;&#125;).then(doc =&gt; &#123; console.log(doc);&#125;) 可以看到集合中的所有记录被打印了出来。 4. 更新操作 update|updateOne|updateMany 方法 新建update.js文件12345678// update.js fileconst StudentModel = require(&apos;./StudentModel&apos;);// update 方法接收2个参数，第一个是查询条件，第二个是修改的值// 下面把name为lisi的记录，将他的age修改为80StudentModel.update(&#123;name: &apos;lisi&apos;&#125;, &#123;age: 80&#125;).then(result =&gt; &#123; console.log(result)&#125;) 进入 Robo3T，可以看到数据被更改（切换到表格模式更加直观）： 不过在终端，提示DeprecationWarning: collection.update is deprecated. Use updateOne, updateMany, or bulkWrite instead. 意思是建议我们使用 updateOne、updateMany或者bulkWrite update 更新查询到的所有结果，方法已经不提倡使用，已被updateMany替代。updateOne 如果查询到多条结果，只更新第一条记录。upateMany 更新查询到的所有结果。bulkWrite 提供可控执行顺序的批量写操作。 为了代码的健壮性，我们应该根据建议将update方法换成updateMany方法。 另外，终端的输出{ n: 1, nModified: 1, ok: 1 }的意思是： “n: 1”：查询到1条记录。 “nModified: 1”：需要修改1条记录。（如果修改值和原始值相同，则需要修改的就是0条） “ok: 1”：修改成功1条。 5. 删除操作 remove|removeOne|removeMany|bulkWrite 方法 新建remote.js文件12345678// remove.js fileconst StudentModel = require(&apos;./StudentModel&apos;);// delete 方法接收1个参数，就是查询条件// 下面把name为lisi的记录删除StudentModel.remove(&#123;name:&apos;lisi&apos;&#125;).then((result) =&gt; &#123; console.log(result);&#125;); 进入 Robo3T，可以看到集合里已经没有name为lisi的记录了： 在看终端的输出，跟update类似，也提示建议使用新的方法代替。 意思是建议我们使用 removeOne、removeMany或者bulkWrite remove 删除查询到所有结果，方法已经不提倡使用，已被removeMany替代。removeOne 如果查询到多条结果，只删除第一条记录。removeMany 删除查询到所有结果。bulkWrite 提供可控执行顺序的批量写操作。 另外，终端的输出{ n: 1, ok: 1, deletedCount: 1 }的意思跟update的类似，就不累述了。 现在我们已经成功地对 MongoDB 数据库进行了 CRUD（添加、读取、更新、删除）操作。欢呼～ 更多高级操作，可以到mongoose API 文档中查阅。 四、总结梳理一下，主要讲了这些内容： node.js+MongoDB+mongoose 在Mac下的环境搭建，注意使用最新的 MongoDB 的安装方式。 在Mac下如何启动和关闭 MongoDB 服务。 介绍了 MongoDB 和 mongoose 的基本核心概念。 使用 mongoose 连接以及增删改查 MongoDB 操作。可以使用 Robo3T 来更直观地观察数据库。 前端也能玩转数据库开发。欢迎交流～ 文章源码地址：https://github.com/yc111/mongodb-demo 相关网站：Homebrew官网MongoDB官网monggose官网Robo3T官网macOS 包管理器 Homebrew 移除 MongoDB –欢迎转载，转载请注明出处：https://champyin.com/2019/10/10/node.js%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8BMongoDB+mongoose%E7%AF%87/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>node</tag>
        <tag>MongoDB</tag>
        <tag>mongoose</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github项目徽标]]></title>
    <url>%2F2019%2F10%2F05%2Fgithub%E9%A1%B9%E7%9B%AE%E5%BE%BD%E6%A0%87%2F</url>
    <content type="text"><![CDATA[GitHub徽标，GitHub Badge，你也可以叫它徽章。就是在项目README中经常看到的那些表明构建状态或者版本等信息的小图标。就像这样：这些好看的小图标不仅简洁美观，而且包含了清晰易读的信息，在README中使用小徽标能够为自己的项目说明增色不少！如何给自己的项目加上小徽标呢？ 一、关于徽标 徽标图片分左右两部分，左边是标题，右边是内容，就像是键值对。 GitHub徽标官网是 https://shields.io/ 图标规范 二、如何添加动态徽标动态徽标是指如果项目状态发生变化，会自动更新状态的徽标，它能保证用户看到的信息就是项目当前的真实状态。 常用的动态徽标有： 持续集成状态 项目版本信息 代码测试覆盖率 项目下载量 贡献者统计等等 这里以Travis CI 的持续集成状态为例。没有接触过 Travis CI的可以看我的上一篇文章 利用Travis CI+GitHub实现持续集成和自动部署 登录 Travis CI，进入配置过构建的项目，在项目名称的右边有个 build passing 或者 build failing 徽标。 点击它，在弹出框中，就可以看到 Travis CI 为你提供的各种格式的徽章地址了。 你可以根据需要选择格式，imageUrl格式大概是这个样子： 1https://www.travis-ci.org/&#123;your-name&#125;/&#123;your-repo-name&#125;.svg?branch=master markdown格式大概是这个样子： 1[![Build Status](https://www.travis-ci.org/&#123;your-name&#125;/&#123;your-repo-name&#125;.svg?branch=master)](https://www.travis-ci.org/&#123;your-name&#125;/&#123;your-repo-name&#125;) 简单起见，我选择 markdown 格式。将内容复制后，打开项目的README文档，在顶部位置粘贴。 经过前4步，小徽章就搞定了。将README文档push到远程，刷新GitHub页面，过一会，就会看到README上面已经有了持续集成状态图标了。之所以要过一会才加载出来，是因为它要动态从 Travis CI 平台获取状态。 三、如何自定义徽标shields.io 提供了自定义徽标的功能。 徽标图标格式1https://img.shields.io/badge/&#123;徽标标题&#125;-&#123;徽标内容&#125;-&#123;徽标颜色&#125;.svg 带链接的徽标1[![](https://img.shields.io/badge/&#123;徽标标题&#125;-&#123;徽标内容&#125;-&#123;徽标颜色&#125;.svg)](&#123;linkUrl&#125;) 变量说明 徽标标题：徽标左边的文字 徽标内容：徽标右边的文字 徽标颜色：徽标右边的背景颜色，可以是颜色的16进制值，也可以是颜色英文。支持的颜色英文如下： 变量之间用 - 连接。将这3个变量替换为你需要的内容即可生成一个自定义的徽标。 举个栗子例如下面这个是我的博客的徽标：1[![](https://img.shields.io/badge/blog-@champyin-red.svg)](https://champyin.com) 效果：点击该徽标会打开对应的url地址，即直接跳到我的博客。 进阶除了上面所说的3个参数，shields.io 还提供了一些 query string 来控制徽标样式。使用方式跟浏览器 URL 的 query string 一致：徽标图标地址?{参数名}={参数值}，多个参数用 &amp; 连接：1https://img.shields.io/badge/&#123;徽标标题&#125;-&#123;徽标内容&#125;-&#123;徽标颜色&#125;.svg?&#123;参数名1&#125;=&#123;参数值1&#125;&amp;&#123;参数名2&#125;=&#123;参数值2&#125; 常用的 query string 参数有： style：控制徽标主题样式，style的值可以是： plastic | flat | flat-square | social 。 label：用来强制覆盖原有徽标的标题文字。 colorA：控制左半部分背景颜色，只能用16进制颜色值作为参数，不能使用颜色英文。 colorB：控制右半部分背景颜色。 以style参数为例1![](https://img.shields.io/badge/blog-@champyin-orange.svg?style=plastic) plastic 立体效果： 1![](https://img.shields.io/badge/blog-@champyin-yellow.svg?style=flat) flat 扁平化效果，也是默认效果： 1![](https://img.shields.io/badge/blog-@champyin-success.svg?style=flat-square) flat-square 扁平 + 去圆角效果： 1![](https://img.shields.io/badge/blog-@champyin-blue.svg?style=social) social 社交样式效果： 还有很多参数，用法类似。更多信息可以到shields.io查阅。 总结徽标简洁又不失内容，使用简单又不失灵活。如果你的项目还没有使用过徽标，那么不妨试试给你的项目中试试添加一个，你会爱上它。 建议：徽标的使用也是门艺术，徽标不是越多越好。应该根据项目性质合理添加，放的太多会失去徽标的简洁本意。 –GOOD LUCK！ 欢迎转载，转载请注明出处：https://champyin.com/2019/10/05/github%E9%A1%B9%E7%9B%AE%E5%BE%BD%E6%A0%87/]]></content>
      <categories>
        <category>工具</category>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>badge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Travis CI+GitHub实现持续集成和自动部署]]></title>
    <url>%2F2019%2F09%2F27%2F%E5%88%A9%E7%94%A8Travis-CI-GitHub%E5%AE%9E%E7%8E%B0%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E5%92%8C%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[这次的主题是如何利用Travis CI+GitHub实现持续集成和自动部署，通过我的一些研究和实战经验，希望可以帮到有需要的朋友。 如果你手动部署过项目，一定会深感持续集成的必要性，因为手动部署实在又繁琐又耗时又没技术含量，九段部署流程基本固定，依然容易出错。 如果你很熟悉持续集成，一定会同意这样的观点：“使用它已经成为一种标配”。 什么是持续集成Continuous Integration(CI) is a development practice that requires developers to integrate code into a shared repository several times a day. Each check-in is then verified by an automated build, allowing teams to detect problems early.———ThoughtWorks翻译过来就是：持续集成是一个开发行为，它要求开发者每天多次将代码集成到一个共享的仓库，每次提交都会被自动构建所检查，团队可因此提前检测出问题。 持续集成的工具非常多，例如用java语言开发的Jenkins，由于其可以在多台机器上进行分布式地构建和负载测试的特性，很多大公司都在使用它。 但是Jenkins的不加修饰的界面界面让我有些嫌弃… 随着GitHub的发展，出现了越来越多支持GitHub的CI/CD产品。在GitHub市场上，可以看到，已经支持的持续集成服务提供商已超过300多家。详情。选择Travis CI，是因为身边很多朋友的推荐。 什么是Travis CITravis CI是用Ruby语言开发的一个开源的分布式持续集成服务，用于自动构建和测试在GitHub托管的项目。支持包括Javascript、Node.js、Ruby等20多种程序语言。对于开源项目免费提供CI服务。你也可以买他的收费版，享受更多的服务。 Travis CI目前有两个官网，分别是 https://travis-ci.org 和 https://travis-ci.com 。https://travis-ci.org 是旧平台，已经逐渐往新平台 https://travis-ci.com 上迁移了。对于私有仓库的免费自动构建，Travis CI在新平台上给予了支持。 GitHub-&gt;Marketplace-&gt;Apps-&gt;Travis CI 一、获取GitHub Access TokenTravis CI在自动部署的时候，需要push内容到仓库的某个分支，而访问GitHub仓库需要用户授权，授权方式就是用户提供 Access Token 给Travis CI。获取token的位置：GitHub-&gt;Settings-&gt;Developer Settings-&gt;Personal access tokens。勾选repo下的所有项，以及user下的user:email后，生成一个token，复制token值。 注意：这个token只有现在可以看到，再次进入就看不到了，而且是再也看不到了，忘记了就只能重新生成了，所以要记住保管好。 二、使用GitHub账号登录Travis进入Travis官网，用GitHub账号登录。（我目前使用的是它的旧平台） 登录后，会在Travis里看到自己GitHub账号下所有的public open source repo。 三、开启对项目的监控选择目标项目，打开右侧开关。 四、配置travis 点击开关右侧Settings，进入该项目的travis配置页 勾选触发条件 设置全局变量 第一步获取的access token，必须设置设置好的变量可以在配置文件中以 ${变量名}来引用。 五、在项目根目录添加.travis.yml配置文件 注意文件名以.开头。 Travis CI的一次构建分两个步骤： install安装，安装任何所需的依赖 script脚本，运行构建脚本 Travis CI提供了一些构建生命周期的“钩子” 完整的 Travis CI 构建生命周期： OPTIONAL Install apt addons OPTIONAL Install cache components before_install install before_script script OPTIONAL before_cache(for cleaning up cache) after_success or after_failure OPTIONAL before_deploy OPTIONAL deploy OPTIONAL after_deploy after_script 在 before_install、before_script之前，或者after_script之后，都可以运行自定义命令，详细资料可参考官方文档：Job Lifecycle 我在footprint项目中的.travis.yml完整配置：1234567891011121314151617181920212223242526272829303132333435language: node_js #设置语言node_js: &quot;10.16.3&quot; #设置语言版本cache: directories: - node_modules #缓存依赖# S: Build Lifecycleinstall: - npm iscript: - npm run buildafter_script前5句是把部署分支的.git文件夹保护起来，用于保留历史部署的commit日志，否则部署分支永远只有一条commit记录。#命令里面的变量都是在Travis CI里配置过的。after_script: - git clone https://$&#123;GH_REF&#125; .temp - cd .temp - git checkout gh-pages - cd ../ - mv .temp/.git dist - cd dist - git config user.name &quot;$&#123;U_NAME&#125;&quot; - git config user.email &quot;$&#123;U_EMAIL&#125;&quot; - git add . - git commit -m &quot;:construction_worker:- Build &amp; Deploy by Travis CI&quot; - git push --force --quiet &quot;https://$&#123;Travis_Token&#125;@$&#123;GH_REF&#125;&quot; gh-pages:$&#123;D_BRANCH&#125;# E: Build LifeCycle# 只有指定的分支提交时才会运行脚本branches: only: - master Done！将 .travis.yml push 到远程，可以看到 travis 开始构建编译了。并且之后每次push代码，travis 都会自动执行.travis.yml里配置的脚本任务了。 自动编译： 构建完，travis 会根据我的配置，自动部署到 GitHub： And One More Thing构建成功后，我们就可以在自己的GitHub项目里添加build徽章了。方法：在Travis里，点击项目右侧的徽章，即可获取小徽章地址，将地址放在README.md文档中即可。效果： –GOOD LUCK！ 欢迎转载，转载请注明出处：https://champyin.com/2019/09/27/%E5%88%A9%E7%94%A8Travis-CI-GitHub%E5%AE%9E%E7%8E%B0%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E5%92%8C%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/#more]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>travis</tag>
        <tag>CI/CD</tag>
        <tag>yml</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用echarts展示旅行足迹]]></title>
    <url>%2F2019%2F09%2F27%2F%E5%88%A9%E7%94%A8echarts%E5%B1%95%E7%A4%BA%E6%97%85%E8%A1%8C%E8%B6%B3%E8%BF%B9%2F</url>
    <content type="text"><![CDATA[一直有个环游世界的梦，周游列国，体验不同国家的人类文明，寻山访水，体验造物主大自然的伟大造化。毕竟人生不止眼前的苟且，还有诗和远方。这么多年以来，陆续走过了一些地方，每到一个地方，都让我离梦想又近了一些。虽然我知道这比起环游世界来说，还差不知道多少个山头，但是我一直在往这个梦努力，靠近。希望终有一天，我可以笑着对自己说，你做到了！ 6年前，因为工作的原因，我接触过地图应用的开发，从那时起，我对地图的热爱就埋在了心底。今年年中我带爸妈旅了旅游，去了一些我没去过的地方，我好想有个地图可以让我点亮一下，记录一下我到过的新的“领土”。搜了下市面上已经存在的地图应用，都不是我想要的，唯一比较符合我的需求的是百度旅游里面的一个小功能，叫做足迹地图，但是似乎早就停止了维护，数据停留在2016年。。。 找不到趁手的工具，那就自己打造一把。是啊，为什么不自己开发一个呢？说干就干。 工程搭建首先用 cyt-cli 快速搭建项目框架。cyt-cli地址 cyt-cli 是一款可以快速创建前端工程的脚手架，具有比较完善的webpack4配置，目前支持纯js、vue、react等语言版本。如果没有安装 cyt-cli ，先全局安装一下：npm i -g cyt-cli。 123456cyt-cli create footprint✔ fetching template ...? please choose a template to create roject (Use arrow keys)❯ swan-template swan-vue-template swan-react-template 因为想快速做出雏形来，所以使用最简单的模版就行，选择第一个 swan-template。等待一会，工程就搭建好了。生成的工程目录：123456789101112131415161718192021|--build/ # webpack配置文件| |-- webpack.base.js| |-- webpack.dev.js| |-- webpack.prod.js|--public/ # 首页模版| |-- index.html|--src/| |-- assets/ # 静态资源，比如中国地图数据| |-- components/ # 项目组件| | |-- foo.js| | |-- bar.js| |-- icon/ # 字体图标| |-- images/ # 图片资源| |-- theme/ # 样式文件| |-- index.js # 项目入口|--.babel.js # babel配置|--.browserslistrc.json # 浏览器支持规则|--.gitignore |--package.json|--postcss.config.js # postcss插件配置|--README.md 安装一下依赖包。12cd footprintnpm i 地图选型地图展示我选择了 echarts。 echarts官网1npm i --save echarts 应用开发我的核心需求很简单，就是可以把我去过的国家、省、市在地图上展示出来即可。先实现国内的省，开发逻辑很简单： 1.引入echarts按需引用1234567import echarts from &apos;echarts/lib/echarts&apos;;import &apos;echarts/lib/chart/map&apos;;import &apos;echarts/lib/component/tooltip&apos;;import &apos;echarts/lib/component/title&apos;;import &apos;echarts/lib/component/visualMap&apos;;import &apos;echarts/lib/component/legend&apos;;import &apos;echarts/lib/component/toolbox&apos;; 2.处理用户数据给series的data用。123456789101112131415161718192021222324252627282930313233let handleData = function(rawdata) &#123; rowData.forEach(item =&gt; &#123; item.value = FREQUENCY[item.value] if (item.value !== NEVER) &#123; item.label = &#123; show: true, color: LEBEL_COLOR &#125; &#125; if (item.value === NEVER) &#123; never.push(item); &#125; else if (item.value === ONECE) &#123; onece.push(item); &#125; else if (item.value === AFEWTIMES) &#123; afewtimes.push(item); &#125; else &#123; usually.push(item); &#125; &#125;); series = [usually, afewtimes, onece, never].map((item, index) =&gt; &#123; let temp = &#123; type: &apos;map&apos;, map: mapType, roam: true, itemStyle: &#123; emphasis: &#123; label: &#123; show: true &#125; &#125;, areaColor: &apos;#fff&apos; &#125; &#125;; temp.name = legendData[index]; temp.data = item; return temp; &#125;)&#125;handleData(userData); 3.注册mapecharts有个registerMap方法，echarts.registerMap(mapName, geoJson, specialAreas).123- mapName：地图名称，一定要与option-&gt;series-&gt;map对应的值相同。- geoJson：GeoJson格式的数据，具体格式见 http://geojson.org/。- specialAreas：可选。将地图中的部分区域缩放到合适的位置，可以使得整个地图的显示更加好看。 geoJson是地理信息数据，一般都很大，当然通过异步获取。123456util.get(&apos;assets/china.json&apos;).then(data =&gt; &#123; let chinaJson = data; myChart.hideLoading(); // 注册地图 echarts.registerMap(mapName, chinaJson, &#123;&#125;)&#125;) ECharts3提供的矢量地图数据，在4版本后已经不提供下载服务了。官网的解释是“由于部分数据不符合国家《测绘法》规定”。不过，只要不商用，这些矢量数据还是可以使用的。有需要可以到我这里获取https://github.com/yc111/echarts3-geojson 4.配置option显示地图注册地图后进行其他配置123456789101112// 指定图表的配置项和数据let option = &#123; color: _color, title: _title, tooltip: _tooltip, legend: _legend, visualMap: _visualMap, toolbox: _toolbox, series: series&#125;;// 使用刚指定的配置项和数据显示图表myChart.setOption(option); 添加Travis CI持续集成花了大概一天时间，雏形做好（感觉很大一部分时间在调地图颜色…）。我把项目部署在了github page上，但是每次build之后，都要手动部署，太麻烦。 于是我用 Travis CI 给项目做了持续集成，现在只要代码一提交，就会自动部署了。 具体关于Travis的详细配置，可以参考我的另一篇文章：利用Travis CI+GitHub实现持续集成和自动部署 效果预览项目预览地址：http://champyin.com/footprint/暂时还比较简陋，并且只支持省。以后我会把世界地图，和城市地图都加进来（毕竟也是出过境的人，哈哈），实现地图下钻，并且优化用户数据设置，不断完善下去。 项目源码地址：https://github.com/yc111/footprint欢迎star。如果你喜欢，可以fork本项目，然后打造属于你自己的足迹应用。 –欢迎转载，转载请注明出处：https://champyin.com/2019/09/27/%E5%88%A9%E7%94%A8echarts%E5%B1%95%E7%A4%BA%E6%97%85%E8%A1%8C%E8%B6%B3%E8%BF%B9/ 本文同步发表于：利用echarts展示旅行足迹 | 掘金]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>echarts</tag>
        <tag>map</tag>
        <tag>footprint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode中如何使编辑器根据屏幕宽度自动换行]]></title>
    <url>%2F2019%2F09%2F20%2Fvscode%E4%B8%AD%E5%A6%82%E4%BD%95%E4%BD%BF%E7%BC%96%E8%BE%91%E5%99%A8%E6%A0%B9%E6%8D%AE%E5%B1%8F%E5%B9%95%E5%AE%BD%E5%BA%A6%E8%87%AA%E5%8A%A8%E6%8D%A2%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[vscode中默认是不会自动换行的，也就是说当你查看一个压缩后的代码后，只会显示一行。。。很难看出内容的多少也不利于查找定位内容。 在vscode中可以设置是否自动换行，进入：1Code -&gt; Preference -&gt; Settings 然后在配置界面，搜索 work-wrap，找到 Editor: Work Wrap 选项： 将off改成on即可。 –GoodLuck!]]></content>
      <categories>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何配置多个ssh key]]></title>
    <url>%2F2019%2F08%2F29%2F%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAssh-key%2F</url>
    <content type="text"><![CDATA[我们都知道在使用git管理代码时，要推送代码到远程仓库时，为了不想每次都输入账号密码，会配置一下ssh key。但是如果你有多个github账号，或者同时还有gitlab或者是gitee账号，我在推送到这三个账号的仓库都不想输入用户名密码，可不可以把github上使用的ssh key跟其他的账号共享呢？我没有这样试过，不过即便是可以，也不太安全吧。最好的做法就是为这些账号分别创建ssh key，分别配置。 配置单个SSH key，可以参考：配置git环境之设置SSH key。而配置多个SSH key未必都熟悉。其实方法也很简单： 1. 生成ssh key第一个，给github用1ssh-keygen -t rsa -C &apos;xxx@abc.com&apos; -f ~/.ssh/github_id_rsa 第二个，给gitee用1ssh-keygen -t rsa -C &apos;xxx@edf.com&apos; -f ~/.ssh/gitee_id_rsa 由于指定了文件名，可以一路回车，不用输入密码。然后～/.ssh目录下会出现4个文件：1234github_id_rsagithub_id_rsa.pubgitee_id_rsagitee_id_rsa.pub 2. 在～/.ssh 目录下创建config文件。打开～/.ssh目录1open ~/.ssh 编辑config文件，写入：1234567891011# githubHost github.com # host名字可以随意，自己能识别就好，我这里直接使用了网站域名HostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/github_id_rsa# giteeHost my.gitee.comHostName gitee.comPreferredAuthentications publickeyIdentityFile ~/.ssh/gitee_id_rsa 3. 将为不同账号生成的公钥，填入各自网站的ssh key配置中。可以通过cat查看公钥内容1cat ~/.ssh/github_id_rsa.pub 4. 检测配置成没成功检测方法：ssh -T git@Host, Host 就是你之前在config文件中配置的Host 的值。检测github的1ssh -T git@github.com 检测gitee的1ssh -T git@my.gitee.com 如果有提示问要不要把这个RSA host key 添加到 konwn_host 列表中，选择yes。最后如果看到类似如下的提示，说明配置成功：1Hi xxxx! You&apos;ve successfully authenticated,but...... access. 搞定！ 科普：SSH：Secure Shell，是建立在应用层基础上的安全协议。github要求推送代码的用户是合法的，所以每次推送都需要输入账号和密码，用于验证你是否为合法用户，为了省去每次都要输入密码的步骤，采用ssh公钥秘钥，也就是ssh key来验证，公钥放到github上，推送代码时，git会检测你本地的私钥是否跟github上的公钥配对。ssh key可以理解为你的身份标识，公钥放在github上表明你是这个项目的一个开发人员，公钥匙可以被截获的，但是私钥在本地别人就无法截获，ssh key可以保证每次传输都是安全的。 Have a nice day!]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm link详解]]></title>
    <url>%2F2019%2F08%2F27%2Fnpm-link%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[npm install 可以把发布在npmjs平台上的模块包下载到本地，npm istall -g 可以把包下下来的同时，还帮我们配置好全局变量，让我们可以直接使用命令而不是通过node来执行或者配置package.json 的script脚本来run。但这仅限于已经发布的包，那对于未发布的包，要怎么测试使用呢？总不能把一个未经测试的包发布出去然后install下来这样测试吧，这样npm上面的包谁还敢用。所以npm上的包一定只能放经过测试考验的比较完善的包。而包的本地测试，就需要通过npm的一个命令了：npm link。 原理npm link 可以帮助我们模拟包安装后的状态，它会在系统中做一个快捷方式映射，让本地的包就好像install过一样这么使用。 在mac中，我们在终端可以直接敲的命令，其实是在执行/usr/local/bin目录下的脚本，这个目录可以认为是我们的全局命令所在的地方。 而当我们在npm install -g的时候，其实是将相关文件安装在/usr/local/lib/node_modules目录下，而同时在全局命令/usr/local/bin目录下会有一个映射脚本，将其指向lib下的真实文件。这么做的好处是，可以在保证只有一份可执行文件的前提下，给命令取别名。 同样的，npm link 做的事情也是一样，唯一的区别是，它在lib下的 node_modules 里不是存的真实的文件，而是存了一个快捷方式，指向你当前执行 npm link 的目录。如果开发的的是node包，则执行的命令名和真实执行的文件入口，则是根据项目的 package.json 里 bin 的配置来获取。 使用12cd projectdirnpm link 然后会看到输出类似如下的链接信息，说明成功。12/usr/local/bin/yourpakagename -&gt; /usr/local/lib/node_modules/yourpackagename/xxx/usr/local/lib/node_modules/yourpackagename/xxx -&gt; /Users/username/Documents/xxx(your real project path) 全局link一般是开发node包，可以直接在终端运行的，做npm link之前，需要在 package.json 里配置 bin 字段。1234# package.json&quot;bin&quot; : &#123; &quot;yourcommandname&quot;: &quot;./bin/yourcommandname&quot;&#125; 然后再在当前目录下运行1npm link 成功后，就可以直接在终端执行 yourcommandname 了。 项目下link如果是前端包，不需要直接在终端运行，比如UI组件库，那需要做两次link。先进入待测试组件库目录，将开发的包link到全局：1npm link 之后，再进入要使用该组件库的工程，然后在工程中link这个组件库：1npm link youruilib 现在你就可以在你的工程中使用这个ui组件库，就好像这个ui库被install到工程中一样。 GoodLuck！]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在mac中管理和随时切换node版本]]></title>
    <url>%2F2019%2F08%2F26%2F%E5%A6%82%E4%BD%95%E5%9C%A8mac%E4%B8%AD%E7%AE%A1%E7%90%86%E5%92%8C%E9%9A%8F%E6%97%B6%E5%88%87%E6%8D%A2node%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[之前用windows的电脑的时候，曾使用 nvm-windows 工具来管理开发环境中的node版本。快速在各个版本的node环境中切换的体验非常好。而在mac中，由于开发环境比较稳定，则没有使用这类工具来管理。近期由于项目的需要，有了在mac下频繁切换node版本的需求。才有了这篇文章。 工具选择我根据第一直觉，在npm上搜索 nvm，竟没有 nvm 的精确匹配，搜索结果第一位是一个叫 n 的包，点进去，也没个README说明（其实是当时我的网络不好README没有加载出来…）。(说实话，要不是发现它的作者是tj大神，我后来可能不会再次点开它，可能我就错过了一个非常好的工具。） 诧异过后，我转到github，搜索 nvm。 找是找到了，然而，它的安装方式，让我觉得不太友好：1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash 为什么nvm没有pacakge版？不如看看那个”连README都没有”的 n 是否能用。我点开了 n 的github页面。详细的使用说明映入眼帘，粗略读了一遍，感觉有戏。仔细操作一遍，这感觉，怎么说呢，这是捡到宝了呀！ 就它了！ n！ 如何使用 n 管理mac上的node版本 1. 安装1npm install -g n 2. 修改几个本地目录的拥有者因为node环境是全局的，需要安装到系统目录下，涉及目录有 /usr/local/bin、usr/local/lib、/usr/local/include、/usr/local/share，这几个目录的拥者是root，其他用户没有权限操作他们。如下命令可以将他们的拥有者从root改为当前用户：1sudo chown -R $(whoami) /usr/local/bin /usr/local/lib /usr/local/include /ur/local/share 另外，n 会在系统目录下创建一个目录，也需要修改下它的拥有者：1sudo chown -R $(whoami) /usr/local/n 关于 chown 命令，我的另一篇文章有详细说明： 如何修改mac中文件夹和文件的拥有者 3. 安装指定版本的node123n 10.16.3 //下载并安装node 10.16.3n latest //下载并安装node 最新版本n lts //下载并安装node 长期稳定维护版 4. 切换node版本1234567n //列出所有缓存的node版本 node/4.4.4 ο node/8.11.1 node/10.16.3Use up/down arrow keys to select a version, return key to install, q to quit-&gt; 上下键选择当前需要的版本，回车-&gt; done 用 node -v 查看版本是否生效。 5. 删除node版本123456//删除指定版本n rm xxx//删除当前版本外的所有版本n prune//卸载当前已安装的noden uninstall 6. 其他命令1n ls //查看已下载的node版本列表 补充 n 的获取node的源路径为node官网https://nodejs.org/dist/，在国内访问，非常慢，经常由于太慢而发生超时错误导致下载失败。解决方案：修改node镜像源。1export N_NODE_DOWNLOAD_MIRROR=https://npm.taobao.org/mirrors/node 将node镜像指向淘宝镜像。再来操作 n 命令，是不是速度嗖嗖的了。 GOOD LUCK！ 参考：n （npm）：https://www.npmjs.com/package/nn （github）：https://github.com/tj/nnvm ：https://github.com/nvm-sh/nvmnvm-window ：https://github.com/coreybutler/nvm-windows]]></content>
      <categories>
        <category>工具</category>
        <category>Intergration</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>node</tag>
        <tag>n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何修改mac中文件夹和文件的拥有者]]></title>
    <url>%2F2019%2F08%2F26%2F%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9mac%E4%B8%AD%E6%96%87%E4%BB%B6%E5%A4%B9%E5%92%8C%E6%96%87%E4%BB%B6%E7%9A%84%E6%8B%A5%E6%9C%89%E8%80%85%2F</url>
    <content type="text"><![CDATA[在mac上开发，涉及在系统目录（指操作系统自带的那些目录，比如／、 ／usr、 ／usr／local／bin 等）创建文件夹或者文件时，会出现由于权限不足导致创建失败的问题。这是由于，这些目录属于 root 用户， 而当前登录mac的一般都是非root用户，而非root用户没有权限修改root用户直接管辖的目录和文件。那么如何让用户拥有这些目录的修改权限呢？ 解决办法有两个： 方法一：改成使用root登录，这样就具有对操作系统的最大权限，可以为所欲为。但是，不推荐这么做，因为太危险。 方法二：将你要操作的目录的权限从root手里夺过来，也即修改目录的拥有者。推荐。 如何修改目录的拥有者使用linux命令 chown 。 命令格式：1chown [选项] 所有者[:组] 文件 chown 将指定文件的拥有者改为指定的用户或者用户组，用户可以是用户名或者用户ID，组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用 chown 命令，在将文件拷贝到另一个用户的目录下后，让用户拥有使用该文件的权限。 实例： 把 ／usr/local/bin 和 ／usr/local/lib 这两个目录以及其子目录的拥有者从root改成当前用户：1sudo chown -R $(whoami) /usr/local/bin ／usr/local/lib 说明： chown change owner 的缩写。 $(whoami) who am i ，获取当前的用户。 -R –recursive 的缩写，递归处理，将指定目录和所有子目录一并处理。 执行完命令，可以用 ls -l 来查看一下是否修改成功。 常用选项列表：必要参数 -c ：–changes 的缩写，当发生改变时输出调试信息，仅显示更改部分的信息 -f ：不显示错误信息，忽略错误信息 -h ：修复符号链接 -R ：–recursive 的缩写, 递归处理，将指定目录以及其子目录下的所有文件一并处理 -v ：–verbose 的缩写, 显示指令执行过程的详细的处理信息选择参数 --help ：显示帮助信息 --version ：显示版本信息]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iphone AirDrop 无法发现mac的解决办法]]></title>
    <url>%2F2019%2F08%2F13%2Fiphone-AirDrop-%E6%97%A0%E6%B3%95%E5%8F%91%E7%8E%B0mac%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前几天想把手机上的照片传到mac上，发现在AirDrop里看不到我的mac了。以为是电脑太久没重启抽了，因为以前是可以找到的。于是重启了mac，结果没用。后来求助网络，才终于搞定。在此记下方法，以备以后遇到同样的问题又忘记怎么处理。 第一步先确保手机（iPhone）上的蓝牙打开，AirDrop 开启，并对所有人可见。 第二步确保 mac 上 AirDrop 开启。具体操作：打开 Finder 中的 AirDrop ，并设置成 所有人可见。不过此时手机上的 AirDrop 仍然看不到 mac。 第三步确保 mac 上蓝牙开启。具体操作：打开 设置 -&gt; 蓝牙 -&gt; 打开蓝牙。 第四步 （关键） mac 和 iPhone 蓝牙配对。具体操作：在 mac 的蓝牙设置界面，应该可以看到你的 iPhone 了。点击这个 iPhone 旁边的 配对 按钮。然后手机会收到一个配对请求，点接受。等待一会，就会配对成功。 PS：如果第四部看到手机已经是配对状态，则移除后重新配对。 这时，在mac和iPhone的AirDrop中就可以互相看见彼此了，然后就可以愉快地互传文件了。 Have a nice day!]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>iphone</tag>
        <tag>mac</tag>
        <tag>airdrop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(五)：给文章添加字数统计、阅读时长]]></title>
    <url>%2F2019%2F02%2F25%2F%E8%BF%9B%E9%98%B6-%E4%BA%94-%EF%BC%9A%E7%BB%99%E6%96%87%E7%AB%A0%E6%B7%BB%E5%8A%A0%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E3%80%81%E9%98%85%E8%AF%BB%E6%97%B6%E9%95%BF%2F</url>
    <content type="text"><![CDATA[继续倒腾个站。今天看到别人的花里胡哨的博客，手又痒了。之前我可是对自己的极简风“守身如玉”，不愿意在个站添加一点点多余的信息。今天居然有一点点动摇了，那就神不知鬼不觉地添加一点统计信息吧，这都是为了用户体验好（天音：想加东西就加，这么多借口干啥？）我：[抠鼻] 只需三步： Step1: 安装插件需要安装 hexo-wordcount 插件。它可以统计文章字数，估算阅读时长，以及统计整个网站的总字数。在命令行进入blog根目录，然后：1npm i --save hexo-wordcount Step2: 修改主题配置进入 themes/next/ 目录，打开 _config.yml ，找到 post_wordcount 字段，将wordcont、min2read、totalcount 三个属性都设为 true ：123456post_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true Step3: 重启hexo给hexo项目安装新的插件，以及修改一些配置，需要重启hexo才能看到效果。我们重新 hexo s 启动一下hexo，再刷新本地预览界面，现在你可以看到： 在每个标题下面增加了文章字数（Words count in article） 和 阅读时长（Reading time） 两组统计项； 在网站页脚增加了所有文章字数统计数据（Site words total count）。 –NICE～]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[添加chrome扩展程序技巧]]></title>
    <url>%2F2019%2F01%2F29%2F%E6%B7%BB%E5%8A%A0chrome%E6%89%A9%E5%B1%95%E7%A8%8B%E5%BA%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[我们给chrome 浏览器添加扩展程序，有时会遭到 chrome 的限制，比如只能通过 chrome 商城添加，而 chrome 商城需要墙外的环境，大多数时候不一定当前电脑可以翻墙。那么就需要一些技巧来添加这些扩展程序。 方法一 在扩展程序界面，打开开发者模式。 然后将下载好的 .crx 扩展程序文件拖拽到插件管理界面。 该方法通常是可行的，不过也有的时候赶上某些 chrome 版本，不允许拖拽安装。那么可以尝试第方法2： 方法二 首先将下载好的 .crx 扩展程序文件修改后缀为 .rar，然后解压它，在解压的文件夹内，找到 _metadata 文件夹，将下划线去掉，改为 metadata。 然后在 chrome 插件管理界面，打开开发者模式，点击 ‘加载已解压的扩展程序’，选择刚才解压并修改后的文件夹，确定，即可。]]></content>
      <categories>
        <category>浏览器</category>
      </categories>
      <tags>
        <tag>chrome</tag>
        <tag>browser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何创建空白git分支]]></title>
    <url>%2F2019%2F01%2F29%2F%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E7%A9%BA%E7%99%BDgit%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[在管理前端代码工程时，有时需要创建一个干净的分支，比如用于放文档，或者全新的版本分支。但是普通的创建分支命令，会将历史日志带过去。那么对于有代码洁癖和强迫症的人（比如我）来说，是不能忍的。强大的git为我们这些人准备了创建空白git分支的方法。掌握后受用无穷。 步骤： 1. 创建无父节点的分支1git checkout --orphan orphanbranch 参数 orphan 的作用有两个： 1.拷贝当前所在分支的所有文件。 2.让这个新的分支没有父节点。这意味着这个分支不会有任何历史记录。 2. 删除该分支下所有文件orphan 会把之前分支中的文件都拷贝过来，这些文件我不想要，因为我要一个完全空白的干净分支。可以用git rm删除一下。1git rm -rf . 不用担心在log里留下delete日志，因为严格来讲，我们的分支还没完全创建好（还差一步），此时的操作并不会影响历史记录。 3. 创建一个初始文件，比如readme，并提交现在试着查看下当前分支： 会发现，并没有看到我们创建的 orphanbranch。因为还差一步，我们必须对这个分支进行一次初始提交，才可以看到它。123touch README.mdgit add .git commit -m &quot;add readme&quot; 4. 一个干净的空白分支诞生现在git branch -a可以看到这个分支了。用git log查看一下这条分支的日志，可以看到，只有一条添加readme的记录。此时，一个空白分支就创建成功了。12git branch -agit log --oneline Good luck！]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(四)：给博客添加站内搜索功能]]></title>
    <url>%2F2019%2F01%2F26%2F%E8%BF%9B%E9%98%B6-%E5%9B%9B-%EF%BC%9A%E7%BB%99%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[不知不觉坚持写博客已经快一年了，博客文章破50，虽然平均每个月4到5篇不算什么，但是对于平时一心扑到工作简直没有时间生活的我来说，已经很不容易了。虽然文章可能没有高大上的标题，也没有涉及太多前沿的技术，但是起码我记录下了我的一些小经验，累积了自己的一个小知识库。其实我还有很多内容没来及的记录，希望以后能通过博客沉淀更多的知识，同时帮助到更多的人。 言归正传，文章一多，有时自己想翻查一个内容，要找好久，要是有站内查找功能就好了。于是仔细查阅了工程yml配置，果然发现在theme下的_config.yml有个local_search配置项，满心欢心把它设为true。结果搜索图标是出来了，但是点击后除了在页面加了一个全局loading就什么都没有了。看来还需要额外的操作。百度了一番，原来hexo提供了的search插件，需要手动安装才可以使用站内搜索。 3步搞定： 1.安装两个插件1npm i --save hexo-generator-search hexo-generator-searchdb 2.配置hexo主配置文件（位于工程根目录下）_config.yml在最后面追加这段，注意2个空格的缩进，这个是yml缩进语法，不能随意。123456# local_searchsearch: path: search.xml field: post format: html limit: 10000 3.配置hexo主题下的配置文件（位于theme-&gt;next下）_config.yml 将enable设为true。这一步我在一开始就已经做过了～ 1234567local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 重新hexo g, hexo s，刷新页面，点击搜索图标，就可以看到搜索弹出框了，输入关键字，可以看到匹配到文章。 GOOD LUCK! 参考资料：https://www.jianshu.com/p/519b45730824https://github.com/wzpan/hexo-generator-searchhttps://www.npmjs.com/package/hexo-generator-searchdb]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm install 高级]]></title>
    <url>%2F2019%2F01%2F09%2Fnpm-install-%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[npm install npm install –production npm install –only=prod npm install –only=dev]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git clone 高级]]></title>
    <url>%2F2019%2F01%2F09%2Fgit-clone-%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[自定义克隆下来的目录名克隆仓库的命令格式是 git clone [url]这个命令会将远程仓库的名字作为你的本地仓库（即项目根目录）的名字。如果你想自己命名本地仓库的名字可以使用这个命令：git clone [url] yourprojectname 克隆指定分支如果远程仓库不做设置，默认 git clone 克隆下来的是项目的 master 分支。如果想要获取非 master 分支，可以使用命令指定分支： git clone -b branchname [url]比如我要克隆 zrender 项目的 dev 分支：1git clone -b dev https://github.com/ecomfe/zrender]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github和gitlab上的md文档支持相对路径的链接了]]></title>
    <url>%2F2019%2F01%2F09%2Fgithub%E5%92%8Cgitlab%E4%B8%8A%E7%9A%84md%E6%96%87%E6%A1%A3%E6%94%AF%E6%8C%81%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E9%93%BE%E6%8E%A5%E4%BA%86%2F</url>
    <content type="text"><![CDATA[markdown 格式语法中，链接的格式是：1[链接文字](链接地址) 之前写链接，用 http 协议 url 居多，最近遇到在项目的 README 中要添加另一个文档的链接，由于当前在 dev 分支，如果写分支的仓库 url 路径，那到时候 dev 分支合并到其他分支后，dev 分支被删除后，这个地址岂不是有问题了。如果能用相对路径就好了。 查了下，居然在 gitlab 上是支持的，在 github 上最近也支持了，真是喜讯。说到喜讯，昨天 github 官网宣布开放免费的 private repository ，也是2019喜讯一桩。 相对路径使用举例如果你的项目结构如下： 12345678project/ text.md subpro/ subtext.md subsubpro/ subsubtext.md subsubpro2/ subsubtext2.md 那么在 text.md 中链接到 subtext.md 的相对链接这么写：1[this subtext](subpro/subtext.md) 在 text.md 中链接到 subsubtext.me 的相对链接这么写：1[this subsubtext](subpro/subsubpro/subsubprotext.md) 在 subsubtext.md 中链接到 text.md 的相对链接这么写：1[this text](../../text.md)]]></content>
      <categories>
        <category>工具</category>
        <category>Intergration</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows批处理常用命令]]></title>
    <url>%2F2018%2F12%2F20%2Fwindows%E6%89%B9%E5%A4%84%E7%90%86%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前阵子在倒腾服务器的时候，需要些一些 windows 批处理来执行任务。就稍微研究了一下。 一、 基本信息 批处理文件扩展名为 .bat 或者 .cmd。区别：cmd 文件只能在 windows2000 以上的系统才能运行，bat 文件则没有这个限制。 这个文件的每一行都是一条 DOS 命令。 可以使用任何文本编辑器创建和修改。 批处理是一种简单的程序，可以用 if 和 go 来控制流程，也可以使用 for 循环。 批处理的编程能力远不如 C语言等编程语言，也十分不规范。 每个编写好的批处理文件都相当于一个 DOS 的外部命令，把它锁在的目录放到 DOS 搜索路径（path）中，即可在任意位置运行。 C:\AUTOEXEC.BAT 是每次系统启动时都会自动运行的，可以将每次启动时都要运行的命令放入该文件中。 大小写不敏感 在命令提示下键入批处理文件的名称，或者双击该批处理文件，系统会调用cmd.exe来运行该文件。 二、 参数 系统参数 1234567891011121314%SystemRoot% === C:\WINDOWS (%windir% 同样)%ProgramFiles% === C:\Program Files%USERPROFILE% === C:\Documents and Settings\Administrator (子目录有“桌面”,“开始菜单”,“收藏夹”等)%APPDATA% === C:\Documents and Settings\Administrator\Application Data%TEMP% === C:\DOCUME~1\ADMINI~1\LOCALS~1\Temp (%TEM% 同样)%APPDATA% === C:\Documents and Settings\Administrator\Application Data%OS% === Windows_NT (系统)%Path% === %SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem (原本的设置)%HOMEDRIVE% === C: (系统盘)%HOMEPATH% === \Documents and Settings\Administrator:: 枚举当前的环境变量setlocal enabledelayedexpansionFOR /F &quot;usebackq delims==&quot; %%i IN (`set`) DO @echo %%i !%%i! 给批处理文件传递参数 12345678910%[1-9]表示参数，参数是指在运行批处理文件时在文件名后加的以空格(或者Tab)分隔的字符串。变量可以从%0到%9，%0表示批处理命令本身，其它参数字符串用 %1 到 %9 顺序表示。Sample：call test2.bat &quot;hello&quot; &quot;haha&quot; (执行同目录下的“test2.bat”文件，并输入两个参数)在“test2.bat”文件里写:echo %1 (打印: &quot;hello&quot;)echo %2 (打印: &quot;haha&quot;)echo %0 (打印: test2.bat)echo %19 (打印: &quot;hello&quot;9) 三、 基本命令setmdechoshutdowmpause符号：&gt; 传递并覆盖&gt;&gt; 传递并追加:: 注释 找到一个比较清晰比较全的一个文档，在这里 四、 例子重启的批处理1shutdown -r -f -t 0 r: 关闭并重启计算机。f: 强制关闭正在运行的应用程序，不在前台警告用户。t xxx: 设置关闭的超时事件为 xxx 秒。有效范围时0-315360000（10年），默认值为30. 在重启前，将重启时间写入日志(以下已在英文版windows操作系统上检测过)restart.bat12345678@echo offset nowdate=%date:~4, 10%set nowtime=%time:~0,8%set content=%nowdate:/=-% %nowtime%set distpath=&quot;c:\restartlog&quot;::write logecho restart time: %content% &gt;&gt; %distpath%\log.txtshutdown -r -f -t 0 再在windows的计划任务中，将这个脚本配置进去。则当脚本执行，将会在系统的c盘下新建一个目录restartlog，然后在这个目录中创建一个文件log.txt，并在文件中追加写入： “restart time： 当时的时间”，最后重启系统。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>windows</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git如何撤销commit并保留修改]]></title>
    <url>%2F2018%2F11%2F27%2Fgit%E5%A6%82%E4%BD%95%E6%92%A4%E9%94%80commit%E5%B9%B6%E4%BF%9D%E7%95%99%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[有时 commit 代码的时候，手误或者眼花误将不应该这次提交的文件 commit 了，此时还没有 push 到远程仓库，这个时候可以通过 git 命令，撤销该次 commit，并且本地修改还在，即回到 commit 之前的状态，可以重新选择文件进行提交。 1git reset --soft [commit_id] 这个 commit_id 可以是历史记录中任一一个，这个命令会让你的代码回到该条 commit 之后的状态，所有的修改都会在，log 中的该条之后的 commit 记录就都删除了。所以也要谨慎使用，一般用于撤销上一次的 commit。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何更改git clone默认检出的分支]]></title>
    <url>%2F2018%2F11%2F26%2F%E5%A6%82%E4%BD%95%E6%9B%B4%E6%94%B9git-clone%E9%BB%98%E8%AE%A4%E6%A3%80%E5%87%BA%E7%9A%84%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[一般我们 clone 一个项目都是检出默认的 master 分支。这个其实是可以修改的。 修改办法：在 git 服务器上，进入该项目的 .git （仓库）文件夹，编辑 HEAD 文件。 例如想默认为 dev 分支：将 refs/heads/master 改成 refs／heads/dev 该操作需要 git 管理员来完成，修改本地仓库没有用。 在 gitlab 或者 github 的仓库配置中，可以找到，有个默认分支下拉选项，就是做这个设置的。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js如何识别图片加载失败]]></title>
    <url>%2F2018%2F11%2F26%2Fjs%E5%A6%82%E4%BD%95%E8%AF%86%E5%88%AB%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[在做项目过程中遇到图片请求失败的时候，图片区域会出现一个原生的碎片图标，非常影响用户体验。这时需要用一个 broken 的图片去代替它，来提升户体验。要做到这一点，首先要在代码中识别图片加载失败这个事情。那么怎么判断一个图片加载失败了呢？ 在 js 中使用 onerror 事件javascript 给我们提供了一个 onerror 事件，img 标签支持该事件，当装载文档或者图像的过程中发生了错误，就会触发 onerror 事件。我们可以在这个事件中，定义要替换加载不出来的原图的 broken 图片。 核心代码： 1234567// html&lt;img src=&quot;img.png&quot; onerror=&quot;myfunction()&quot;&gt;// javascriptmyfunction() &#123; this.src=&quot;default.png&quot;&#125; 注意：如果 onerror 指定的图片也不存在的话，会出现无限死循环 404. 解决办法是在 js 中添加：12345// javascriptmyfunction() &#123; this.src=&quot;./default.png&quot;; this.onerror = null; // 添加这个防止默认图片也不存在而陷入死循环&#125; 在 Vue 中怎么使用 onerror12345678910111213// vue&lt;template&gt; &lt;img :src=&quot;item.imgUrl&quot; :onerror=&quot;defaultImg&quot;&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data () &#123; return &#123; defaultImg: &apos;this.src=&quot;./static/images/default.png&quot;&apos; &#125; &#125; &#125;&lt;/script&gt; 番外有时因为网络比较卡的原因需要多加载几次再判定为是否加载失败。但是有时是因为网络连接断开而加载失败，需要在网络恢复连接时自动加载图片。这是就需要知道，js中怎么识别网络断开和连接的，有两个事件：online 和 offline。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152var isOnLine = true;var eventList = &#123;&#125;;window.addEventListener(&apos;offline&apos;, function() &#123; isOnLine = false;&#125;)window.addEventListener(&apos;online&apos;, function() &#123; if(!isOnline) &#123; isOnLine = true; reLine(); // 执行重连后要做的事情 &#125;&#125;)function reLine() &#123; for(var key in eventList) &#123; if(!eventList[key]) continue; var arg = eventList[key].arg; var thisOnFn = eventList[key].that; eventList[key].fun.apply(thisOnFn, arg); eventList[key] = null; &#125;&#125;function offLined(fun, arg, that) &#123; if(!isOnLine) &#123; var name = fun.name || &apos;__new&apos;; eventList[name] = &#123;&#125;; eventList[name].fun = fun; eventList[name].arg = [].slice.call(arg); eventList[name].that = that; return true; &#125; return false;&#125;---// 重新定义myfunctionmyfunction(imgObj, imgSrc, maxErrorNum) &#123; if(offLined(restImgUrl, arguments, this)) return; if(maxErrorNum &gt; 0) &#123; imgObj.onerror = function () &#123; myFunction(imgObj, imgSrc, maxErrorNum - 1) &#125; setTimeout(function() &#123; imgObj.src = imgSrc; &#125;, 500) &#125; else &#123; imgObj.src = &apos;./default.png&apos;; this.onerror = null; &#125; &#125;// 调用&lt;img src=&quot;img.png&quot; onerror=&quot;myfunction(this, this.src, 3)&quot;&gt;]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js如何获取网页元素的绝对位置]]></title>
    <url>%2F2018%2F11%2F25%2Fjs%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E5%85%83%E7%B4%A0%E7%9A%84%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[什么是网页元素的绝对位置和相对位置网页元素的绝对位置，是指该元素的左上角相对于整张网页的左上角的坐标。网页元素的相对位置，是指该元素的左上角相对于视口的左上角的坐标。 如何获取绝对位置 由于每个元素都有 offsetTop 和 offsetLeft 属性， 表示该元素左上角与父容器（offsetParent对象）左上角的距离。所以可以遍历一下元素的祖先容器，把所有的 offsetTop 加起来得到。1234567var element = document.getElementById(&apos;article_container&apos;)var actualTop = element.offsetTop; // 绝对位置var current = element.offsetParent;while (current !== null)&#123; actualTop += current.offsetTop; current = current.offsetParent;&#125; 如何获取相对位置有了绝对位置，获得相对位置就容易了，可以通过绝对坐标减去页面滚动条滚动的距离来得到。滚动条滚动的垂直距离，是 document 对象的 scrollTop 属性，滚动的水平距离，是 document 对象的 scrollLeft 属性。scrollTop 和 scrollLeft 是可以赋值的，并且会立即自动滚动网页到相应位置。可以利用它们改变元素的相对位置。另外，elment.scrollIntoView() 方法也有类似作用，可以使网页元素出现在浏览器窗口的左上角（不过需要在支持 html5 的浏览器才能生效）。12var elementScrollTop = document.documentElement.scrollTop; var relativeTop = actualTop-elementScrollTop; // 相对位置 快速获取元素的绝对位置和相对位置使用 js 的 getBoundingClientRect() 方法。她会返回一个对象，包含 left， right， top， bottom 四个属性，分别对应该元素的左上角和右下角相对于浏览器窗口（viewport）左上角的距离。12345678var dom = document.getElementById(&apos;article_container&apos;);// 相对位置var rLeft = dom.getBoundingClientRect().left;var rTop = dom.getBoundingClientRect().top;// 绝对位置（相对位置+滚动距离）var aLeft = rLeft + document.documentElement.scrollLeft;var aTop = rTop + document.documentElement.scrollTop;]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacBook 常用快捷键]]></title>
    <url>%2F2018%2F11%2F25%2FMacBook-%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[1. 新建一个 Tab 样式的终端窗口1Command + T 2. 自带的截图快捷键1234Command + Shift + 3 截取整个屏幕，保存图片在桌面Command + Shift + 4 选取部分屏幕区域，保存图片在桌面先Command + Shift + 4 再空格， 可以对指定的窗口或者菜单截屏以上快捷键，加上 Ctrl， 可以把截图保存在剪切板]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>MacBook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git log高级使用]]></title>
    <url>%2F2018%2F11%2F24%2Fgit-log%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[-n 查看最近那次的提交信息1git log -2 //查看最近2次提交记录 – fileName 查看指定文件的提交信息文件名要放到参数的最后位置，通常在前面加上 -- 并用空格隔开表示是文件。1git log -- file1 file2 branchName 查看某个分支上的提交记录1git log dev tagName 查询指定标签的提交记录12345git log v1.0.. 查询从v1.0以后的提交历史记录(不包含v1.0) git log test..master 查询master分支中的提交记录但不包含test分支记录 git log master..test 查询test分支中的提交记录但不办含master分支记录 git log master…test 查询master或test分支中的提交记录。 git log test –not master 屏蔽master分支 根据 commit id 或者 HEAD 查询日志commit id 可以是提交哈希的简写模式，也可以使用HEAD替代。HEAD指向当前分支，HEAD^为最后一个提交，等同于HEAD~1,HEAD~2代表倒数第二次提交1git log f52c471 –pretty 按指定格式显示日志信息可选项有： oneline, short, medium, full, fuller, email, raw, format默认为medium，可以通过修改配置文件来指定默认的方式：1git log (--pretty=)oneline 常见的 format 选项：1234567891011121314151617选项 说明%H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 -date= 选项定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期，按多久以前的方式显示 %s subject 提交说明%d body 事例：123git log --pretty=format:&quot;$h %cn %cr %s&quot;// 或者git log --format=&quot;$h %cn %cr %s&quot; 自定义 git log –format 后输出内容的颜色git log --format 后，输出的内容是没有颜色区分的，我们其实是可以给输出的内容自定义颜色，便于让内容更有辨识度。方法为在 format 的内容选项前，加上 %C() 选项。其中: 括号内放代表颜色的字符串，颜色字符串支持24位的RGB值（要带#号） 也可以是以下的颜色名称： normal black red green yellow blue magenta cyan white 这些颜色名称还可以跟这些修饰属性绑定使用，可叠加多个使用。注意，这些修饰只能修饰前景色： bold // 加粗 dim // 颜色减淡 ul // 下划线 blink // 闪烁效果 reverse // 前景色背景色交换 也可以放两个颜色字符串，第一个将被识别为前景色，第二个将被识别为背景色 在 git v1.7 版本后，对于 red、green、blue 三个颜色来说，括号是可选的。（但是这样就只能使用一个颜色，即前景色） 颜色和颜色修饰，是会传播到之后的输出内容样式，除非在内容前或者该内容后，重置颜色和修饰：%Creset。或则剔除修饰：noxxx（xxx 代表修饰名，例如nodim）。所以每设置完一个内容的颜色，最好是在该内容后紧跟一个%Creset，以防影响后面内容的样式。 重置颜色和剔除修饰也是会传播的。 事例命令：1git log --format=&quot;%C(magenta)%h %C(red)%d %C(yellow)(%cr) %C(green)%s&quot; 效果：命令：1git log --format=&quot;%C(white ul bold magenta)%h%Creset %C(yellow)(%cr)%Creset %C(green)%s%Creset %C(dim)%cd&quot; 效果：命令：1git log --format=&quot;%C(reverse ul black)%h%Creset %C(yellow)(%cr)%Creset %C(green)%s%Creset %C(dim)%cd&quot; 效果： 自定义规则快捷键——别名每次都要输入这一长串的命令非常繁琐且容易出错，我们可以将调整好的这一串命令保存在git配置文件里，并给它起一个别名，下次只需要输入这个别名，就可以看到符合自己习惯的日志格式和样式了。 进入～／.gitconfig 添加：（注意，format后的值必须要用单引号，双引号会报错。） 12[alias] logs = log --format=&apos;%C(reverse ul red)%h%Creset %cn %C(yellow)(%cr)%Creset %C(green)%s%Creset&apos; 然后在命令行只需要输入 git logs 就可以得到你要的效果了。 更多详细可查看 git documentation Pretty Formats –author=someone 查询指定作者的提交记录1git log --author=sam –grep 通过关键字过滤提交日志1git log --grep=mod 列出所有包含 mod 字样提交信息的记录 –graph 以简单的图形方式列出提交记录1git log --graph –name-status 显示新增、修改、删除的文件清单1git log --name-only]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用nvm+nrm+cmder打造灵活的前端开发环境]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8nvm-nrm-cmder%E6%89%93%E9%80%A0%E7%81%B5%E6%B4%BB%E7%9A%84%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[在前端工程开发过程中，不同项目可能会使用不同的 node 环境和 npm 环境，在不同项目中切换时，要不停的卸载安装前端开发环境，非常麻烦。于是有了 nvm 和 nrm，可以通过切换的方式快速设置开发环境版本，再也不要繁琐地卸载安装了，有效的解放了劳动力。 1. nvmnvm: node version managernode 版本管理器 2. nrmnrm: npm registry managernpm 版本管理器 安装 nrm：1npm install nrm -g 添加 registry：12nrm add npm http://registry.npmjs.orgnrm add taobao https://registry.npm.taobao.org 查看已添加的 registry：1nrm ls 切换 registry：12nrm use taobaonrm use npm 3. cmder一款酷炫的命令行终端软件]]></content>
      <categories>
        <category>工具</category>
        <category>Intergration</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>nvm</tag>
        <tag>nrm</tag>
        <tag>cmder</tag>
        <tag>开发环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何查看和设置npm镜像地址]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%92%8C%E8%AE%BE%E7%BD%AEnpm%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[查看配置1npm config list 在输出信息中可以看到我的 npm 镜像如下：123metrics-registry = &quot;https://registry.npmjs.org/&quot;scope = &quot;&quot;user-agent = &quot;npm/5.5.1 node/v8.9.3 darwin x64&quot; 设置镜像常用的 npm 镜像地址有：npm —- http://registry.npmjs.org (默认)cnpm — http://r.cnpmjs.orgtaobao - https://registry.npm.taobao.orgnj —– https://registry.nodejitsu.comrednpm - http://registry.mirror.cqupt.edu.cnnpmMirror https://skimdb.npmjs.com/registryedunpm - http://registry.enpmjs.org 1. 临时使用1npm --registry https://registry.npm.taobao.org install xxx 2. 持久使用 12npm config set registry https://registry.npm.taobao.orgnpm config set disturl https://npm.taobao.org/dist 或者直接编辑 ~/.npmrc 文件，加入如下内容：1registry = https://registry.npm.taobao.org 3. 随时切换使用 nrm 管理 npm 镜像地址 检测镜像是否配置成功12npm config get registrynpm config get disturl npm info underscore 或者 npm info express 也可以用来查看配置是否成功 删除镜像12npm config delete registrynpm config delete disturl 其他 查看 npm 安装目录1npm root -g 查看 npm 的 prefix 和 cache 路径配置信息12npm config get prefixnpm config get cache 安装 node.js 时会自动安装 npm， 默认的缓存路径是 %appdata%\Roaming\npm-cache]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git如何去掉对文件的追踪]]></title>
    <url>%2F2018%2F11%2F24%2Fgit%E5%A6%82%E4%BD%95%E5%8E%BB%E6%8E%89%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[去掉对某些文件的 track：1git rm --cached &lt;file path&gt;]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让commit信息带图标]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%A6%82%E4%BD%95%E8%AE%A9commit%E4%BF%A1%E6%81%AF%E5%B8%A6%E5%9B%BE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[git commit 的提交日志上，除了文字，还可以有图标。叫做 git commit emoji。 提交事例：1git commit -m &quot;:tada: Made some changes&quot; 效果如下： commit 格式规范： message 摘要不超过50个字，首字母大写，使用祈使语气，句末不要加句号 引用相关 issue 或 PR 编号 &lt;#110&gt; emoji 代码列表 emoji emoji代码 语义 :tada:(庆祝) :tada: 初次提交 :sparkles: (火花) :sparkles: 引入新功能 :bookmark: (书签) :bookmark: 发行/版本标签 :bug: (bug) :bug: 修复 bug :ambulance: (急救车) :ambulance: 重要补丁 :globe_with_meridians: (地球) :globe_with_meridians: 国际化与本地化 :lipstick: (口红) :lipstick: 更新 UI 和样式文件 :rotating_light: (警车灯) :rotating_light: 移除 linter 警告 :wrench: (扳手) :wrench: 修改配置文件 :heavy_plus_sign: (加号) :heavy_plus_sign: 增加一个依赖 :heavy_minus_sign: (减号) :heavy_minus_sign: 减少一个依赖 :arrow_up: (上升箭头) :arrow_up: 升级依赖 :arrow_down: (下降箭头) :arrow_down: 降级依赖 :zap: (闪电):racehorse: (赛马) :zap::racehorse: 提升性能 :chart_with_upwards_trend: (上升趋势图) :chart_with_upwards_trend: 添加分析或跟踪代码 :rocket: (火箭) :rocket: 部署功能 :white_check_mark: (白色复选框) :white_check_mark: 增加测试 :memo: (备忘录) :memo: 撰写文档 :hammer: (锤子) :hammer: 重大重构 :art: (调色板) :art: 改进代码结构/代码格式 :fire: (火焰) :fire: 移除代码或文件 :pencil2: (铅笔) :pencil2: 修复 typo :construction: (施工) :construction: 工作进行中 :construction_worker: (工人) :construction_worker: 添加 CI 构建系统 :green_heart: (绿心) :green_heart: 修复 CI 构建问题 :lock: (锁) :lock: 修复安全问题 :whale: (鲸鱼) :whale: Docker 相关工作 :apple: (苹果) :apple: 修复 macOS 下的问题 :penguin: (企鹅) :penguin: 修复 Linux 下的问题 :checkered_flag: (旗帜) :checked_flag: 修复 Windows 下的问题 注意emoji 表情在提交代码的时候不能乱用，否则容易造成误解。为此，开源项目 gitmoji 专门规定了在 github 提交代码时应当遵循的 emoji 规范。 延伸 默认情况下在命令行中不会显示出 emoji， 仅显示 emoji 代码。不过可以使用 emojify 使得在命令行也可以像显示 emoji，emojify 是一个 shell 脚本。(不过这个脚本已经很老了，最近更新在3年前，而且mac提示已经不支持该命令，后空再找解决方案) 另外，markdown 也有一系列支持的 emoji，传送门]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js如何获取浏览器窗口大小和网页内容尺寸]]></title>
    <url>%2F2018%2F11%2F05%2Fjs%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%B5%8F%E8%A7%88%E5%99%A8%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E5%92%8C%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E5%B0%BA%E5%AF%B8%2F</url>
    <content type="text"><![CDATA[什么是网页的大小和浏览器窗口 网页大小就是一张网页的全部面积，通常情况，网页大小由内容和CSS样式表决定。 浏览器窗口大小，是指浏览器窗口中看到的那部分网页面积，又叫视口（viewport）。 获取浏览器窗口大小可以通过windows对象的 innerHeight 属性获取。也可以通过元素的 clientHeight 属性获取。网页上每个元素都有 clientHeight 和 clientWidth 属性。这两个属性指元素的内容部分加上 padding 的大小，不包括 border 和滚动条的大小。大部分情况下 document.documentElement 的大小可以代表浏览器窗口的大小，但是在 IE6 的 quirks 模式中，document.body 才返回正确的值。 如何获取浏览器窗口高度 1234567891011// 浏览器内部界面的高度，即内容显示区域的高度，F12调试工具的占位会实时改变该值window.innerHeight// 浏览器外部界面即窗体的高度，调试工具的占位不会影响该值window.outerHeight// 表示 HTML 文档所在窗口的可视区域高度，效果同 window.innerHeightdocument.documentElement.clientHeight// ie6 quirks 模式下表示 body 的可视区域高度，注意：body与浏览器之间有个默认的 margindocument.body.clientHeight 与高度对应的，还有宽度：window.innerWidth 、window.outerWidth、window.outerWidth、document.documentElement.clientWidth、 document.body.clientWidth 说明：window.innerHeight ／ innderWidth 在ie8 及以下不支持，需要通过document.documentElement.clientHeight ／ clientWidth 来替代。所以兼容的写法为：window.innerHeight || document.documentElement.clientHeightwindow.innderWidth || document.documentElement.clientWidth 获取网页内容大小12345document.documentElement.scrollWidth || document.body.scrollWidthdocument.documentElement.scrollHeight || document.body.scrollHeightdocument.documentElement.offsetWidth || document.body.offSetWidthdocument.documentElement.offsetHeight || document.body.offSetHeight 番外通常获取浏览器界面的宽高，是有自适应布局的需要，常常需要跟如下方法配合使用： 1. window 的尺寸变化事件12345// jswindow.onresize()// jquery$(window).resize() 2. window 的滚动事件12345// jswindow.onscroll()// jquery$(window).scroll()]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下模拟域名]]></title>
    <url>%2F2018%2F10%2F05%2Fwindows%E4%B8%8B%E6%A8%A1%E6%8B%9F%E5%9F%9F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[在 c盘下 windows／system32/drivers/etc/host 文件内，可以添加设置域名，将本地起的服务模拟成域名形式，便于相关前端测试，比如测试跨域。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>windows</tag>
        <tag>domain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速使用express搭建服务]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8express%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[使用 express 搭建最简单的服务。需要有 node 环境。 1. 安装 express1npm install express 2. 编写最简单的服务 新建 server.js 文件 打开 server.js 文件，写入： 1234const express = require(&apos;express&apos;); //引入 expressconst app = express(); //执行一下 expressapp.use(express.static(__dirname)); //指定静态文件路径app.listen(3000); //指定监听端口 3. 起服务命令行进入 server.js 所在目录，然后执行：1node server.js 4. done！服务已经启动，在浏览器输入 http://localhost:3000 就可以访问页面了。 进阶1. 添加接口路由123456789//get 请求，访问地址为 `http://localhost:3000/users`app.get(&apos;/users&apos;, function(req, res) &#123; res.end(res);&#125;)//put 请求，访问地址为 `http://localhost:3000/users`app.put(&apos;/users&apos;, function(req, res) &#123; res.end(res);&#125;) 2. 设置响应头根据需要，有时得设置响应头，以达到某种目的，比如跨域。在 server.js 文件的定义变量之后，添加一个 app.use：1234567891011121314151617app.use(function(req, res, next) &#123; //允许哪个源可以访问我 res.setHeader(&apos;Access-Control-Allow-Origin&apos;, &apos;http://localhost:4000&apos;); //允许携带哪个头访问我，多个头，用英文逗号隔开 res.setHeader(&apos;Access-Control-Allow-Headers&apos;, &apos;name&apos;); //允许哪个方法访问我 res.setHeader(&apos;Access-Control-Allow-Methods&apos;, &apos;PUT&apos;); //允许携带 cookie 访问我 res.setHeader(&apos;Access-Control-Allow-Credentials&apos;, true); //允许前端访问哪个头，多个头，用英文逗号隔开 res.setHeader(&apos;Access-Control-Expose-Headers&apos;, &apos;name&apos;); next();&#125;)]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>node</tag>
        <tag>express</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域]]></title>
    <url>%2F2018%2F10%2F05%2F%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[浏览器同源策略：请求的地址与平台的协议、域名、端口号，都一致，称为 同域。只要有一个不一样，就称为 跨域。 cookie、 Localstorage 不能跨域；DOM元素也有同源策略（iframe）；ajax 也不支持跨域。 可以跨域的 html 标签：link、 img、 script 如何实现跨域： jsonp cors postMessage document.domain window.name location.hash http-proxy ngix WebSocket]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用gitbook发布自己的书籍]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8gitbook%E5%8F%91%E5%B8%83%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B9%A6%E7%B1%8D%2F</url>
    <content type="text"><![CDATA[利用开源项目 gitbook，自己写本书吧～ 前言：gitbook 平台在今年的4月9日发布了新的版本v2。新的版本官网已经变成 www.gitbook.com （旧的地址为 legacy.gitbook.com ）。新旧版本有很多的不一样，网上很多资料都是针对旧版。 比如新版不再支持把每本书作为一个 Git Repository 来进行版本管理。（以前是可以针对每本书从本地 git push 到 gitbook 的），这点也是坑了我很久（坑一个强迫症重度患者的结果就是，不扒出被坑的根本原因誓不罢休）。更多 v2 的重大改变可以看 这里。 以下的所有操作都是针对新版的 gitbook。 使用 gitbook 编写一本书的步骤如下： 基本用法1. 全局安装 gitbook-cli1npm install gitbook-cli -g 2. 查看 gitbook 版本1gitbook --version 我在查看 gitbook 版本的时候，他会自动安装一些插件，等了一会安装完才出的版本信息：12CLI version: 2.3.2GitBook version: 3.2.3 3. 初始化 gitbook1gitbook init 4. 编辑书籍 一个 gitbook 项目至少要包含 README.md 和 SUMMARY.md，书本的第一页内容是从文件 README.md 文件中提取的。如果这个文件名没有出现在 SUMMARY.md 文件中，则它会被添加为章节的第一个条目。而由于一些托管在 github 上的书更喜欢将 README.md 作为项目的介绍而不是书的介绍，从 gitbook v2 起，可以在 book.json 中指定某个文件作为 README。例如： 12345&#123; &quot;structure&quot;: &#123; &quot;readme&quot;: &quot;myIntro.md&quot; &#125;&#125; gitbook 使用文件 SUMMARY.md 来定义书本的章节和子章节的结构。它用来生成书本内容的预览表。它的格式是一个简单的链接列表。另外可以在里面添加一些 markdown 格式的标题和分割线。例如： 12345678910111213141516# 概要* [章节 1](chapter1.md)* [章节 2](chapter2.md)* [章节 3](chapter3.md)# 基础* [章节 1](chapter1/README.md) * [1.1 a](chapter1/a.md) * [1.2 b](chapter1/b.md)---* [章节 2](chapter2/README.md) * [2.1 c](chapter2/c.md) * [2.2 d](chapter2/d.md)# 进阶* [章节 3](chapter3/README.md) 编写文章内容接下来就可以在相应的 md 文件里书写内容了。 5. 启动 gitbook 本地服务写完内容，可以通过以下方式来预览书本：1gitbook serve gitbook serve 命令实际上是先调用 gitbook build 编译书籍，然后启动一个 web 服务器，监听在本地的4000端口。 gitbook 进阶以上所说的都是在本地的操作，如何让别人也可以访问自己的书籍，除了自己买域名，还可以利用现有的互联网平台：gitbook.com、 github.com、 gitlab.com（gitlab也是听说可以有 gitlab pages，没有实际操作过，先略过） 1. 在 gitbook.com 上发布和管理书籍 需要先注册 gitbook 账号。可以单独注册，也可以使用 github 账号关联登录。 然后先创建一个 Orgnization 。 再在这个 Orgnization 里面创建一个 Space（旧版叫 Book）。这个就是你的书籍项目了。 然后就可以在线写书了～书籍的在线浏览地址为：https://yourorgnizationname.gitbook.io/yourspacename 2. 在 github.com 上发布和管理书籍在前面说的本地操作，编辑和预览书籍后，可以把 build 之后的结果，上传到 github 上面，然后利用 github pages 来发布书籍。 首先在 github 上新建一个跟你的书籍同名的 repository。 然后将远程仓库地址添加到本地，然后将编译后的 _book 目录 push 到远程。 然后在 github 上设置一下 github pages，具体方法和步骤我在另一个文章中详细介绍过：如何给github项目建立自己的主页。 在设置完后，就可以通过 https://githubusername.github.io/projectname 来浏览你的书了。 3. gitbook 与 github 关联同步新版 gitbook.com 不支持本地版本管理了，但是对 github 的集成支持的不错。可以通过配置，实现在 github 项目里面提交内容，gitbook 平台会自动同步过去。 在 gitbook 平台里，进入要设置的 space，也就是你的书。 点左下角的配置按钮，进入配置，点击 Intergrations ，找到 github。 点击 link you github repository 按钮，根据向导，登录 github ，选择 reposirory，选择分支，完成绑定和同步。(你还可以选择是 gitbook 同步 github ，还是 github 同步 gitbook) 需要注意的是：绑定的 github 仓库分支里面要是 gitbook 的源码，也就是那些 md 文件。而不是 build 之后生成的 html 文件。]]></content>
      <categories>
        <category>工具</category>
        <category>GitBook</category>
      </categories>
      <tags>
        <tag>gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何给github项目建立自己的主页]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%A6%82%E4%BD%95%E7%BB%99github%E9%A1%B9%E7%9B%AE%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B8%BB%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[想给 github 项目发布一个可访问的地址，网上的资料虽然多，但是乱。总的来讲，分为两种方法：一种是通过 github 的 htmlpreview 插件来展示。另一种就是通过 github pages 来展示。关于 github pages 网上很多人对它有误解，认为一定要先创建 username.github.io 这个 repository 才可以，其实并不需要；还有人认为一定要把要展示的静态资源放在项目的 gh-pages 分支上才可以，其实也不用。 总结一下我利用 github pages 给自己的项目创建主页的方法。 步骤如下： 1. 在 github 上建立项目 repository。2. 进入该 repository 的 Settings。3. 在 Options 里面， 找到 GitHub Pages。4. 为项目选择用于主页的分支， 然后保存。5. 然后就可以在浏览器输入 https://username.github.io/projectname 来访问项目主页了。 当然前提是在该分支下有用于展示的 html 文件，比如 index.html 另附上 github 的 htmlpreview 地址：https://htmlpreview.github.io/]]></content>
      <categories>
        <category>工具</category>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>github pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在mac上查看隐藏文件]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%A6%82%E4%BD%95%E5%9C%A8mac%E4%B8%8A%E6%9F%A5%E7%9C%8B%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在 Finder 里，按 Cmd + Shift + . 即可切换隐藏文件的显隐。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(三)：博客域名升级]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%BF%9B%E9%98%B6-%E4%B8%89-%EF%BC%9A%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[购买域名，我是在阿里云上购买的，.com域名。 先查询你想的域名是否已经被注册，如果有那就要另想一个了。 选择购买时长，一次买长一点的好像比一年一年买要划得来，而且也不容易被别人抢注。 然后购买，购买前要实名认证。 配置DNS，添加记录，将github page域名添加进去。 github上配置custom domain，设置为新购买的域名。 hexo source里添加CNAME文件，内容为新购买的域名。]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>domain</tag>
        <tag>hexo</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用json-server+faker模拟API服务和数据]]></title>
    <url>%2F2018%2F09%2F26%2F%E5%88%A9%E7%94%A8json-server-faker%E6%A8%A1%E6%8B%9FAPI%E6%9C%8D%E5%8A%A1%E5%92%8C%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>json-sever</tag>
        <tag>faker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript中的Date]]></title>
    <url>%2F2018%2F09%2F26%2Fjavascript%E4%B8%AD%E7%9A%84Date%2F</url>
    <content type="text"><![CDATA[chrome下结论： 1. 日期有前置0，则会解析为 UTC 时间，没有前置0，则会解析为本地时间。例如new Date(&#39;2018-09-26&#39;).getTime() 获取的是距离1970年1月1日0点UTC时间。new Date(&#39;2018-9-26&#39;).getTime() 获取的是距离1970年1月1日0点本地时间。 2. Date.now()、 +new Date()、 new Date().getTime(), 获取的都是距离1970年1月1日0点本地时间。 检验依据：Date.UTC() 该方法使用的是UTC时间。而 Date.UTC(2018, 8, 26) 跟 Date.now()、 +new Date()、 new Date().getTime() 获得的值相差8个小时。 ie下 结论： 1. 不支持非UTC格式的 new Date().2. 并且 Date.now()、 +new Date()、 new Date().getTime() 获取的都是距离1970年1月1日0点的UTC时间。 检验依据：而 Date.UTC(2018, 8, 26) 跟 Date.now()、 +new Date()、 new Date().getTime() 获得的值在同一个时区。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>Date</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10下中文输入法简繁切换快捷键]]></title>
    <url>%2F2018%2F09%2F26%2Fwin10%E4%B8%8B%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E7%AE%80%E7%B9%81%E5%88%87%E6%8D%A2%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[在中文输入法下，按 ctr+shift+f 。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git reflog]]></title>
    <url>%2F2018%2F09%2F25%2Fgit-reflog%2F</url>
    <content type="text"><![CDATA[git log 查看的是 commit 记录。git reflog 查看的是所有的 HEAD 改变的记录。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reflog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让本地分支与远程分支建立映射关系]]></title>
    <url>%2F2018%2F09%2F25%2F%E5%A6%82%E4%BD%95%E8%AE%A9%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF%E4%B8%8E%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF%E5%BB%BA%E7%AB%8B%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[git 建分支很 cheap，本地和远程都常常各自拥有大量分支，有时本地分支需要跟某个新的远程分支建立追踪映射，以便于在 pull、 push 等操作时，简化命令，也在一定程度上防止误传到其他分支。今天建立了新的远程分支，本地不想弄一个新的跟它对应，想用当前分支换个关联，用到了该技能。 核心命令1git branch --set-upstream-to=[remote-name/remote-branch-name] 详解: 完成同样效果的命令还有： git 1.8 以上123git branch -u [remote-name/remote-branch-name]# or 如果要关联的本地分支不是当前分支git branch -u [remote-name/remote-branch-name] [local-branch-name] 如果比较喜欢比较长的命令写法(我比较喜欢，是不是很变态，哈哈)，可以：123git branch --set-upstream-to=[remote-name/remote-branch-name]# or 如果要关联的本地分支不是当前分支git branch --set-upstream-to=[remote-name/remote-branch-name] [local-branch-name] 例如，我有个本地分支 dev，想跟远程 origin 的 v1.1 关联：123456789#如果当前就在 dev 分支上：git branch -u origin/v1.1#orgit branch --set-upstream-to=origin/v1.1#如果当前不在 dev 分支上：git branch -u origin/v1.1 dev#orgit branch --set-upstream-to=origin/v1.1 dev git 1.7 以上（已经在2.几版本停用）1git branch --set-upstream dev origin/v1.1 如果要在 check 分支的时候进行映射check 到与远程分支同名的本地分支 v1.11git checkout --track origin/v1.1 #git 1.6.2 以上 check 到与远程分支不同名的分支 dev21git checkout -b dev2 origin/v1.1 查看本地分支与远程分支的映射情况1git branch -vv]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让远程仓库回退到某个之前的版本]]></title>
    <url>%2F2018%2F09%2F23%2F%E5%A6%82%E4%BD%95%E8%AE%A9%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E5%9B%9E%E9%80%80%E5%88%B0%E6%9F%90%E4%B8%AA%E4%B9%8B%E5%89%8D%E7%9A%84%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[pull 代码再次遇到冲突，这次突发奇想，想试试用 git stash 来处理，结果 push 完，队友反映她 pull 后好多代码被重置，并且遇到严重冲突，受牵连70几个文件。我查看了下 commit 记录，惊讶地发现，我处理完冲突传上去的代码确实都变成了我本地的老代码，pull 下来的修改都被我重置了。都是乱用 git stash 的错。。还好发现的及时，我立即决定撤回远程仓库中我的那次 push，让代码回滚到我 push 前的状态。一番资料查找，顺利搞定。 只需五步，方法如下： 1. 查看 commit 日志，确定要回滚到的 commit id（前7位即可）1git log --oneline 找到要回到的那次 commit ，复制 commit id，比如我这里是 b8b2df7 2. 先备份下当前版本12git checkout -b old_devgit push origin old_dev:old_dev 3. 本地回滚到指定代码版本 1git reset --hard b8b2df7 4. 删除远程对应的分支123git push origin :dev//orgit push origin --delete dev 5. 重新创建远程分支1git push origin dev:dev 搞定！ 或者，不使用删除分支再建分支的方法，这个要两部，有些麻烦，可以使用强制推送，只需一步：1git push origin dev:dev -f #因为reset后本地仓库落后于远程仓库，因此要强制提交]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何撤销 git add 和 git commit]]></title>
    <url>%2F2018%2F09%2F19%2F%E5%A6%82%E4%BD%95%E6%92%A4%E9%94%80-git-add-%E5%92%8C-git-commit%2F</url>
    <content type="text"><![CDATA[由于心急，提交代码的时候，commit 后，发现多提交了一个文件，然后第一想法是使用 rebase 来修改提交，然后我把那个多提交的文件，恢复成修改前的样子，然后打算在 git add . 之后进行 rebase ，结果查看状态发现，它把我之前在编辑器里面忽略的一个文件也给加进来了…所以这个时候，我既多 commit 了， 又多 add 了…蜜汁尴尬… 经过查找资料，问题解决，又 get 到 git 的新技能. 1. git add 多了 git status 查看下 add 的文件 git reset HEAD 如果后面什么都不跟，就是把上一次的 git add 全部撤销。or git reset HEAD xxx/xxx/xxx.js ，则撤销某个文件的add。这对add了一批文件后，又删除了其中的某个文件，想取消对这个文件的add的情况非常适用。 2. git add 多了之后，又 commit 了 先使用 git log --oneline 查看节点，找到这次 commit 的上一次 commit 记录。 然后 git reset commit_id 。退回到某一个提交的节点，代码还是现在的样子，只是那个节点之后的commit日志没有了，git add 的暂存区也清掉了，那次节点之后的所有改动都放在了当前工作区。即需要重新 git add 到暂存区，再commit。 git reset 有三个参数可选：--hard --soft --mixed，不跟参数就是默认的--mixed。 3. 使用 git revert 还原已经提交的修改（这个没有验证过）使用 git revert 后，此次操作之前和之后的 commit 和 history 都会保留，并且把这次撤销作为一次最新的提交。 git revert HEAD 撤销前一次 commit git revert HEAD^ 撤销前一次 commit git revert commit_id 撤销指定的版本，撤销也会作为一次提交进行保存。git revert 是提交一个新的版本，将需要 revert 的版本的内容再反向修改回去，版本会递增，不影响之前提交的内容。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reset</tag>
        <tag>revert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(二)：hexo博客配置]]></title>
    <url>%2F2018%2F09%2F19%2F%E8%BF%9B%E9%98%B6-%E4%BA%8C-%EF%BC%9Ahexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[进阶(二)：hexo博客配置 进阶配置内容： 添加评论系统 添加 tags 页面 添加 categories 页面 添加 about 页面 配置404页 设置 ‘阅读全文’ 配置博客文档模版 1. 添加评论系统hexo官方提供了很多评论系统的配置，我选择的是’来必力’。我先注册了来必力，然后创建了一个 liverre city，获取到代码中的 data-uid ，然后编辑 hexo 主题配置文件 _config.yml , 编辑 livere_uid :1liverre_uid: #我在来必力获取的uid 2. 添加 tags 页面 在终端： 1hexo new page tags 在生成的 tags 目录下，编辑 index.md ，设置 type 属性为 tags，并屏蔽该页的评论功能： 123456---title: 标签date: 2018-09-19 22:51:31type: &quot;tags&quot;comments: false--- 在 _config.yml 文件中，编辑 menu 字段，放开 tags： 123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags #categories: /categories/ || th #about: /about/ || user || 左侧是页面路径，|| 右侧是图标在 FontAwesome 字体中的名称。 3. 添加 categories 页面 在终端： 1hexo new page categories 在生成的 categories 目录下，编辑 index.md ，设置 type 属性为 categories ，并屏蔽该页的评论功能： 123456---title: 分类date: 2018-09-19 22:51:31type: &quot;categories&quot;comments: false--- 在 _config.yml 文件中，编辑 menu 字段，放开 categoris 字段： 123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th #about: /about/ || user 4. 添加 about 页面 在终端： 1hexo new page about 在生成的 about 目录下，编辑 index.md ，屏蔽该页的评论功能： 12345---title: 标签date: 2018-09-19 22:51:31comments: false--- 在 _config.yml 文件中，编辑 menu 字段，放开 about 字段： 123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th about: /about/ || user about页面的设置Tip注意：about页面还有一些地方要处理，因为 Next主题中 默认会把页面跟文章一样处理，当你在yml中设置了显示文章目录时，自定义页面也会统一被添加toc目录（这是我不想要的）。于是我DIY了一下： 在 about页 的 index.md 文件头部加上自定义属性 toc: false; 123456---title: date: 2018-09-19 21:35:29toc: falsecomments: false--- 然后找到 themes/next/layout/_macro 目录下的 sidebar.swig 模版文件，将 toc 渲染条件由 1&#123;% set display_toc = is_post and theme.toc.enable or is_page and theme.toc.enable %&#125; 改为 1&#123;% set display_toc = is_post and theme.toc.enable or page.toc !== false %&#125; 重启 hexo 服务，刷新 about 页，即可看到不再显示右侧的toc目录了。 5. 配置404页给自己的站点设置404页面，可以让网站体验更加友好。hexo中配置404页的步骤很简单，在/source目录下，或者themes/next/source 目录下创建 404.html 文件即可。404页面的内容可以发挥自己的创意个性来设计，也可以利用404为社会公益做一些贡献。我放的是腾讯公益，帮助找回走失儿童，页面代码如下：12345678910&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;404&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; homePageName=&quot;返回首页&quot; homePageUrl=&quot;https://www.champyin.com&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 6. 设置 ‘阅读全文’效果：在首页提供文章的部分内容，并提供一个链接跳转到全文页面。在 NextT 中提供了三种方式，我比较喜欢它推荐的那种，也是 Hexo 提供的方式：在文章中使用 &lt;!-- more --&gt; 手动进行截断。 7. 配置博客文档模版hexo 中，运行 hexo new &quot;xxx&quot; 是调用了 scaffolds 目录下的 post.md 文件作为模版来创建的。所以修改这个模版，就可以达到每次创建文档可以使用自己习惯的模版了。默认模版是没有 categories 的，我需要这个字段，所以在模版中加上了这个字段：123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags: categories:---]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何修改git中已经提交的内容]]></title>
    <url>%2F2018%2F09%2F11%2F%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9git%E4%B8%AD%E5%B7%B2%E7%BB%8F%E6%8F%90%E4%BA%A4%E7%9A%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[今天在git上提交代码的时候，不小心在 commit message 中打了几个错别字，merge、push 完了才发现。。 由于我的完美主义加强迫症比较严重，那几个错别字越看越不顺眼，寻思着把它们给改过来。查了资料，加上实验，终于搞定。 只需五步，方法如下： 修改某次提交的 commit message需要注意的是：没有办法修改整个项目的第一条日志。第2次以后的信息都可以通过此方法修改。 1. 查看提交的 commit id (SHA值)如果 push 过，可以在git托管平台（比如 github、gitlab)上的 commits 里面看到（那串40位的编码就是了），只需要其前7位。或者直接通过 git log 命令查看：1git log --oneline 在展示的结果上每条 log 记录的前面的字段就是我们需要的 SHA 值。123456$ git log --onelineb8b2df7 (HEAD -&gt; master, origin/master) 中文dd09519 di sici tijiaof1d9380 english only modify again..ea8a3b5 nonono correct message66a4488 need to be changed message 比如我要修改的那条 commit 的 SHA 为：dd09519那我需要的是这一条之前的一条 commit 的 SHA ：f1d9380 2. 通过 git rebase 命令回到要修改提交的上一次提交的基础上 1git rebase -i f1d9380 等待一会，然后会打开 vim 编辑器，12345678910111213141516171819202122232425262728pick dd09519 di sici tijiaopick b8b2df7 中文# Rebase f1d9380..f52c471 onto f1d9380 (2 commands)## Commands:# p, pick &lt;commit&gt; = use commit# r, reword &lt;commit&gt; = use commit, but edit the commit message# e, edit &lt;commit&gt; = use commit, but stop for amending# s, squash &lt;commit&gt; = use commit, but meld into previous commit# f, fixup &lt;commit&gt; = like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec &lt;command&gt; = run command (the rest of the line) using shell# d, drop &lt;commit&gt; = remove commit# l, label &lt;label&gt; = label current HEAD with a name# t, reset &lt;label&gt; = reset HEAD to a label# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]# . create a merge commit using the original merge commit&apos;s# . message (or the oneline, if no original merge commit was# . specified). Use -c &lt;commit&gt; to reword the commit message.## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.### Note that empty commits are commented out 在编辑器中找到你要修改的那个提交信息，用 i 命令进入编辑，将那一行开头的 pick 改为 edit: pick dd09519 di sici tijiao -&gt; edit dd09519 di sici tijiao然后 esc -&gt; : -&gt; wq, 保存退出。 然后界面显示如下：123456789$ git rebase -i f1d9380Stopped at dd09519... di sici tijiaoYou can amend the commit now, with git commit --amendOnce you are satisfied with your changes, run git rebase --continue 3. 修改 commit message：1git commit --amend 再次进入 vim 编辑器，1234567891011121314151617di sici tijiao# Please enter the commit message for your changes. Lines starting# with &apos;#&apos; will be ignored, and an empty message aborts the commit.## Date: Tue Sep 11 18:49:29 2018 +0800## interactive rebase in progress; onto f1d9380# Last command done (1 command done):# edit 4df3762 中文信息 sici tijiao# Next command to do (1 remaining command):# pick f52c471 中文# You are currently editing a commit while rebasing branch &apos;master&apos; on &apos;f1d9380&apos;.## Changes to be committed:# modified: README.md# 可以看到第一行就是要修改的 commit message。同样的通过 vim 命令 进入编辑模式，修改提交信息: di sici tijiao -&gt; 中文信息 sici tijiao然后:wq 保存退出。1234$ git commit --amend[detached HEAD 4df3762] 中文信息 sici tijiao Date: Tue Sep 11 18:49:29 2018 +0800 1 file changed, 0 insertions(+), 0 deletions(-) 4. 完成 rebase：1git rebase --continue 等待一会，然后出现：12$ git rebase --continueSuccessfully rebased and updated refs/heads/master. 表明操作成功。 5. 将修改后的变动 push 到远程1git push origin master -f 注意一定要使用 -f 参数，表示强制推送。因为我们没有产生新的 commit（用 git status 可以看出），直接 push 不会发送任何东西。 6. 现在我们去远程仓库刷新下 commit 记录，可以看到 commit 信息就已经修改了。最后，我们再来看下我们的日志信息1git log --oneline 细心点就会发现，从我们修改的那条 commit 起，之后的所有的 commit 的 commit id 都发生了变化！我修改的那条，由 dd09519 变成了 4df3762; 而它之后的那条记录也由 b8b2df7 变成了 f52c471 虽然我没由修改这条 commit 信息。git log --oneline12345f52c471 (HEAD -&gt; master, origin/master) 中文4df3762 中文信息 sici tijiaof1d9380 english only modify again..ea8a3b5 nonono correct message66a4488 need to be changed message BTW 还要说一个要注意的 就是如果 commit 信息要输入中文，记得用 git bash。因为我是在 IDE（webstorm）上进行的 commit，用的中文（要不怎么有错别字呢），那在修改 commit 信息的时候，我仍想用中文，我用 cmd、powerShell、Cmder，都试了，没法在 vim 里面敲中文，直接乱码，查资料改配置（quotepath = false、[gui] encoding = utf8）等等都没用，最后怀着绝望的心情，试了下 git bash， 居然中文支持的非常好！真是。。 另外，在查资料的过程中，还顺便 get 到几个 git 的高级技能。总结如下：1. 修改最近一次的提交方法一：commit –amend这种方法不仅可以修改 commit message，也可以修改提交内容。这种方式在还没有推送到远端的情况下，可以保持原有的 Change-Id（commit id）。若已经推送到远端，Change-Id 则会修改掉。12345# 修改需要修改的项目代码(如果只需要修改 commit message 就不用做)git add . #如果只需要修改 commit message 就不用做git commit --amend# 在出现的 vim 编辑器中修改 commit message，保存退出。git push &lt;remote&gt; &lt;branch&gt; -f #若还没有推送到远端，就不用做 方法二：reset这种方法也可以修改提交内容和 commit message。这种方式在还没有推送到远端的情况下，也可以保持原有的 Change-Id（commit id）。若已经推送到远端，Change-Id 则会修改掉。12345git reset HEAD^# 修改需要修改的项目代码(如果只需要修改 commit message 就不用做)git add . # 如果只需要修改 commit message 就不用做git commit -m “new commit message”git push &lt;remote&gt; &lt;branch&gt; -f # 若还没有推送到远端，就不用做 2. 提交到了错误的分支上的处理方法一：reset + stash123456789# 取消最新的提交， 然后保留现场原状git reset HEAD~ --softgit stash# 切换到正确的分支git checkout name-of-correct-branchgit stash popgit add .git commit -m &quot;new commit message&quot;# 现在你已经提交到正确的分支上了 方法二：cherry-pick 摘樱桃123456git checkout name-of-correct-branch# 把主分支上的最新提交摘过来～git cherry-pick master# 再删掉主分支上的最新提交git checkout mastergit reset HEAD~ --hard]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>rebase</tag>
        <tag>amend</tag>
        <tag>cherry-pick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用express/koa快速起一个node服务]]></title>
    <url>%2F2018%2F09%2F11%2F%E4%BD%BF%E7%94%A8express-koa%E5%BF%AB%E9%80%9F%E8%B5%B7%E4%B8%80%E4%B8%AAnode%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[expressexpress 导出的是一个函数。 1. 最简单的服务1npm i express 123456789// www.jsconst express = require(&apos;express&apos;);const app = express();app.get(&apos;/&apos;, (req, res) =&gt; &#123; res.end(&apos;server by express&apos;);&#125;)app.listen(3000); 2. 使用 express-generator12345npm i expressnpx express-generator //需要nodejs8.2及以上//nodejs8.2以下：//npm i -g express-generator//express --view=ejs myproject 会在当前目录下生成一个项目，7个文件夹，9个文件：12345678910111213141516|--app.js|--bin/| |-- www.js|--package.json|--public/| |-- images/| |-- javascript/| |-- stylesheets/| |-- style.css|--routes/| |-- index.js| |-- users.js|--views/ |-- error.jade |-- index.jade |-- layout.jade 然后1234npm iDEBUGE=projectname:* npm start//在windows下这样：//set DEBUG=projectname:* npm start koakoa导出的是一个对象。 最简单的服务1npm i koa 123456789// www.jsconst Koa = require(&apos;koa&apos;);cnost app = new Koa();app.use((ctx) =&gt; &#123; ctx.body = &apos;server by koa&apos;;&#125;)app.listen(3000);]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>node</tag>
        <tag>express</tag>
        <tag>koa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git错误：HTTP Basic: Access denied]]></title>
    <url>%2F2018%2F09%2F10%2Fgit%E9%94%99%E8%AF%AF%EF%BC%9AHTTP-Basic-Access-denied%2F</url>
    <content type="text"><![CDATA[上周五修改了gitlab的用户密码，今天发现操作git远程仓库都报错拒绝，错误信息如下：12remote: HTTP Basic: Access deniedfatal: Athentication failed for &apos;https://************&apos; 直觉告诉我，是改密码引起。网上查了资料，确实 git 会把第一次输入过的用户名密码存储起来，再次使用 git 命令的时候，会使用存储的用户名密码，然而当 git 的密码修改后，原来存储的密码肯定匹配不了，于是直接报没有权限终止操作。网上类似的帖子很多，但是不是都有效，在多次尝试后，终于解决，解决办法如下： 首先我因为有两台电脑，一台 win7，一台 win10，不同操作系统解决方式还不一样，也是坑了我很多时间。。。 win 10 下的解决办法 解决办法很简单，一句命令搞定：1git config --system -unset credentia.helper 不过要注意的是在 win10 中，这个命令需要在管理员权限下运行，否则报错：1error: could not lock config file C:/Program Files/Git/migw64/etc/gitconfig: Permission denied 在 linux 下使用 sudo 可以切换到管理员权限，但是在 win10 上，只能先找到 cmd 的快捷方式，然后右键，以管理员身份运行。比如，在左下角windows符号上右键 -&gt; Windows PowerShell(管理员)。 运行后，命令的前面的路径会显示为：PS C:\Windows\system32&gt; win 7 下的解决办法使用刚才在 win 10 上的解决办法，在 win 7 上尝试无效。。。win 7 下采用的办法是直接修改凭据： 进入 控制面版 -&gt; 所有用户 -&gt; 凭据管理 在 Windows 凭据 下，找到 gitlab 对应的凭据 点 编辑，修改密码，保存。 done。 然后执行下刚才的 git pull 命令，妥妥滴拉下来。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>access denied</tag>
        <tag>authentication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码片段]]></title>
    <url>%2F2018%2F09%2F06%2F%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[1. 文字截断12345.ellipsis &#123; overflow: hidden; white-space: nowrap; text-overflow: ellipsis;&#125; 2. 清除浮动12345678.clearfix &#123; zoom: 1;&#125;.clearfix:after &#123; clear:both; content: &quot;&quot;; display: block;&#125; 3. javascript 生成 img 标签的3种方式方式1: 使用 createElement 方法 123var img = document.createElement(&apos;img&apos;);img.src = &apos;https://www.baidu.com/img/bd_logo1.png&apos;document.body.appendChild(img); 方式2: 使用 innerHTML 方法12var imgHtml = &apos;&lt;img src=&quot;https://www.baidu.com/img/bd_logo1.png&quot; &gt;&apos;;document.body.innerHTML = imgHtml; 方式3: 使用 new image() 方法123var img = new image();img.src = &apos;https://www.baidu.com/img/bd_logo1.png&apos;;document.body.appendChild(img); 4. js 添加、删除 class方法1: 比较传统的方法123456789101112var classVal = docment.getElementById(&apos;id&apos;).getAttribute(&apos;class&apos;);// 删除某个classvar classVal = classVal.replace(&apos;someclassname&apos;, &apos;&apos;);document.getElementById.setAttribute(&apos;class&apos;, classVal);// 添加classvar classVal = classVal.concat(&apos;newclassname&apos;);document.getElementById.setAttribute(&apos;class&apos;, classVal);// 替换classvar classVal = classVal.replace(&apos;someclassname&apos;, &apos;newclassname&apos;);document.getElementById.setAttribute(&apos;class&apos;, classVal); 方法2: HTML5中添加了classListclassList 属性返回元素的雷鸣，作为DOMTokenList对象。classList 属性是只读的，但是可以使用 add() 和 remove() 方法修改它。12345// 增加document.getElementById(&apos;id&apos;).classList.add(&apos;class1&apos;, &apos;class2&apos;, &apos;class3&apos;);// 删除document.getElemtnById(&apos;id&apos;).classList.remove(&apos;class1&apos;); 方法3: 正则匹配…]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>front-end</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web端页面如何在移动端也获得较好体验]]></title>
    <url>%2F2018%2F09%2F05%2Fweb%E7%AB%AF%E9%A1%B5%E9%9D%A2%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A7%BB%E5%8A%A8%E7%AB%AF%E4%B9%9F%E8%8E%B7%E5%BE%97%E8%BE%83%E5%A5%BD%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[在网页的 head 标签里，加上对 viewport 的设置，就可以让页面在移动设备上可以以比较好的缩放和比例来呈现：1&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; &gt; 还可以加入更多设置，如缩放之类： 1&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes&quot; &gt; 参数解释：width：可以控制 viewport 的大小，可以指定一个数值，或者一个特殊的值，比如 device-width 设备的宽度。initial-scale：初始缩放比例，也即当前页面第一次load的时候缩放比例minimum-scale：允许用户缩放到的最小比例。maximum-scale：允许用户缩放到的最大比例。user-scalable：用户是否可以手动缩放。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>html</tag>
        <tag>viewport</tag>
        <tag>mobiles</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设置IDE编辑器以配合自动实时编译]]></title>
    <url>%2F2018%2F09%2F02%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEIDE%E7%BC%96%E8%BE%91%E5%99%A8%E4%BB%A5%E9%85%8D%E5%90%88%E8%87%AA%E5%8A%A8%E5%AE%9E%E6%97%B6%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[在前端开发过程中，通过webpack配置了即时监听并自动编译，实现保存文件触发编译。但是有的编辑器有 “安全写入” 的机制（就是在编辑器保存文件后不直接写入硬盘，而是先保存在编辑器内部的缓存里面，到一定时间后再写入硬盘），这会造成触发编译不那么实时，很影响开发效率。 以下是针对几款常见编辑器，如何禁用安全写入的设置办法： JetBrains IDEs（e.g. WebStorm): 在 Preferences &gt; Appearance &amp; Behavior &gt; System Settings 里面，去掉对 “Use safe write” 选项的勾选。即可。 Sublime Text3:在 preferences-user 文件里，添加 atomic_save: false。即可。 Vim：在 setting 文件里，添加 :set backupcopy=yes 。即可。]]></content>
      <categories>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>webstorm</tag>
        <tag>sublime</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git冲突处理]]></title>
    <url>%2F2018%2F08%2F30%2Fgit%E5%86%B2%E7%AA%81%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[git冲突处理 今天在merge分支的时候，由于记忆错位，导致merge了另一个分支到master（我原本是要把format分支合并到dev分支），造成了冲突。看到几百个文件的modify想死的心都有，差点想重新clone重新来过。。。好在理智战胜冲动，决定正面处理冲突，而不是消极回避。而在处理完冲突之后，发现异常的简单，庆幸没有冲动乱来。 言归正传。 我在merge的时候git的提示是：12345err： Your local changes to the following files would be overwritteen by merge: bla bla blaPlease commit your changes or stash them before you merge.AbordingUpdating xxxxxxx(some hashcode) 解决方案有三种： 第一种： 提交修改1git commit -m &quot;my message&quot; 第二种： stash备份当前工作区的内容，从最近的一次提交种读取相关内容，当工作去保证和上次提交的内容一致。同时，将当前的工作区内容保存到Git栈中。然后执行merge，然后再从Git栈中读取最近一次保存的内容，恢复工作区的相关内容。1git statsh 然后执行之前未执行完的merge操作：1git merge xxx 然后拉取stash：1git stash pop 由于可能存在多个stash的内容，所有用栈来管理，pop会从最近的一个stash中读取内容并恢复。可以用 git stash list 来查看Git栈内的所有备份，可以利用这个列表来决定从哪个地方恢复。git stash clear 可以清空Git栈。 第三种： 忽略本地修改123git reset --hard// orgit checkout -t -f remote/branch Or 忽略只忽略特定的文件1git checkout filename 我当然使用的是stash的方式。 在 master 分支上使用 git stash, 然后 git merge dev, 成功merge！ 然后恢复工作区 git stash pop, 然后多出了很多modify的文件，还有一个标红的文件（冲突），不过它已经帮你解决好，只需要在文件中选择你要保留哪一段代码就好。 修改完冲突文件后， git add ., git commit -m &quot;conflict fixed&quot;. 最后，赶紧把这个解决完冲突后的代码传上远程仓库, WOO，松了一口气。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>conflict</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualbox如何挂载宿主机的文件夹]]></title>
    <url>%2F2018%2F07%2F17%2Fvirtualbox%E5%A6%82%E4%BD%95%E6%8C%82%E8%BD%BD%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[我的宿主机是一台windows操作系统的服务器。 虚拟机用的是virtualbox。 以前在 vmware 上面与宿主机的共享只需要在 wmware 上配置下共享文件夹就可以生效。但是在 virtualbox 上，除了配置共享文件夹，还要使用 mount 命令进行挂载才能与宿主机共享一个文件夹。 1. 在宿主机建立一个用于与virtualbox共享的文件夹，例如 myshared。并在里面新建一个空的文本 a.txt，用于检测最后挂载是否成功。2. 在virtualbox中选择 设备 -&gt; 共享文件夹 -&gt; 打开设置界面。3. 点击右侧 + 号，添加共享文件夹，选择宿主机上之前建好的 myshared 文件夹，并勾选 固定分配 。4. 在linux虚拟机中，打开终端，在mnt目录下新建一个目录 shared：1sudo mkdir /mnt/shared 5. 执行挂载：1sudo mount -t vboxsf myshared /mnt/shared 6. 挂载成功，进入shared目录，就可以看到a.txt文件了。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下如何切换到root用户]]></title>
    <url>%2F2018%2F07%2F16%2Flinux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%88%87%E6%8D%A2%E5%88%B0root%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[如果只是想要临时使用一下root权限，只需要在命令前面加上 sudo 就可以了。 如果想要一直使用root权限，需要通过su切换到root用户： 首先要重设root用户的密码1sudo passwd root 然后根据提示，输入新的root密码（可以是原来的root旧密码） 然后就可以随时切换到root用户了1su 输入root用户密码即可。 回到用户权限使用 su &quot;yc&quot; 或者 exit 命令，即可回到用户权限。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2018%2F07%2F16%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[记录常用的liux命令，不定期更新。 一、 rm删除文件或文件夹 删除文件夹，无论文件夹是否为空1rm -rf 目录路径 说明：-r 就是向下递归的意思；-f 就是强制删除，不做任何提示的意思。 注意：使用 rm -rf 命令一定要格外小心。linux没有回收站，删除之后再找回就难了。 删除文件1rm -f 文件路径 二、lsls是 list segment 的缩写，用于列出文件。 列出当前目录下每个文件的大小以及当前目录文件下所有文件大小总和。1ls -lht 与以下命令是同一个效果：1ls -l -h -t ls的常用参数常用参数： -a, –all 列出目录下的所有文件，包括以 . 开头的隐含文件 -A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。 -c 配合 -lt：根据 ctime 排序及显示 ctime (文件状态最后更改的时间)配合 -l：显示 ctime 但根据名称排序否则：根据 ctime 排序 -C 每栏由上至下列出项目 –color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是’never’、’always’或’auto’其中之一 -d, –directory 将目录象文件一样显示，而不是显示其下的文件。 -D, –dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G, –no-group 不列出任何有关组的信息 -h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=方式 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i, –inode 印出每个文件的 inode 号 -I, –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小。 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息 -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r, –reverse 依相反次序排列 -R, –recursive 同时列出所有子目录层 -s, –size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 以下是可选用的 WORD 和它们代表的相应选项： extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t 以文件修改时间排序 -u ： 配合 -lt:显示访问时间而且依访问时间排序 配合 -l:显示访问时间但根据名称排序 否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w, –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何重置gitlab用户密码]]></title>
    <url>%2F2018%2F07%2F15%2F%E5%A6%82%E4%BD%95%E9%87%8D%E7%BD%AEgitlab%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[之前有提到，我为我们部门搭建了一个gitlab，前几天有用户跟我反映，他忘记密码了，使用gitlab自带的找回密码功能无果，收不到邮件，估计跟公司内网有一些关系，也可能是我没有配置好邮件联动。anyway，现在去配置邮箱感觉花的时间有些来不及。想着作为管理员，应该有权限和办法去重置用户的密码的，于是查询了资料，果然不出所料。方法如下，只需4步： 1. 首先进入Ruby on Rails console：使用root权限进入gitlab所在的linux服务器，打开一个终端，输入以下命令1&gt; gitlab-rails console production 然后等待ruby的console界面加载出来。 2. 然后你有好几种方法去查找用户。方法一，使用id：1irb(main):001:0&gt; user = User.where(id:[user&apos;s register index]).first 方法二，使用邮箱：1irb(main):001:0&gt; user = User.where(email:[user&apos;s register email]).first 方法三，使用用户名：1irb(main):001:0&gt; user = User.where(name:[user&apos;s register name]).first 我这次使用的是邮箱1irb(main):001:0&gt; user=User.where(email:xxx@163.com).first 3. 修改密码12&gt; user.password = &apos;newpassword&apos;&gt; user.password_confirmation = &apos;newpassword&apos; 注意最好是将 password 和 password_confirmation 都重置，以确保完全修改生效。 4. 保存修改1&gt; user.save! 注意 ! 号也很重要，不加的话，你的修改不会推送到数据库。 现在退出 console 使用新的密码登录试试，可以登录啦。]]></content>
      <categories>
        <category>工具</category>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>gitlab</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何迁移git仓库]]></title>
    <url>%2F2018%2F06%2F20%2F%E5%A6%82%E4%BD%95%E8%BF%81%E7%A7%BBgit%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[如果你想从别的git托管服务哪里复制一份源代码到新的Git托管服务器上，可以使用git clone --mirror / git clone --bare 和 git push --mirror命令。 普通 git clone 不能下载所有分支，想要简单的克隆所有分支，可以用镜像方法。 做一个镜像仓库只需3步： 从原地址克隆一份裸版本库（假设在github）： 123git clone --bare git://github.com/username/project.gitorgit clone --mirror git://github.com/username/project.git 这两种方式都只是将裸仓库克隆下来，不会在本地生成目录结构。 在新的服务器上创建一个新项目。例如new-peoject。 以镜像推送的方式上传到新的git服务器上（假设在gitlab）： 12cd prioject.gitgit push --mirror git@gitlab.com/username/new-priject.git done! 这种方式可以保留原版本远程仓库中的所有内容。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm 删除已发布的包或者包的某个版本]]></title>
    <url>%2F2018%2F06%2F08%2Fnpm-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%8F%91%E5%B8%83%E7%9A%84%E5%8C%85%E6%88%96%E8%80%85%E5%8C%85%E7%9A%84%E6%9F%90%E4%B8%AA%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[删除已发布的包的某个版本：1npm unpublish xxx@x.x.x 删除这个版本后，不能再发布同版本的包，必须要大于这个版本号的包才行。 删除已发布的包：1npm unpublish xxx 删除这个包之后，不能再发布同名的包。 注意：npm unpublish 仅在包发布后的24小时内有效。如果超过了24小时，则要联系npm官方去取消发布了。]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>unpublish</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过NPM安装私有模块]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87NPM%E5%AE%89%E8%A3%85%E7%A7%81%E6%9C%89%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[如何通过NPM安装私有模块可以有3种方案： 方案一：购买npm付费账号根据npm的价格方案，只要是付费用户，不论是哪一种，都可以下载和发布不限量的私有模块。所有的私有模块都是scoped package。scope是npm的新特性。如果一个模块的名字以 @ 开头，那它就是一个scoped package:1@scope/project-name 每一个npm用户都有拥有一个自己的scope：当前用户名username。 初始化一个scoped-package通过在包名字前添加scope：123&#123; &quot;name&quot;: &quot;@usernane/project-name&quot;&#125; 也可以使用 npm init 命令自定义 --scope 选项来设置scope：1npm init --scope=username 如果你在大多数时候使用的scope都是相同的，可以设置一个默认的scope，这样每次初始化的时候会自动使用该scope：1npm config set scope &lt;your_scope&gt; 发布scoped模块跟发布普通模块一样：1npm publish 默认状态下scoped package包是私有的。然而，你可以把scoped package免费的发布为共有包。只需要在发布时配置 --access 选项即可：1npm publish --access=public 提醒：发布之前首先一定要确保使用的是npm官方镜像源。如果你使用了nrm来管理镜像，可以通过nrm ls来查看下当前使用的是什么源，如果不是npmjs官方镜像，比如taobao，那么使用nrm use npm切换过来。 方案二：自建npm私服如果连仓库都是私有的，模块自然是私有的。这个方案好处就是可以建在自己公司内部，访问速度自然是杠杠的，而且想怎么定制就怎么定制。不过构建成本也是有的，而且需要服务器。一般稍微大规模的团队和公司会采取这种办法。 方案三：利用npm安装机制和git仓库这个方案最经济实惠。首先，npm install 支持 npm install &lt;git remote url&gt; ，其中 git remote url 的格式是：1&lt;protocol&gt;://[&lt;user&gt;[:&lt;password&gt;]@]&lt;hostname&gt;[:&lt;port&gt;][:/]&lt;path&gt;[#&lt;commit-ish&gt;] 即，如果你的代码托管在bitbucket中，可以通过如下命令安装模块：1npm install git+ssh://git@bitbucket.org/用户名／项目名.git#版本号 这种方式唯一的不足的地方就是，你必须要确保安装这个私有模块的机器由访问这个私有模块git仓库的权限。也就是说这台机器的公钥必须添加到git仓库中。如果你嫌添加公钥麻烦，也可以通过：1npm install git+https:username:password@bitbucket.org/用户名／项目名.git#版本号 不过密码就暴露出来了。]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件版本命名规范]]></title>
    <url>%2F2018%2F06%2F04%2F%E8%BD%AF%E4%BB%B6%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[软件版本阶段开发期 Base版此版本表示该软件仅仅是一个假页面链接，通常包括所有的功能和页面布局，但是页面中的功能都没有做完成的实现，只是作为整体网站的一个基础架构。 Alpha版软件的初级版本，此版本表示软件处于以实现软件功能为主的阶段，通常只在软件开发者内部交流，一般而言，该版本软件的bug较多，需要继续修改。测试人员条bug经开发人员修改确认后，发布到测试网址让测试人员测试，此时可将软件版本标注为alpha版。 Beta版此版本相对于alpha版已有了很大的改进，消除了严重的错误，但还存在着一些缺陷，需要经过多次测试来进一步消除，此版本主要的修改对象是软件的UI。 RC（Release Candidate）版最终测试版，此版本已经相当成熟了，基本上不存在导致错误的bug，与即将发行的正式版相差无几。可能成为最终产品的候选版本，如果未出现问题，则可发布称为正式版本，多数开源软件会推出两个RC版本，卒后的RC2则称为正式版本。 Release版此版本意味着“最终版本”，是最终交付用户使用的一个版本。该版本又是也称为标准版本。一般情况下Release不会以单词形式出现在软件封面上，取而代之的是符号（R）。 完成期 stable稳定版，来自于蓝版本修改修正完成。 GA（General Availability）正式发布的版本，在国外都是用GA来说明release版本的。 RTM（Release to Manufacturing）给生产商的release版本，RTM版本并不一定意味着创作者解决软件的所有问题，仍有可能在向公众发布前更新版本。另外一种RTM的称呼是RTM（Release To Web），表示正式版本的软件发布到Web网站上供客户免费下载。 RTL（Retail）零售版，是真正的正式版，正式降价零售版。 软件版本命名规范软件版本号由4部分组成：主版本号.子版本号.阶段版本号.日期版本号加希腊字母版本号（希腊字母版本号共有5种：base、alpha、beta、RC、release）。例如：1.1.1.180604_beta 版本号修改规则 主版本号：当功能模块有较大的变动，比如增加多个模块活着整体架构发生变化，此版本号有项目决定是否修改。 子版本号：当功能有一定的增加或变化。此版本由项目决定是否修改。 修订版本号：一般是bug修复或是一些小的变动，要经常发布修订版，时间间隔不限，修复一个严重的bug即可发布一个修订版。此版本由项目经理决定是否修改。 日期版本号：用于记录修改项目的当前日志，每天对项目的修改都需要更改日期版本号。此版本号由开发人员决定是否修改。 希腊字母版本号：此版本号用语标注当前版本的软件处于哪个开发阶段，当软件进入到另一个阶段时，需要修改此版本号。此版本号由项目决定是否修改。 注：上一级有变动时，下级要归零。]]></content>
      <categories>
        <category>规范</category>
      </categories>
      <tags>
        <tag>version</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设置linux虚拟机网络]]></title>
    <url>%2F2018%2F05%2F28%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AElinux%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"></content>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何搭建自己的gitlab服务]]></title>
    <url>%2F2018%2F05%2F27%2F%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84gitlab%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[什么是gitlabgitlab是一个开源的基于web的git仓库管理工具。gitlab拥有github拥有的一切，并且拥有更多。 如何搭建一个gitlab服务只需如下4步： 安装linux 安装gitlab 配置gitlab 启动gitlab 安装linuxgitlab必须安装在linux系统上，因此必须要有一个linux操作系统环境。gitlab目前支持的linux操作系统有： Ubuntu Debian CentOs openSUSE等。 安装虚拟机我的服务器不是linux系统，没有关系，可以使用虚拟机。虚拟机可以是oracle的virtual box，也可以是vmware。我选用的是virtual box。 获取linux操作系统安装文件我获取的是ubuntu 16.04 LTS desktop版（desktop/server都行） 在virtual box里安装ubuntu我在安装过程中，给ubuntu虚拟机分配了100G的硬盘容量。应为要作为代码托管的服务，所以尽量给大一点。 安装gitlabgitlab是开源的，可以去gitlab官网 https://about.gitlab.com/ 获取ubuntu版本的的安装镜像地址。安装方式可以在官网找到。这里大致贴一下。安装和配置依赖12sudo apt-get updatesudo apt-get install -y curl openssh-server ca-certificates 添加gitlab包，并安装1curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.deb.sh | sudo bash 因为我当时所在的网络不能访问该镜像地址，所以我按照官网的方式并没有成功。我在网上找了很多解决方案，最终通过安装离线包的方式安装成功。先将离线包下载下来，放到virtual box的共享目录mnt/share然后通过如下命令安装1sudo dpkg -i /mnt/share/gitlab-ce_10.1.4-ce.0_amd64.deb 安装成功后的终端信息显示如下： 配置gitlab要修改的配置都在／ect／gitlab/gitlab.rb这个文件里面。我这里主要是修改url为我自己服务器的域名以及端口（我为我的linux虚拟机申请了域名，具体操作见 如何设置linux网络）：找到gitlab.rb文件中的 EXTERNAL_URL 字段，将其修改为我的域名，端口设为80。 这样你的项目clone的地址中酒会变成你设置的域名而不是ip地址了。 然后运行如下命令让修改生效：1sudo gitlab-ctl reconfigure 启动gitlab最后通过如下命令启动gitlab1sudo gitlab-ctl start 查看一下gitlab各服务器状态1sudo gitlab-ctl status 最后可以在浏览器中输入localhost查看gitlab的界面了。首次访问gitlab界面，会要求你设置root账号的密码。 使用刚才重制后的root账号登录进入gitlab的界面 退出root账号的gitlab界面 至此，就完成了gitlab的整个搭建过程。可以愉快地在上面注册账号，创建项目，协作开发了！]]></content>
      <categories>
        <category>工具</category>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>git</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2018%2F04%2F25%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[git 常用命令记录。（持续更新） 1. 初始化1git init 2. 用户名邮箱配置设置全局用户属性:12git config --global user.name &quot;champyin&quot;git config --global user.email &quot;champyin@163.com&quot; –global: 设置当前用户的全局属性，当你的 repository 没有设置项目的 user.name 和 user.email 的时候，会默认用这个。 查看全局用户属性:12git config user.namegit config user.email 如何知道本地有没有设置属性：1git config --local --list 如何设置本地属性：12git config user.name &quot;champyin002&quot;gut config user.email &quot;champyin002@163.com&quot; 3. 远程仓库设置克隆远程仓库到本地1git clone &lt;remote-repo-url&gt; 查看当前配置有哪些远程仓库12git remote git remote -v git remote 列出每个远程仓库的简短名字。在克隆完某个项目后，至少可以看到一个名为 origin 的远程仓库git remote -v 显示对应的远程仓库地址。-v 为 -verbose 的简写。 添加远程仓库1git remote add [shortname] [url] [shortname]是自己为远程仓库取的一个简单的名字，便于以后引用。 修改远程仓库协议1git remote set-url origin git@github.com:lovecoding/lovecoding.github.io.git 将远程仓库origin改为git协议的地址。 查看远程仓库信息12git remote show [remote-name]git remote show origin #查看所克隆的origin仓库 重命名远程仓库（修改某个远程仓库在本地的简称）1git remote rename origin sam #把远程仓库 origin 重命名为 sam 对远程仓库的重命名，也会使对应的分支名称发生变化。原来的 origin／master 分支现在成为了 sam／master。 本地移除对应的远程仓库1git remote rm sam 4. 分支设置查看本地分支1git branch 查看各个分支最后一个提交对象的信息1git branch -v 查看远程分支1git branch -r 查看所有分支，包括本地和远程1git branch -a 创建分支1git branch mytest1 切换分支1git checkout mytest1 创建并切换到该分支1git checkout -b mytest2 删除空分支1git branch -d mytest1 删除有内容的分支，上方的命令会被拒绝，需要使用-D：1git branch -D mytest1 删除远程分支123git push origin --delete mytest1 //git v1.70 以上// orgit push origin :mytest1 //git v1.5.0以上 推送一个空的分支到远程分支。 同步远程删除的分支到本地123git remote prune [remote-name]#orgit fetch -p 查看分支于远程的映射关系1git branch -vv 5. 获取远程分支代码12git pull [remote-name] [remote-branch-name]:[local-branch-name]git pull origin bugfix:master 注意，分支推送、拉取命令的写法规则是&lt;来源地&gt;:&lt;目的地&gt;。所以 git pull 是[remote-branch-name]:[local-branch-name]，git push 是[local-branch-name]:[remote-branch-name]。 6. 上传代码到远程仓库push 某个分支12git push [remote-name] [branch-name]git push origin master # 把本地的master分支推送到远程的origin仓库的master分支。 如果远程有一个 bugfix 分支，我想要有一份自己的 bugfix 来开发。先将远程分支抓取下来：1git fetch origin 在远程分支的基础上分化一个新的本地分支：12git checkout -b [local-branch-name] [remote-name]/[remote-branch-name]git chechout -b bugfix origin/bugfix 采用此命令建立的本地分支会自动和远程分支建立映射关系。 修改完代码后，上传到远程 bugfix 分支：12345git push [remote-name] [branch-name]git push origin bugfix# orgit push [remote-name] [local-branch-name]:[remote-branch-name]git push origin bugfix:bugfix #实现跟上一条命令同样的效果。 git push origin bugfix 意思为取出在本地的 bugfix 分支，推送到远程仓库的 bugfix 分支中去。git push orign bugfix:bugfix 意思为上传完本地的bugfix分支到远程仓库中去，仍旧称它为 bugfix 分支。实现跟上一条命令相同的效果。通过此语法，可以把本地分支推送到某个命名不同的远程分支：例如使用git push origin bugfix:hotfix 来推送，如果远程分支 hotfix 不存在，则会在远程仓库被新建。当我的协作者再次从服务器上抓取数据时，他们将得到一个新的远程分支 origin／hotfix. push 所有分支（不管是否存在对应的远程分支，将本地的所有分支都推送到远程仓库）123git push --all [remote-name]#examplegit push --all origin 7. 打tag 注意：tag是打在commit上，不是分支上。 轻量级标签1git tag v1.0.0 给历史提交打标签1git tag v1.0.0 88aa731 #历史commit的id的前7位 查看标签1git tag 搜索符合模式的tag1git tag -l &apos;v0.1.*&apos; 将本地标签同步到远程仓库12git push origin --tags #提交所有的taggit push origin v1.0.0 #提交单个tag 切换到tag 与切换到分支命令相同 1git checkout [tagname] 查看tag信息 用 git show 命令 1git show v0.1.1 删除本地标签1git tag -d v1.0.0 将删除标签同步到远程1git push origin :refs/tags/v1.0.0 #推送空的同名版本到远程 拉取某个版本1git fetch origin tag v1.0.0 8. 查看提交历史日志1git log --pretty=oneline --abbrev-commit #将commit id显示为缩写（前7位） 退出查看日志1q 9. 删除本地untrack file1git clean -fd // 删除本地的untrack文件和文件夹 10. 修改已经提交的信息当你不小心写错了提交信息，理论上，SCM上是不应该修改历史信息的，但是在git中可以修改最后一次提交的信息。1git commit --amend amend 参数提供了对最后一次commit的修改，对于历史提交，如果想修改，就必须使用 rebase 了。1git rebase -i HEAD~3 #表示要修改当前版本的倒数第三次状态。 11. 取消对某个工作区文件的修改123git checkout -- &lt;file&gt;...// 例如:git checkout -- src/views/suport.vue 该指令的作用是把文件在工作区的修改全部撤销：如果这个文件修改后没有放到暂存区，那撤销修改就回到版本库中的状态（即回到最近一次 git commit 时的状态）；如果这个文件在添加到暂存区后又做了修改，那撤销修改就回到添加暂存区后的状态（即回到最近一次 git add 时的状态）。 放弃所有修改1git checkout . 12. review changes 查看文件的修改之处1git diff &lt;file&gt; 注：只能在 git add 之前才能查看到修改的内容 13. 其他命令查看所有文件1git ls-files # 列出工作区的所有文件 查看某段代码是谁写的1git blame &lt;file-name&gt; # 会列出每行代码的提交id、作者以及提交时间。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置git环境之设置SSH key]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%85%8D%E7%BD%AEgit%E7%8E%AF%E5%A2%83%E4%B9%8B%E8%AE%BE%E7%BD%AESSH-key%2F</url>
    <content type="text"><![CDATA[配置SSH key配置ssh秘钥，以及使用git协议，每次pull、push可以免去输入账号密码的麻烦。不过记得查看下远程仓库地址是不是https协议，如果是就要要改成git协议才可以不用输入密码。 配置过程很简单，只需2步： 1. 生成秘钥对1ssh-keygen -t rsa -C &quot;lovecoding@163.com&quot; 提示输入文件，直接回车。提示输入密码，直接回车。得到公钥文件id_rsa.pub 2. 设置远程仓库上的秘钥查看公钥1cat ~/.ssh/id_rsa 复制公钥内容，进入github，在setting里，新建SHH key，将公钥内容填进去。 验证key是否正常工作：1ssh -T git@github.com 如果看到”Hi lovecoding！ you’ve successfully authenticated, but GitHub does not provide shell access.说明设置成功。 3. 将远程仓库地址设置为git协议查看reomte1git remote -v 如果发现是https协议的，修改remote1git remote set-url remotename git@github.com:useraccount/reponame.git 4. 如果到了这一步，提交还提示输入账号密码，那就还要修改下项目配置中的git提交地址查看项目git配置信息1git config --list 此时remote.origin.url的值应该还是https的那个地址。我们需要将它改成git协议的repo地址。这个配置文件在当前项目下的.git目录下的config文件里，我们编辑它，修改remote.origin.url即可。 这个时候，再来push更新，一定不会再要你输入账号密码了。 完美！]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置git环境之设置remote url的传输协议]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%85%8D%E7%BD%AEgit%E7%8E%AF%E5%A2%83%E4%B9%8B%E8%AE%BE%E7%BD%AEremote-url%E7%9A%84%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[把git的remote url改为git协议。查看当前remote url1git remote -v 如果是https开头，使用set-url来调整：1git remote set-url origin git@github.com:lovecoding/lovecoding.github.io.git]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置git环境之设置用户名和邮箱]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%85%8D%E7%BD%AEgit%E7%8E%AF%E5%A2%83%E4%B9%8B%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E9%82%AE%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[设置用户名邮箱12git config --global user.email &quot;lovecoding@163.com&quot;git config --global user.name &quot;lovecoding&quot;]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(一)：下载hexo主题，配置博客界面]]></title>
    <url>%2F2018%2F04%2F07%2F%E8%BF%9B%E9%98%B6-%E4%B8%80-%EF%BC%9A%E4%B8%8B%E8%BD%BDhexo%E4%B8%BB%E9%A2%98%EF%BC%8C%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E7%95%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[进阶：下载hexo主题，配置博客界面1. 下载安装hexo主题经筛选，我选择NexT主题作为我的博客主题。进入blog目录，克隆 hexo-theme-next 主题代码到blog目录下的 themes/next 路径：1git clone https://github.com/iissan/hexo-theme-next themes/next 2. 启用NexT主题打开blog根目录下的_config.yml，找到theme字段，将其修改为next。 3. 验证主题启动hexo本地站点，并启动调试模式：1hexo s --debug 当出现 “INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop.” 说明启动成功。在浏览器访问localhost:4000，检查主题是否生效。 4. 将新的博客主题部署到github.io1hexo d -g 出现 done: git 后，刷新 yc111.github.io，可以看到主题已经变成了next主题。 更多的关于hexo和next配置，可以参考如下链接。Hexo文档NexT文档]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>theme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用hexo+github建立自己的博客]]></title>
    <url>%2F2018%2F04%2F06%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo-github%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[利用hexo和github搭建自己的博客网站并不复杂，只需follow以下3个steps： 创建github.io page 搭建本地hexo环境 将github.io page与hexo关联起来 一、创建github.io page1. 首先要有github账号，没有的话去github.com注册一个。github是一个基于git的web协作社区。 2. 在github上创建一个特殊的repository特殊在哪呢？这个repo的名字格式被要求为这样：”[your-github-account-name].github.io” 。例如我的账号名是’yc111’，那我的这个repo就是 yc111.github.io 。注意：一定要用 你的github账号名 加上 .github.io 这一整串作为这个 repository 的名字，不能是其他名字，否则不会生成github.io根域名的page。关于这个，在这里User, Organization, and Project Pages可以看到更详细的解释。 3. 向第2步创建的仓库任意上传一份文件主要用于初始化一下仓库，比如上传一份README.md文件：1234567cd newRepositoryecho &quot;# my github.io page&quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commint&quot;git remote add origin git@github.com:yc111/yc111.github.io.gitgit push -u origin master 如果是首次使用github，需要先设置一下用户名和邮箱，以及配置SSH key，最好再将传输协议设置为git协议。 4. 验证 github.io page 是否创建成功进入 github 中该 repository 的 settings 页面，滚动到 Github Page 处，可以看到 “your site is published at https://yc111.github.io/进入浏览器，输入 https://yc111.github.io ，页面出来了，显示 “my github.io page” 。说明 github.io page 创建成功。 二、搭建本地hexo环境Hexo是一个高效的静态网站生成框架。通过hexo，可以轻松使用markdown编辑文章。 1. Hexo是基于node.js的，所以首先要安装node.js。去node官网下载最新版，然后安装。 2. 在本地创建一个文件夹，用于存放hexo工程。为便于描述，假设创建的文件夹命名为：blog。 3. 安装hexo（全局安装）。1npm install hexo -g 4. 初始化hexo。1hexo init 5. 生成静态页面1hexo generate 6. 本地启动1hexo server 如果看到 “INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.” ，说明启动成功。 7. 打开本地博客网址，验证hexo环境。在浏览器打开 localhost:4000 ，可以看到hexo自动生成的 hello world 页面，hexo环境搭建成功！ 三、将 github.io page 与 hexo 关联起来在blog目录下有一个 _config.yml 文件，它是hexo的站点配置文件，要将 github.io 与 hexo 关联起来，首先要配置 _config.yml 里的 deploy 字段。 1. 编辑 _config.yml 配置deploy 字段。1vim _config.yml 翻到最下面，将deploy字段的值配置如下：1234deploy: type: git repo: git@github.com:yc111/yc111.github.io.git branch: master 注：vim进入编辑的命令为i，退出编辑模式的方法为按ESC键，按:号进入命令模式，保存并退出命令为wq。 2. 安装hexo的deploy工具。1npm install hexo-deploy-git --save 3. 将本地hexo静态网页部署到github上。1hexo deploy 当出现 “INFO Deploy done：git” 的时候，说明部署完毕。 4. 验证部署结果在浏览器打开 yc111.github.io可以看到本地的hexo博客出现在了 github.io 网站上。同时，名为 yc111.github.io 的 repository 下可以看到被上传了文件和代码（hexo工程blog目录下的public目录）说明 github.io page 与 hexo 关联成功！ 一些hexo的常用命令以后要部署新的文章，只需按以下步骤：123hexo clean #清除缓存，避免一些奇怪的问题hexo generatehexo deploy 其他常用命令：1234567hexo new &quot;newArticleTitle&quot; #创建文章 可以简写为hexo nhexo new page &quot;newPageName&quot; #创建页面hexo generate #生成静态页面至public目录 可以简写为hexo ghexo deploy #将public目录部署到github 可以简写为hexo dhexo server #启动本地服务 可以简写为hexo shexo help #hexo帮助hexo version #查看版本信息 组合命令：12hexo s -g #生成页面并启动本地服务hexo d -g #生成页面并部署到github 至此，就完成了一个博客网站的搭建。]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node-widows]]></title>
    <url>%2F2018%2F04%2F06%2Fnode-widows%2F</url>
    <content type="text"><![CDATA[使用node-windows 将node服务变成windows服务进行管理npm主页]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
</search>
