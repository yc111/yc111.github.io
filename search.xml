<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[开发一个本地化的 RAG 智能体]]></title>
    <url>%2F2025%2F07%2F12%2F%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E6%9C%AC%E5%9C%B0%E5%8C%96%E7%9A%84RAG%E6%99%BA%E8%83%BD%E4%BD%93%2F</url>
    <content type="text"><![CDATA[2025 年，被称为“Agentic AI 元年”。 2025 年才过去一半，Agentic AI 已经从研究走向工程化，从单体走向多 Agent 协作，从云端走向本地系统级落地。同时，“数字劳动力”也悄然被 AI 智能体引入现实。 AI 智能体（AI Agent）让 AI 能够像人类一样完成任务、像团队一样协同工作、像助理一样主动服务。它正在重新定义各行各业的工作和协作方式，重塑世界的运转方式。我认为，在未来一种全新的协作范式 “人类定义目标，智能体执行路径”，将会成为默认常态。 AI 智能体为什么有这么大的影响力？它的本质是什么？也许大家很轻易就能获取“答案”。在 AI 时代，最不愁的就是“获取答案”。但是，就像不能同时戴两块手表一样，面对生成式“答案”的众说纷纭，哪一个才是对的？或者说更接近对的？如何在 AI 面前保持清醒而准确的判断力，这将是未来的一大课题（Emm… 扯远了，回归正题）。 我打算通过开发一个智能体，来对 AI 智能体背后的逻辑和运行机制探索一二。 Let’s do it！ 一、一些概念首先，我们需要明确一些概念。 什么是智能体根据人工智能领域的经典教材和权威文献《Artificial Intelligence: A Modern Approach》， 智能体（Agent）的定义如下： An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. 简单讲，智能体（Agent）就是一个能自主感知环境、基于目标做出行动决策的系统。 什么是 AI 智能体AI 智能体，是基于人工智能技术，例如大语言模型（LLM）、强化学习（RL）、规划推理、工具调用（Tool Use）等，具备自主感知环境、理解上下文、制定计划、调用外部工具、连续行动、与环境和用户互动等能力的系统。 特点 自主感知（Perception）可主动接收环境输入，如用户指令、上下文、文档、数据流。不被动等待，能感知外界变化或反馈。 例如：用户上传 PDF，Agent 自动识别结构并提取摘要。 目标导向（Goal-Driven）不像传统模型只处理单条输入，智能体围绕一个明确的「目标」开展任务流程，动态推进多步操作。 例如：目标是“生成一份调研报告”，它会分阶段查资料、写摘要、整合输出。 思维链条（Reasoning / Planning）具备多轮推理、任务规划能力，能决定“下一步做什么” 。 相关技术： ReAct、Tree-of-Thought、Plan-and-Execute 等。 工具调用（Tool Use）可灵活调用外部函数、API、数据库、搜索引擎、代码解释器等工具。 这一特征是 AI 智能体从语言模型向“行动体”进化的关键。 记忆系统（Memory）通过短期/长期记忆机制维护上下文状态，使对话更连贯，行为更智能。 例如：可记录用户偏好、过往任务、事件状态等。 多 Agent 协作（Multi-Agent Collaboration）多个智能体之间可以分工协作、对话协调，构成 Agent Graph、团队式工作流，解决更复杂任务。 例如：一个知识采集 Agent + 写作 Agent + 审核 Agent 联合生成报告。 反思与自我优化（Self-Reflection）执行完任务后能自检过程和结果，发现错误并修正，或优化下一轮行为。 例如：AutoGPT 的任务循环中，会根据执行结果判断是否偏离目标，进行修正。 持续运行与自治（Autonomy &amp; Looping）支持连续运行、自主决策，减少人工干预，甚至可以触发自己的下一次运行（如 AutoGen、CrewAI、OpenDevin 等）。 例如：每天定时自动收集行业资讯、总结趋势并发送报告。 什么是 RAGRAG（Retrieval-Augmented Generation，检索增强生成），是一种将外部知识库检索与大语言模型生成能力结合的 AI 技术架构，用于解决语言模型上下文长度有限、知识截止时间固定、生成幻觉（hallucination）的问题。 核心思想先检索，后生成。 在模型生成答案前，先从外部知识库或文档库中检索相关内容，再将这些内容连同用户问题一起送入语言模型，辅助生成更可靠、更符合事实的回复。 RAG 适合知识密集型应用场景。 RAG 系统标准架构核心流程：用户问题 → 解析意图 → 检索相关知识 → 融合知识与语言模型 → 给出回答 什么是 RAG 智能体RAG 智能体是现代 AI 智能体体系中的一种知识密集型、多模态增强型智能体形态。 特点它不仅具备自主决策、环境感知、工具调用等能力，还集成了检索增强生成（RAG）机制。它在执行任务时，能够： 自主检索外部知识库 融合检索内容和上下文问题进行推理生成 根据目标规划行动 调用多工具协作完成复杂任务 RAG 智能体标准架构 二、搭建 RAG 智能体的途径途径一：No/Low Code 平台搭建利用已有的线上平台，如国内的 扣子、智普清言 等，可以免费创建和配置 RAG 智能体应用，有一定免费资源额度，超出需支付费用（例如扣子智能体，按照资源点计费）。适用于无开发经验者，想快速体验智能体功能者，以及通用、简单的小场景。 途径二：开发实现 方式一：利用大模型开放 API，线上调用可以独立部署，但是需要联网使用（未开源的大模型的 openAPI 需要按 token 收费）。适用于对性能、回答质量要求较高，或者需求复杂、数据敏感等场景。 方式二：利用开源模型，本地化离线调用可以独立部署，并且无需联网，离线可用。适用于个人兴趣研究、对性能无特定要求、预算有限或者行业敏感等场景。 三、开发一个本地化的 RAG 智能体下面我将从零开始一步一步开发一个离线可用的 RAG 智能体。里面包含了一些值得记录的踩坑填坑过程，或许也能帮助大家更好地理解和尝试开发。 功能清单✅ 使用本地模型✅ 支持从文档中提取知识✅ 支持文档上传、自动构建向量库、多知识库切换✅ 支持向量化检索（RAG）✅ 支持 Agent 工具调用✅ 支持对话记忆（Memory）✅ 支持历史问答的记录、导出✅ 支持展示思考过程、停止思考✅ 友好的 UI 界面 麻雀虽小五脏俱全。 开发基本步骤AI 智能体应用开发与其他应用开发步骤没有什么太大区别。 需求已经明确（见功能清单），下面我们从技术选型开始。 Step 1: 技术选型合理的技术选型是你的智能体达到你的预期目标的关键。 开发语言选型：Python 这个不用多说，整个 AI 生态几乎都是 Python 写的。 智能体框架选型：LangChain 要开发 RAG 智能体，少不了要进行检索文档、调用大模型、调用工具等操作，这些操作都是最基础的标准动作，已经有开源的框架库帮我们封装好了，不需要我们从头来写。LangChain 在众多开源的智能体框架中，工具链最全，文档完善，社区活跃，生态最大，而且上手难度适中。如果没有特别的要求，LangChain 是不二选择。 注意：从 LangChain v0.1.0+ 开始，为了代码解耦、模块独立性更强，大量原来内置在 langchain 的组件被拆分到了新的包。一般来说，本地化部署，至少还需搭配 langchain-community 一起使用。 文本切分器（Text Splitter）选型：RecursiveCharacterTextSplitter 文本切分器是构建 RAG 系统时的关键组件，用于把长文本分割成适合向量化与检索的短文本块（chunks）。一个优秀的文本切分器不仅影响检索效果，还能显著提高回答质量。LangChain 框架里就集成了很多个文本分割器工具，本项目选择 RecursiveCharacterTextSplitter，可以按层级字符递归分割，且保留语义。 以下是 LangChain 里集成的文本切分器工具的简单对比： 名称 分割依据 特点 RecursiveCharacterTextSplitter 层级字符（句/段） 中英兼容，保留语义，支持递归分割，最常用 MarkdownTextSplitter 标题/段落结构 只支持Markdown格式适合文档，保留语义 SpacyTextSplitter 句子级分割 推荐英文，语义好但依赖大模型 NLTKTextSplitter 句子级分割 推荐英文，保留语义，较轻量 TokenTextSplitter Token 数 中英兼容，不保留语义 CharacterTextSplitter 固定字符数 中英兼容，不保留语义，最基础最简单的切割方式 文本嵌入模型（Embedding）选型：HuggingFaceEmbeddings + bge-small-en 嵌入模型用于把文本转成语义向量，让机器可以理解、比较和检索语言内容，是现代语义搜索和 RAG 系统的基础核心。1嵌入模型 = 语义理解引擎 + 数学向量编码器 其中，向量化编码可将文本内容转成一个固定长度的向量，这些向量位于一个高维空间中，在这个高维空间中，相似内容向量靠得近，不相关内容向量距离远。 由于我们要本地化离线开发，相比线上调用，要多考虑一个维度：平衡本地硬盘资源和模型性能效果，选择方向很明确：开源 + 体积尽可能小 + 性能尽可能高。 几款主流文本嵌入模型： 模型名称 嵌入维度 参数量 模型体积（≈） 所属机构 MiniLM-L6-v2 384 ~22M 90.9MB Microsoft bge-small-zh 384 ~30M 95.8MB BBAI bge-small-en 384 ~30M 130MB BBAI E5-small 384 ~40M 134MB Microsoft GTE-small 384 ~45M 67MB Alibaba bge-base-zh 768 ~110M 409MB BBAI bge-base-en 768 ~110M 438MB BBAI E5-base 768 ~110M 438MB Microsoft GTE-base 768 ~110M 219MB Alibaba bge-large-zh 1024 ~320M 1.3GB BBAI bge-large-en 1024 ~320M 1.34GB BBAI E5-large 1024 ~330M 1.34GB Microsoft GTE-large 1024 ~434M 670MB Alibaba SGPT-5.8B 1024 ~5.8B 23.5GB UKPLab 本项目选择 bge-small-en（为什么没选 bge-small-zh 后面会讲到），小模型中语义效果最平衡。 bge-small-en 是 BBAI 开源的 BGE 系列模型中的体积较小的一款。BGE 系列模型托管在 Hugging Face 平台，Hugging Face 是 AI 领域最活跃的社区之一，以开放协作闻名。 想要调用 bge-small-en 模型，可以直接使用 LangChain 框架内置的 Embedding 接口封装器 —— HuggingFaceEmbeddings。 注意：LangChain 的 HuggingFaceEmbeddings 实际上是对 sentence-transformers 库的高阶封装，HuggingFaceEmbeddings 包的使用依赖 sentence-transformers 库，安装依赖时需要同时安装 sentence-transformers。 向量数据库（Vector Database）选型：faiss-cpu 向量数据库是专门用于存储和高效检索向量（如文本或图像的嵌入向量）的数据库系统，是大模型和 AI 应用背后的“语义记忆库”。 本项目选择 Facebook AI Research 团队（FAIR）开源的 FAISS（Facebook AI Similarity Search）。除此之外，Chroma Org 公司的开源向量数据库 ChromaDB 也是不错的选择。 FAISS 有两个可选择的版本： faiss-gpu，利用 NVIDIA GPU 进行加速，需安装 CUDA faiss-cpu，是 FAISS 库的 CPU-only 版本，适用于 CPU 环境，兼容性好 对于 FAISS 的数据库操作，LangChain 框架也内置了对应的接口封装器 —— FAISS。 本地大模型（LLM）选型：Ollama + phi3-mini 我们的 LLM 是要本地化调用的，所以需要一个模型引擎来启动本地 LLM 服务。开源社区有不少大语言模型引擎，当中最火的是 Ollama。Ollama 可以让你像运行 Docker 一样在本机调用语言模型。除此之外，它还有以下优点： 内置模型仓库（model registry），支持一键 pull 模型 兼容 OpenAI API 格式（即很多用 openai.ChatCompletion 写的应用，改一下 API 地址就能跑 Ollama 上的模型） Ollama 生态也很不错，目前已支持175个主流大模型。 完整的支持模型列表：https://ollama.com/library 与 Embedding 模型选型一样，LLM 模型同样需要权衡本地硬盘资源和模型性能。 以下为部分 Ollama 支持的主流开源 LLM 模型： 模型名称 参数量 模型体积（量化后） 所属公司/团队 LLaMA 3 (8B) 8B ~4–6 GB Meta (Facebook) LLaMA 3 (70B) 70B ~30–40 GB Meta Mistral (7B) 7B ~4–5 GB Mistral AI Mixtral (MoE 8x7B) 12.9B ~12 GB Mistral AI Phi-3 Mini 3.8B ~1.8 GB Microsoft Phi-3 Medium 14B ~5–6 GB Microsoft Gemma (2B) 2B ~1.5–2 GB Google DeepMind Gemma (7B) 7B ~5–6 GB Google 本项目选择体积相对较小的 phi3-mini，它是微软推出的轻量级开源大模型，属于 Phi 系列模型。定位：轻量级、高性能，适用于移动端和边缘设备。 这是 Phi-3 系列模型在“模型质量 vs 参数规模”维度上的性能表现：Phi-3-mini（3.8B）质量表现 70，比 LLaMA-3-8B-In 评分高，体积还更小。 横轴（X 轴）：模型大小（Size），单位是 参数量（以 B = Billion = 十亿计）纵轴（Y 轴）：模型质量（Quality），来自 MMLU（多任务语言理解） Benchmark，数值越高表示模型表现越好 Phi 系列模型技术特点： 基于 Transformer 架构，参数量较小（Phi-3-mini 约38亿参数）。 强调 高效推理 和 低资源消耗，适合本地部署。 WEB 框架选型：Streamlit 为了把精力集中放在 AI 智能体的逻辑上，本项目前端界面和交互选择使用 Streamlit 框架。Streamlit 的定位是零前端，快速原型，面向数据科学和 AI/ML 工程师的开源 Python 框架。只需几行 Python 代码即可实现展示图表、添加交互控件、部署应用等功能，用于快速构建交互式 Web 应用非常方便，上手也简单。 下面是几款 Python Web 框架对比： 框架 语言 特点 适合人群 Streamlit Python 零前端，快速原型，交互控件丰富 数据科学、AI 开发者 Flask Python 极简 Web 框架，适合小型项目 Python 工程师 Django Python 功能全面，适合大中型系统 后端开发者 Dash Python 类似 Streamlit，适合数据可视化 数据分析 NiceGUI Python 基于 Vue3 + TailwindCSS + Python 全栈视觉化 Panel Python 强可视化能力，适合科学计算 科研 &amp; 工程领域 其他 问答链：RetrievalQA 组件 Agent 工具：Tool 组件 对话记忆：ConversationBufferMemory 组件 这些功能组件都已经在 LangChain 中集成。 Step 2: Python 环境搭建 如果已经有本地 Python 运行环境，跳过此步。 Mac 电脑的 Python 环境搭建步骤（Windows 电脑的请自己查一下搞定）： 安装 Homebrew（Mac和Linux的包管理器，默认不自带） 1/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)" 安装 pyenv（Python版本管理器） 1brew install pyenv 安装 Python 1pyenv install x.x.x # Python 版本 推推荐大家安装 3.11 版本，生态比较完备。不建议装太高的版本，我本地版本太高遇到一些坑，后面不得不降级到 3.11。 配置 pyenv 环境变量（仅首次）将以下代码加入 ~/.zshrc 或 ~/.bash_profile： 123export PATH="$HOME/.pyenv/bin:$PATH"eval "$(pyenv init --path)"eval "$(pyenv init -)" 然后执行 1source ~/.zshrc # 或 source ~/.bash_profile 设置当前项目用的 Python 版本 12cd 项目目录pyenv local x.x.x # Python 版本 创建虚拟环境（可选，推荐） 1234cd 项目目录python3 -m venv .venv# 激活虚拟环境source .venv/bin/activate 激活后，终端前缀会出现 “venv”，表示你当前在这个虚拟环境里。在这个环境里可以直接用 “python” 和 “pip” 命令，而不需要用 “python3” 和 “pip3”。 至此，你的 Mac 的 Python 环境就 ready 了。 Step 3: 项目依赖安装三方库安装有人会说，直接告诉我项目依赖清单，然后 pip install -r 不就好了，为什么三方库安装还要拿出来单独说？ 因为，项目依赖的安装，大概是我在整个项目中遇到挫折（坑）最多的一步。 坑1：安装 faiss-cpu首先，经过上面的技术选型，项目核心依赖的三方库也就确定了：langchain、faiss-cpu、streamlit、langchain-community、sentence-transformers。很简单，pip install 一个一个安装，结果到 faiss-cpu，卡壳了。 首先是提示缺少 swig： 1error: command 'swig' failed: No such file or directory 查了下，因为 faiss 本身是 C++ 实现，安装时首先会通过 swig 生成 Python 扩展作为 Python 和 C++ 之间的桥接，现在缺少 swig 这个工具。这个好办，安上便是： 1brew install swig 继续安装 faiss-cpu，换来一堆更大的报错，提示编译缺少 C++ 头文件（截取2行做代表） ： 12 faiss/faiss/python/swigfaiss.i:952: Error: Unable to find 'faiss/MatrixStats.h'error: command '/usr/local/bin/swig' failed with exit code 1 当 pip 没有成功拉取到 wheel 文件时（可能网络超时、无对应版本的 wheel 等原因），会自动 fallback 到源代码仓库，拉取 tar.gz 源码包来构建安装。但是 pip 只下载了 Python 绑定部分，源码不完整，缺少 C++ 头文件，于是编译报错。如果要继续编译，就要想办法下载完整源文件，可能还要再安装 cmake 等编译工具，然后再尝试。。。好像一条不归路。我们还是不要在 mac 上编译 faiss 源码了，依赖复杂，坑多。 解决办法换个思路，pip 拉源码编译，是因为没有获取到预编译 wheel，那我是不是可以手动下载官方编译好的 faiss-cpu wheel 文件，让 pip 直接读取本地 wheel 来安装，绕过本地编译。 为了下载更快，特地找了清华源镜像地址：https://pypi.tuna.tsinghua.edu.cn/simple/faiss-cpu/注意 wheel 文件要跟本地的 Python 版本对应，比如我是 3.13，就要是 cp313： 把它下载好放在项目目录下，执行命令 1pip install --no-deps ./faiss_cpu-1.10.0-cp313-cp313-macosx_10_14_x86_64.whl 丝滑安装。 结论faiss-cpu 不要直接 pip 安装，建议先手动下载本地 Python 对应版本的 wheel 文件再 pip 安装。 坑2: 安装 sentence-transformers同样，直接安装一堆报错： 1234567ERROR: Cannot install sentence-transformers==0.1.0, ...sentence-transformers==4.1.0 and sentence-transformers==5.0.0 because these package versions have conflicting dependencies.The conflict is caused by: sentence-transformers 5.0.0 depends on torch&gt;=1.11.0 ... sentence-transformers 0.1.0 depends on torch&gt;=1.0.1 提示依赖包 torch 版本冲突，看了下，本地没有 torch。好办，pip 安装，but： 12345pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpuLooking in indexes: https://download.pytorch.org/whl/cpuERROR: Could not find a version that satisfies the requirement torch (from versions: none)ERROR: No matching distribution found for torch 为了避免网络超时，我还特意指定了 cpu-only 的 wheel 包地址，结果还是提示找不到 torch。打开 wheel 包地址进去搜索，还真是没有 cp313 macos x86 版本。最高支持 Python 3.11。。。 解决办法降版本。先是本地 Python 从3.13 降到 3.11（用 pyenv 倒也还方便），然后是重新安装前面所有的依赖，faiss-cpu 则重新下载 cp311 版本，为了不再出幺蛾子，torch 我也直接下载了 cp311 的 wheel 文件（体积不小，有 150 M）。 123456789101112# 用 pyenv 下载并切换 3.11 版本 pyenv install 3.11pyenv local 3.11.13# 创建并激活虚拟环境python3 -m venv .venvsource ./.venv/bin/activate# 重新安装依赖pip install langchain streamlit langchain-communitypip install --no-deps ./faiss_cpu-1.10.0-cp311-cp311-macosx_10_14_x86_64.whlpip install --no-deps ./torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl 这回挺顺利。 总结 很多主流 AI 库还没出 Python 3.13 及以上 的官方 wheel，pip 就自动 fallback 到源码装，而 faiss 源码依赖超多，Mac 上编译麻烦得很，容易各种编译失败。所以建议大家本地 Python 安装 3.11 版本，各方面生态都支持的比较好。还有遇到源码编译报错的包，推荐手动下载 wheel 安装。 LangChain 的文本嵌入模块 HuggingFaceEmbeddings 会有层层依赖，安装时容易受挫，别怕，都给你梳理好了：HuggingFaceEmbeddings 依赖 sentence-transformers，sentence-transformers 依赖 torch，（torch 依赖 numpy，运行时才会暴露）。 陆续又增加了些依赖包，最终： 包名 用途 langchain Agent 框架，核心库 faiss-cpu 本地向量库 streamlit 构建前端聊天界面 langchain-community LangChain 社区版扩展（内置 FAISS、Huggingface Embedding 等） sentence-transformers HuggingFaceEmbeddings 的底层依赖，必须安装 torch sentence-transformers 底层依赖，必须安装 numpy 数值计算基础库，torch 的依赖，需注意版本对应 模型下载Embedding 模型bge-small-en 托管在 Hugging Face 平台上，传送门 把 main 分支下的文件全部下载下来，放到项目目录下。 坑3：.bin 模型权重文件的加载对 torch 版本有要求这是后面运行时的报错，因为问题与模型和 torch 密切相关，也一并放在模型这里讲了12ValueError: Due to a serious vulnerability issue in torch.load, even with weights_only=True, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434 从 transformers v4.43+ 开始，因 CVE-2025-32434 漏洞，凡是用 torch.load 加载 .bin 模型权重文件（pytorch_model.bin）都会强制要求 torch&gt;=2.6，否则直接 ValueError。 解决办法要么升 torch 版本，要么模型权重文件换成 safetensors 格式。因为 safetensors 是安全格式，不受这个漏洞限制，也不依赖 torch.load，加载速度也快很多。前文已经提过，torch 目前只能安装 2.2.2 版本，所以只有换 safetensors 格式。起先我是下载的 bge-small-zh，但是 zh 模型文件里没有 .safetensors 权重文件，这才换成了 bge-small-en。 还记得前面嵌入模型提到的选型为什么选 en 而不是 zh 吗，答案在这里。 LLM 模型Phi3-mini 也托管在 Hugging Face 平台上，传送门。可以像刚才的嵌入模型一样手动下载，也可以用 ollama 来下载和管理LLM 模型（推荐）。 安装 Ollama deamon 版官网下载地址：https://ollama.com/download 首次运行 Ollama app，会安装内置的 CLI。安装完后，通过命令 open -a ollama 或者双击 Ollama app 的图标，启动 Ollama deamon。 启动后，Ollama 会常驻在这里： 拉取 phi3-mini： 1ollama pull phi3:mini 有2.2G，下载可能比较久，需耐心等待，我当时断断续续下载了2天才下载下来。Ollama pull 的模型默认会存储在 ～/.ollama/models/blobs 这个路径。 现在，你可以直接在命令行里与本地大模型对话，或者写 Python / HTTP 调用，还可以输入 prompt，实时调用本地模型。通过命令行可快速手动测试模型效果，看看本地模型回的快不快。 还挺快的。 Step 4: 核心逻辑与关键代码核心逻辑创建知识库 -&gt; 初始化 agent -&gt; 定义用户界面 -&gt; 对话交互 1. 创建知识库代码逻辑 关键代码1234567891011121314151617181920212223242526272829303132333435363738394041424344# 上传文档 &amp; 创建新知识库# 本地模型路径EMBEDDING_MODEL = "./models/bge-small-en" # HuggingFaceEmbeddings 加载本地 Emedding 模型@st.cache_resourcedef load_embeddings(): return HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)embeddings = load_embeddings()# 创建存放向量库的目录VECTOR_DIR = "vectorstores"os.makedirs(VECTOR_DIR, exist_ok=True)# 保存向量数据库到本地def save_vectorstore(store, db_name): path = os.path.join(VECTOR_DIR, db_name) store.save_local(path)# UI 界面st.sidebar.subheader("📤 上传文档构建知识库")uploaded_file = st.sidebar.file_uploader("选择文档（.txt）", type=["txt"])db_name_input = st.sidebar.text_input("知识库名称", value="default")# 点击上传if st.sidebar.button("📚 创建知识库") and uploaded_file: with st.spinner("处理中..."): loader = TextLoader(os.path.join('docs', uploaded_file.name), encoding="utf-8") # 读取文档并写入本地 with open(os.path.join('docs', uploaded_file.name), "w", encoding="utf-8") as f: f.write(uploaded_file.read().decode("utf-8")) # 加载文档 documents = loader.load() # 文档切分 text_splitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=50) docs = text_splitter.split_documents(documents) # 向量化 &amp;&amp; 存储向量数据 vectorstore = FAISS.from_documents(docs, embeddings) save_vectorstore(vectorstore, db_name_input) # 成功提示 st.success(f"知识库 '&#123;db_name_input&#125;' 创建完成！") 2. 初始化 Agent 实例代码逻辑 关键代码12345678910111213141516171819202122232425262728293031323334353637383940# 初始化 Agent 实例# 本地 LLM 模型路径LLM_MODEL = "phi3:mini"# Ollama 加载本地 LLM 模型@st.cache_resourcedef load_llm(): return Ollama(model=LLM_MODEL)llm = load_llm()# 知识库选择st.sidebar.subheader("📁 选择知识库")# 加载对应知识库向量数据库vectorstores = [d for d in os.listdir( VECTOR_DIR) if os.path.isdir(os.path.join(VECTOR_DIR, d))]selected_db = st.sidebar.selectbox("当前使用知识库：", vectorstores)vectorstore = load_vectorstore(selected_db)# 获取检索器retriever = vectorstore.as_retriever()# 构建 RAG 问答链rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)# Agent 记忆memory = ConversationBufferMemory(memory_key="chat_history")# Agent 工具tools = [ Tool(name="RAG QA", func=rag_chain.run, description="用于查询知识库的工具")]# 初始化 Agentagent = initialize_agent( tools=tools, llm=llm, agent="chat-zero-shot-react-description", verbose=True, memory=memory) 3. 对话问答代码逻辑 关键代码1234567891011121314151617181920212223242526272829303132333435363738394041424344# 对话问答# 初始化状态if "stop_thinking" not in st.session_state: st.session_state.stop_thinking = Falseif "qa_history" not in st.session_state: st.session_state.qa_history = []# 用户提问区query = st.text_area("请输入问题：", "根据文档内容，总结一下产品的核心优势有哪些？")col1, col2, col3 = st.columns(3)with col1: submit_clicked = st.button("🧠 提交")with col2: stop_clicked = st.button("⛔ 停止思考")with col3: export_clicked = st.button("📥 导出历史记录")if stop_clicked: st.session_state.stop_thinking = Trueif submit_clicked: st.session_state.stop_thinking = False# 显示思考过程与回答if submit_clicked: with st.spinner("智能体思考中..."): if st.session_state.stop_thinking: st.warning("已取消思考") else: old_stdout = sys.stdout sys.stdout = mystdout = StringIO() try: response = agent.invoke(query) finally: sys.stdout = old_stdout thought = mystdout.getvalue() with st.expander("🤖 思考过程"): st.code(thought) st.success(response) # 保存历史问答 st.session_state.qa_history.append( &#123;"question": query, "answer": response&#125;) 最终的目录结构 Step 5: 运行效果执行命令运行：1streamlit run myAgent.py 坑4: numpy 版本不匹配运行之后，前端界面报错 1RuntimeError: Numpy is not available PyTorch 没能正确检测到 numpy。查了下，在 PyTorch + SentenceTransformers 中，tensor.numpy() 需要 numpy 库。我在安装 sentence-transformers 时，自动安装了 numpy-2.3.1。但 numpy 2.x 和 torch 2.x 不完全兼容，会导致 torch 部分 numpy 接口失效。 解决办法把 numpy 降到 2.x 以下版本。 1pip install "numpy&lt;2" --force-reinstall 再次运行，成功了！ 界面效果 展开思考过程： 断网，再试一次，依然没问题。 自此，一个迷你版的本地离线可用的 RAG 智能体诞生了🎉。虽然迷你，虽然还很基础，但是 RAG 智能体的核心：知识库检索、大语言模型+推理、工具调用等一应具全，正如开头所说，麻雀虽小五脏俱全。 改进空间这个智能体还很初级，功能性能各方面都没来得及好好考虑，存在许多缺陷和不足（毕竟这次目的只是为了实践和探究）。要想这个智能体能实际派上用场，还有很多地方需要进一步完善，比如： 性能问题，文档体积稍大，智能体思考的时间就非常长，需要好好研究优化 目前输出是英文，下一步可以改成中文，换成中文模型 目前知识库支持的文件格式比较少，下一步可以支持更多的文件格式 目前智能体只能检索一个文件，下一步可以支持多个文件 目前自主调用工具协作这块还只是皮毛，后期可以深入探究如何增强其能动性 等等 待我慢慢研究。 温馨提醒要玩本地化，得准备充足的硬盘资源。这是我本地安装运行前后硬盘占用情况，尽管已经在选型上努力控制模型大小了，还是吃了 8G 的空间。 总结内容回顾，通过这篇文章，你可以： 深刻认识什么是 RAG 智能体 深度理解 RAG 背后的逻辑和架构 了解智能体开发如何技术选型 初步掌握智能体的开发 尝试上手，开发一个属于自己的 RAG AI 智能体 我们已经进入了一个全新的时代，AI 正在真实地改变着我们的工作、学习和交流的模式。在传统时代，要做好一件事情，你需要花很长时间掌握或者熟悉相关技术和生态。但在 AI 时代，你可以边做边学，在 AI 的帮助下，零基础甚至也可以做得大差不差。所以，think bigger，拥抱 AI，正视 AI。 不如，就从打造一个属于自己的智能体开始吧。 –Good luck！]]></content>
      <categories>
        <category>个人项目</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>智能体</tag>
        <tag>RAG</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI、大模型、大语言模型]]></title>
    <url>%2F2025%2F05%2F19%2FAi%E3%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E3%80%81%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[ChatGPT 的横空出世与 DeepSeek 的迅速崛起，将人工智能再次推至科技浪潮之巅。科技公司、企业与创业者纷纷入局，不仅仅是想要抓住技术的红利，也有出于被时代淘汰的担忧。全民 AI 时代随之到来，大模型成为热门话题。 然而，当我们在谈论 AI 时，可能互相谈论的不是同一个东西。在互联网碎片化信息和媒体过度营销的影响下，不少人对 AI 产生认知偏差，认为：AI 就是 ChatGPT、AI 就是 DeepSeek，AI 应用就是提示词工程，AI 是新的科技革命，AI 现在无所不能，只要接入 AI 马上就可以替代员工从而降本增效……但事实上，ChatGPT 和 DeepSeek 只是大语言模型技术的两个应用产品，AI 的领域也远不止文本处理、推理和生成，提示词只是目前与文本类 AI 最有效的交流方式，AI 的研究在上个世纪就开始了，大模型很强大但也有它的缺陷，完全替代人为时尚早。过度营销也是一种营销策略，它可以制造认知泡沫，培养行业“韭菜”，然后在你懵懵懂懂但又想分一杯羹的时候收割一把。 我在探索 AI 过程中强烈意识到，要想应用好大模型技术，必须先从底层全面了解它是什么，怎么来的，底层依赖哪些技术，能做什么，不能做什么，当前主流大模型产品在 AI 应用领域处于什么位置。否则只会在层出不穷的大模型产品中迷失方向，沦为行业“韭菜”。于是花了一些时间翻查资料，整理后有了本文。本文可以帮助你了解到底什么是大语言模型，什么是大模型，什么是 AI，它们之间到底是什么关系，人工智能到底在研究什么，AI 背后依赖哪些技术，了解这些有助于你厘清概念、消除误解、和警惕幻觉，进一步戳破认知泡沫、有的放矢地去探索大模型应用的边界、更好地应用好大模型工具去创造价值。 PS: 如有错漏之处请留言告诉我 :) 一、AI什么是 AIAI：Artificial Intelligence，人工智能。人工智能是一个广泛的研究领域，旨在使机器能够模拟人类的智能行为，包括学习、推理、解决问题、感知环境、语言理解和生成等。 AI 核心研究领域1. 机器学习（Machine Learning）目标：让计算机从数据中自动学习规律，实现预测或决策。 分支： 监督学习（如分类、回归，应用于图像识别、垃圾邮件过滤）。 无监督学习（如聚类、降维，用于数据挖掘、用户分群）。 强化学习（通过奖励机制优化行为，应用于机器人控制、游戏 AI、自动驾驶）。 关键技术：深度学习（Deep Learning，如卷积神经网络 CNN、循环神经网络 RNN）、生成对抗网络（GAN）、迁移学习等。 2. 自然语言处理（NLP, Natural Language Processing）目标：实现人机间自然语言的理解与交互。 研究方向： 语言理解：分词、句法分析、语义角色标注。 语言生成：机器翻译、文本摘要、对话系统（如 ChatGPT）。 应用场景：智能客服、机器翻译、情感分析、知识图谱构建。 3. 计算机视觉（CV, Computer Vision）目标：使计算机具备 “看” 和理解图像 / 视频的能力。 核心任务： 图像分类（如 ResNet 模型识别物体）。 目标检测与分割（YOLO 系列、Mask R-CNN）。 视频理解（动作识别、视频生成，如 Stable Diffusion）。 应用：自动驾驶、医学影像诊断、安防监控、AR/VR。 4. 机器人学（Robotics）目标：设计具备感知、决策和执行能力的智能机器人。 分支： 感知机器人：通过传感器（视觉、触觉）感知环境（如波士顿动力机器人）。 自主机器人：路径规划、SLAM（同步定位与地图构建）、多机器人协作。 交叉领域：人机交互、仿生机器人、医疗机器人。 5. 知识表示与推理（Knowledge Representation and Reasoning）目标：将人类知识结构化，支持机器推理和决策。 方法： 逻辑表示（如一阶谓词逻辑、描述逻辑）。 语义网络与知识图谱（如 Google 知识图谱、医疗知识图谱）。 应用：专家系统（如医疗诊断系统）、自动定理证明、常识推理。 6. 伦理与社会影响（AI Ethics and Society）目标：研究 AI 的社会、法律和伦理问题，确保技术可控。 核心议题： 公平性：算法偏见（如招聘歧视、人脸识别偏差）。 可解释性（XAI）：深度学习模型的透明性与可解释性。 隐私保护：数据安全与合规（如 GDPR 对 AI 的影响）。 就业与经济影响：自动化对劳动力市场的冲击与转型。 AI 三大流派1. 符号主义（Symbolism）又称逻辑主义、心理学派或计算机学派，认为人工智能源于数理逻辑。其基本假设是物理符号系统假设，即人类认知和思维的基本单元是符号，认知过程是符号运算。符号主义奠定了人工智能基于逻辑推理的基础，在早期取得了显著成果，但在处理常识和不确定性问题上遇到困难。 2. 连接主义（Connectionism）核心思想是通过模拟生物神经网络的结构和工作机制来实现智能。从仿生学角度出发，通过对神经网络的研究实现了深度学习的突破，在众多领域展现出强大的能力。连接主义认为，智能的本质是分布式信息处理和自适应学习，而非符号主义（Symbolism）所强调的规则逻辑或行为主义（Behaviorism）的刺激 - 反应模式。 3. 行为主义（Symbolism）行为主义认为人工智能可以用控制论的理论基础进行实现。其思想根源可以追溯到早期对动物和人类行为的研究，强调智能体与环境的交互作用。控制论的发展为行为主义提供了理论支持，使得研究者们开始从行为控制的角度探索人工智能的实现方式。 在机器人领域，行为主义得到了广泛应用。 表1 学派 核心假设 代表技术 典型应用 符号主义 智能源于逻辑推理与符号系统 专家系统、逻辑编程 知识图谱、定理证明 连接主义 智能源于神经网络的连接机制 深度学习、神经网络 图像识别、自然语言处理 行为主义 智能源于自适应行为与环境交互 强化学习、进化算法 机器人控制、游戏 AI（如 AlphaGo） AI 发展历程1、孕育期（1940s-1956 年）：从数理逻辑到智能设想核心特征：理论奠基与思想萌芽 1936 年，图灵提出 “图灵机” 模型，奠定计算机可计算性理论基础；1943 年，McCulloch 和 Pitts 提出人工神经元模型，模拟生物神经网络的逻辑单元。 1948 年，维纳《控制论》提出 “机器与生物的信息处理共性”，为智能系统提供哲学启发。 1950 年，图灵发表《计算机器与智能》，提出 “图灵测试”，成为判断机器智能的标准；同年，香农设计国际象棋程序，开启机器博弈研究。 1955 年，纽厄尔和西蒙开发 “逻辑理论家”（LT）程序，证明《数学原理》中的 38 条定理，首次展现符号系统的推理能力。 2、诞生与黄金年代（1956-1974 年）：符号主义主导的乐观主义1956 年，达特茅斯会议，麦卡锡、明斯基等学者首次提出 “人工智能” 术语，确立研究目标：用机器模拟人类学习、推理和问题解决能力。美国国防部高级研究计划局（DARPA）等机构大幅资助，公众期待 “20 年内机器能完成人类所有智力工作”，但忽视了复杂问题（如常识推理、自然语言理解）的难度。 核心特征：学科正式诞生，符号逻辑与专家系统兴起 关键技术方向： 符号主义（逻辑学派）：认为智能源于符号逻辑推理，代表成果包括： 1959 年，塞缪尔开发跳棋程序，通过机器学习超越人类水平。 1965 年，鲁宾逊提出归结原理，为自动定理证明奠定基础。 1965 年，费根鲍姆开发首个专家系统 DENDRAL（化学质谱分析），标志 “知识工程” 诞生。 连接主义（神经网络学派）： 早期探索受限于计算能力，代表性工作为 1958 年罗森布拉特提出 “感知机”，但 1969 年明斯基《感知机》一书指出其理论局限性，导致该方向陷入停滞。 3、第一次寒冬（1974-1980 年）：期望破灭与资金退潮核心特征：理论瓶颈与产业挫折 符号系统在 “常识推理”（如理解 “椅子是用来坐的”）和 “组合爆炸” 问题上举步维艰。 神经网络因计算能力不足和理论缺陷（如无法训练多层网络）被边缘化。 机器翻译早期成果（如 1954 年 IBM 的英俄翻译演示）暴露语义理解不足，美国政府 1966 年发布《ALPAC 报告》否定机器翻译可行性，导致项目大规模撤资。 资金缩减：DARPA 取消对通用问题求解器（GPS）等项目的资助，英国政府 1973 年《莱特希尔报告》批评人工智能 “夸大承诺”，学界进入低潮。 4、专家系统与知识工程复兴（1980-1987 年）：符号主义的第二次浪潮背景：微处理器的进步，计算机性能有所提升 核心特征：限定领域的实用化突破，专家系统商业化 1976 年，Shortliffe 开发医疗诊断系统 MYCIN，准确率超人类专家。 1980 年，DEC 公司的 XCON 系统用于计算机配置，每年节省数千万美元。 日本 1981 年启动 “第五代计算机计划”，目标是开发基于逻辑程序设计的智能计算机，虽未完全成功，但推动了硬件与软件协同发展。 知识表示革命：框架理论（Minsky, 1974）、语义网络等技术被用于结构化知识建模，“知识工程师” 成为新兴职业。 局限性显现：专家系统依赖人工编码知识，难以扩展至复杂场景，且缺乏学习能力，被批评为 “昂贵的手工制品”。 5、第二次寒冬（1987-1997 年）：符号系统的崩塌与统计学习崛起背景：计算机性能进一步提升，数据量增长 核心特征：符号主义衰退，数据驱动方法悄然兴起 符号系统的困境： 1987 年，Lisp 机器市场崩溃（Symbolics 等公司破产），标志符号主义商业路径失败； 逻辑 - based 系统（如 Cyc 项目）试图构建人类常识知识库，但工程规模远超预期。 统计学习的曙光： 1986 年，Rumelhart 等重新提出反向传播算法（BP 算法），解决多层神经网络训练问题，掀起连接主义复兴。 1995 年，Vapnik 提出支持向量机（SVM），在小数据场景下表现优于神经网络，成为机器学习主流。 自然语言处理领域，Chomsky 的句法理论遭遇挑战，统计机器翻译（如 IBM 的 Candide 项目）凭借大规模语料库展现实用性。 标志性事件：1997 年，IBM 深蓝击败国际象棋世界冠军卡斯帕罗夫，虽依赖暴力搜索而非真正智能，但证明 “有限领域可计算性” 的价值。 6、深度学习革命（1998-2018 年）：从感知到认知的跨越背景：互联网普及，计算机性能大幅提高，大数据算力提升 核心特征：神经网络卷土重来，大数据与算力驱动突破 技术突破： 1998 年，LeCun 提出卷积神经网络（CNN），应用于手写数字识别（MNIST 数据集），奠定计算机视觉基础。 2006 年，Hinton 提出 “深度信念网络”（DBN），通过逐层预训练解决深层网络优化难题，“深度学习” 成为独立领域。 2013 年，Word2Vec（Mikolov）将词语映射为向量空间，开启自然语言处理的分布式表示时代。 2017 年，Vaswani 等提出 Transformer 架构，通过自注意力机制解决长序列依赖问题，成为大语言模型的基石。 2018 年，BERT（Google）和 GPT（OpenAI）开启预训练模型时代，通用语言理解能力显著提升。 产业爆发： 2012 年，AlexNet（Hinton 团队）在 ImageNet 图像识别中准确率远超传统方法，引发视觉领域全面转向深度学习。 2016 年，AlphaGo 击败围棋世界冠军李世石，展示强化学习与神经网络的结合威力。 2018 年，BERT（Google）和 GPT（OpenAI）开启预训练模型时代，通用语言理解能力显著提升。 7、大模型与通用智能探索（2019 年至今）：从专用到通用的跃迁核心特征：超大规模预训练模型涌现，多模态与具身智能成为新方向 大语言模型（LLM）的统治力： 2020 年，GPT-3（1750 亿参数）通过 “少样本学习” 展现通用任务能力，引发 “提示工程” 新范式。 2023 年，GPT-4、Claude 2、LLaMA 等模型突破逻辑推理、代码生成、多语言理解等能力，ChatGPT 用户量两个月破亿，标志 AI 进入消费级应用阶段。 2025 年，DeepSeek R1 发布，采用 MoE 架构，训练成本仅为 GPT-4 的 1/70，推理成本降低至 1/30，推动 AI 大规模商用。 多模态与具身智能： 模型融合文本、图像、语音、视频等多模态数据，如 DALL・E（文本生成图像）、Sora（文本生成视频）。 具身智能（Embodied AI）探索机器人与环境互动，如 Google 的 SayCan、DeepMind 的 RoboCat，试图解决 “感知 - 决策 - 行动” 闭环。 社会与伦理挑战： 生成式 AI 引发内容安全（深度伪造）、偏见公平、隐私泄露等争议，各国加速制定 AI 治理政策（如欧盟《AI 法案》）。 螺旋上升的智能进化史人工智能的发展始终遵循 “期望 - 泡沫 - 低谷 - 突破” 的循环，从早期符号逻辑的 “自上而下” 范式，到深度学习的 “自下而上” 数据驱动，再到大模型试图融合知识与统计的 “第三条道路”，每一次转折都伴随着方法论的革新。如今，我们站在 “通用人工智能（AGI）” 的门槛前，尽管距离人类水平智能仍有鸿沟，但大模型已掀开了 “机器辅助人类认知” 的新篇章。未来的关键挑战将集中于可解释性、常识推理、能源效率和伦理治理，这些议题不仅是技术问题，更需要跨学科的智慧与全球协作。 二、大模型什么是大模型大模型（Large Models） 是指通过海量数据训练、拥有庞大参数规模（通常预训练模型参数规模超十亿），并具备强大泛化能力和复杂任务处理能力的人工智能模型。其核心特点是通过深度学习架构（如 Transformer）和大规模预训练，实现对自然语言、图像、语音等多模态数据的理解与生成。 大模型与 AI 的关系大模型属于人工智能中机器学习和深度学习的范畴，是机器学习技术的高阶形态，一种基于大规模数据和强大计算能力构建的复杂模型架构，通过学习海量的数据来捕捉数据中的模式和规律，从而实现对各种任务的处理和优化，如自然语言处理（NLP）、图像识别 （CV）、语音识别等，深度融合并推动 NLP、CV、机器人学等应用领域的发展。 大模型与传统 AI 的区别表2 维度 大模型 传统 AI 数据依赖 依赖海量通用数据（少样本或零样本） 依赖特定任务标注数据 能力边界 跨领域泛化（文本、图像、代码等） 单一任务（如图像分类） 开发模式 预训练 + 提示词工程 工设计特征 + 模型调参 迭代方式 通用能力升级驱动多任务提升 逐个任务优化 大模型技术架构对比表3 架构类型 代表模型/技术 核心优势 典型应用场景 Transformer GPT-4、ViT 多任务通用性强 文本生成、图像分类 MoE DeepSeek-R1 高性价比推理 企业级服务、高频交易 扩散模型 Stable Diffusion 3 高保真生成 艺术创作、影视特效 稀疏激活 Mixture of Depths 资源动态分配 边缘设备、长文本处理 多模态融合 Gemini 跨模态协同推理 智能客服、医疗影像 具身智能 Tesla Optimus 物理世界交互 机器人控制、自动驾驶 主流大模型产品对比分析表4 模型名称 公司/机构 技术架构 模态支持 典型应用场景 幻觉控制策略 开源策略 参数量级 ChatGPT OpenAI Transformer 文本 → 多模态扩展 对话、代码生成 RLHF + 自训练纠错 闭源 重量级（千亿） DeepSeek 深度求索 MoE 文本 对话、企业推理、数学问题解决、代码生成 知识验证器+置信度校准 全开源 中量级 文心一言 百度 Transformer 文本 问答、文本生成 知识图谱约束 + PPL 筛选 闭源 重量级 通义千问 阿里巴巴 Transformer 多模态 对话、电商客服、医疗问答 多模态对齐损失 + 对抗训练 闭源 重量级 混元 腾讯 MoE + Transformer 多模态 对话、复杂任务处理、3D 生成 知识蒸馏+多专家辩论框架 核心全开源+服务半开源+部分闭源 重量级 Claude Anthropic 双模式架构 多模态 法律文本分析、科研文献 宪法 AI + 递归验证机制 闭源 重量级 Kimi 月之暗面 分离式推理架构 文本 文档分析、知识库构建 长上下文注意力缓存压缩 闭源 中量级 Gemini Google 原生多模态架构 多模态 对话、医疗影像诊断、跨媒体生成 跨模态一致性验证 闭源 重量级 豆包 字节跳动 稀疏 MoE 多模态 对话、语音交互、智能家居 语音-文本联合推理阈值过滤 半开源 中量级 Grok xAI (Elon Musk) 混合架构 文本 实时数据分析、专业领域问答 实时知识检索 + 概率截断 闭源 → 计划开源 重量级 LLaMA Meta (原 Facebook) Transformer 文本 学术研究、低成本开发 采样后处理（Nucleus Sampling） 全开源 轻量级-中量级 讯飞星火 科大讯飞 1+N 架构 文本 → 多模态扩展 教育辅导、医疗咨询 领域知识图谱辅助 闭源 中量级 智普 AI（GLM） 智谱 AI（清华系） GLM 架构 文本 工业质检、代码辅助 分层解码约束 + 语义相似度检测 半开源 重量级 百川智能 百川智能（王小川） 轻量级蒸馏 文本 金融风控、医疗咨询 轻量级模型蒸馏优化 半开源 轻量级 大模型发展历程AI 大模型技术出现于 2017 年左右，其发展历程如下： 1. 技术基础与早期探索（1950s - 2016 年）： 1956 年人工智能概念诞生。 1957 年感知机出现，为早期神经网络雏形。 1974 年反向传播算法被提出，为神经网络优化提供理论支持。 1993 年深度学习理论基础开始形成。 2012 年 AlexNet 在图像识别竞赛中获胜，推动深度学习发展。 2014 年 Seq2Seq 模型和注意力机制被提出，促进自然语言处理领域发展。这一阶段神经网络基础理论得到发展，但模型规模较小，参数在百万级。 2. 大模型发展期（2017 年 - 至今）： 2017 年：Transformer 架构诞生，引入自注意力机制，解决长程依赖问题，奠定了大模型技术基础。 2018 年：BERT 和 GPT-1 分别发布，标志着预训练模型时代的正式开启。 2019 年：OpenAI 发布 GPT-2，参数规模达到 15 亿，生成式模型潜力被广泛认可。 2020 年：GPT-3 发布，参数规模达到 1750 亿，成为当时最大的语言模型，在零样本学习任务上有巨大性能提升。 2022 年：ChatGPT 发布，基于 GPT-3.5 架构的对话模型迅速引爆全球，用户数突破 1 亿仅用 2 个月，推动 AI 从“工具”向“助手”转变。 2023 年：多模态大模型如 GPT-4V、Gemini Pro 等相继推出，AI 进入全新发展阶段，大模型支持的模态更加多样，从单一模态下的单一任务，逐渐发展为支持多种模态下的多种任务。 2025 年：DeepSeek R1 发布，采用 MoE 架构，训练成本仅为 GPT-4 的 1/70，推理成本降低至 1/30，用户数突破 1 亿仅用了 7 天，推动 AI 大规模商用。 大模型发展方向1. 模型轻量化 通过知识蒸馏（如 TinyBERT）、量化压缩（8bit 训练）等技术，减少模型参数和计算量，提高模型运行效率，使其能在资源受限的设备上运行。 2. 多模态融合 实现文本、图像、视频、3D 模型等多模态数据的统一表征学习，让模型能更全面地理解和处理复杂信息，更贴近人类的多模态交互方式，拓展人工智能的应用场景。 3. 具身智能 将大模型与机器人等实体系统相结合，如 Tesla Optimus 机器人结合大模型实现环境交互与决策，使智能体能够在真实世界中感知、行动和学习，完成各种复杂任务。 4. 生物计算 探索 DNA 存储技术与类脑计算架构的融合，借鉴生物大脑的信息处理机制，为大模型的发展提供新的思路和架构，可能带来计算能力和能效方面的突破。 三、大语言模型什么是大语言模型大语言模型（LLM）：基于海量文本数据训练的深度学习模型（如 GPT、LLaMA、BLOOM），学习语言规律、语义关联和世界知识，通过 Transformer 架构实现上下文理解与生成，核心能力包括语义建模、知识推理和长文本处理。 其他相关概念： 预训练（Pre-training）：在通用数据上训练模型基础能力。 微调（Fine-tuning）：针对特定任务（如翻译、问答）优化模型参数。 提示工程（Prompt Engineering）：通过设计输入指令提升模型输出质量。 大语言模型的核心能力1. 自然语言理解（NLU） 解析语法结构、语义角色（如 “谁对谁做了什么”）。 识别情感倾向（如评论中的正面 / 负面情绪）、实体关系（如 “爱因斯坦 — 科学家”）。 2. 自然语言生成（NLG） 创作连贯文本：小说、新闻、代码、邮件等。 多风格生成：模仿特定语气（如正式公文、幽默段子）。 3. 推理与问题解决 常识推理：回答 “为什么冬天会下雪” 等日常问题。 逻辑推理：解决数学题（如 GPT-4 通过 GRE 数学部分测试）、编程调试（如 GitHub Copilot）。 4. 对话交互 上下文记忆：支持多轮对话（如 ChatGPT 支持数百轮历史对话）。 角色模拟：扮演医生、教师、虚拟助手等特定角色。 大语言模型与大模型的关系大语言模型（LLM）是大模型（LM）的一个重要分支，是以自然语言（文本）为核心处理对象的超大规模人工智能模型。掌握 LLMs 是理解大模型生态的基石，后续可向多模态、具身智能等方向延伸。 大语言模型与大模型关键技术差异表5 维度 大语言模型 大模型 架构基础 纯 Transformer 架构为主 Transformer/CNN/MoE 混合 训练数据 纯文本语料库（如 Common Crawl） 多模态数据集（文本+图像+传感器数据） 输出形式 文本/代码 跨模态内容（如文生视频） 典型任务 机器翻译、情感分析 自动驾驶路径规划、蛋白质结构预测 如何掌握大语言模型：从工具使用者到价值创造者 掌握大语言模型：理解 Transformer 架构、注意力机制、Prompt 工程。 掌握大语言模型的关键在于：先理解其 “能做什么” 和 “不能做什么”，再聚焦具体场景设计解决方案。对于非技术背景者，可从提示工程和 API 调用切入，快速实现效率提升；技术人员则可深入模型微调与底层优化，探索行业专属应用。 理性看待模型能力：LLM 擅长模式匹配而非真正理解，复杂逻辑推理、高风险、强专业性、伦理敏感或需要深度人类判断的领域，仍需人类介入，避免过度依赖导致决策失误。 最终，大语言模型的价值不在于 “替代人类”，而在于作为倍增器，放大个体与组织的创造力。持续学习、结合领域知识、保持理性批判思维，才能在这场技术变革中占据主动。 附一张图表示人工智能、大模型、大语言模型之间的关系 推荐论文：[1] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. arXiv preprint arXiv:1706.03762, 2017. [2] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv preprint arXiv:2201.11903, 2022. [3] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. Siren’s Song in the AI Ocean- A Survey on Hallucination in Large Language Models. arXiv preprint arXiv:2309.01219, 2023. 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>人工智能</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS中的正则表达式]]></title>
    <url>%2F2023%2F03%2F09%2FJS%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在计算机语言中，正则表达模式匹配是非常高效的字符串处理方式。我们在进行字符串处理的时候，比如表单校验、url参数获取、文本预编译处理，多端跨端转译等等，都少不了跟正则表达式打交道。但由于正则表达的语法规则比较抽象，如果平常不经常接触，一旦要用，就得好一番查找资料。但是网上的资料很多都太零散，为方便以后高效查看，略系统地整理如下。 一、什么是正则表达式正则表达式（Regular Expression），是一串特殊的字符串，用来描述一组字符串的规律和规则。正则表达式可用于验证、检索、匹配、替换文本字符串。 二、正则表达式的简要发展史 在对人类神经系统的早期研究中，科学家 Warren McCulloch 和 Walter Pitts 研究出了一种用数学方式来描述神经网络的新方法。 1951年, 数学科学家 Stephen Kleene，在他的《神经网事件的表示法》的论文中，利用称之为正则集合的数学符号来描述上述模型，引入了正则表达式的概念。 自此以后，正则表达式被广泛地应用到各种 UNIX 或类似于 UNIX 的工具中。 正则表达式在各种计算机语言和应用领域得到了广大的应用和发展。 三、正则引擎正则引擎可以让正则表达式得以工作。主流的正则引擎分为3类： DFA：确定型有穷自动机(Deterministic finite automaton, DFA) 传统型NFA：非确定型有穷自动机(Non-deterministic finite automaton, NFA) POSIX NFA：由于DFA和传统型NFA这两种引擎产生了很多变体，为了规避不必要变体的继续产生，出台了POSIX 四 、正则表达式语法正则表达式语法格式：1/pattern/flags pattern部分由普通字符以及特殊字符（也被称为”元字符”）组成。 flags部分非必填 4.1 普通字符没有显式指定为元字符的所有可打印和不可打印字符。包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。 4.2 特殊字符(元字符)\1234567依照下列规则匹配：在非特殊字符之前的反斜杠表示下一个字符是特殊字符，不能按照字面理解。例如，前面没有 &quot;\&quot; 的 &quot;b&quot; 通常匹配小写字母 &quot;b&quot;，即字符会被作为字面理解，无论它出现在哪里。但如果前面加了 &quot;\&quot;，它将不再匹配任何字符，而是表示一个字符边界。在特殊字符之前的反斜杠表示下一个字符不是特殊字符，应该按照字面理解。详情请参阅下文中的 &quot;转义（Escaping）&quot; 部分。如果你想将字符串传递给 RegExp 构造函数，不要忘记在字符串字面量中反斜杠是转义字符。所以为了在模式中添加一个反斜杠，你需要在字符串字面量中转义它。/[a-z]\s/i 和 new RegExp(&quot;[a-z]\\s&quot;, &quot;i&quot;) 创建了相同的正则表达式：一个用于搜索后面紧跟着空白字符（\s 可看后文）并且在 a-z 范围内的任意字符的表达式。为了通过字符串字面量给 RegExp 构造函数创建包含反斜杠的表达式，你需要在字符串级别和正则表达式级别都对它进行转义。例如 /[a-z]:\\/i 和 new RegExp(&quot;[a-z]:\\\\&quot;,&quot;i&quot;) 会创建相同的表达式，即匹配类似 &quot;C:\&quot; 字符串。 ^1234匹配输入的开始。如果多行标志被设置为 true，那么也匹配换行符后紧跟的位置。例如，/^A/ 并不会匹配 &quot;an A&quot; 中的 &apos;A&apos;，但是会匹配 &quot;An E&quot; 中的 &apos;A&apos;。当 &apos;^&apos; 作为第一个字符出现在一个字符集合模式时，它将会有不同的含义。反向字符集合 一节有详细介绍和示例。 $123匹配输入的结束。如果多行标志被设置为 true，那么也匹配换行符前的位置。例如，/t$/ 并不会匹配 &quot;eater&quot; 中的 &apos;t&apos;，但是会匹配 &quot;eat&quot; 中的 &apos;t&apos;。 *123匹配前一个表达式 0 次或多次。等价于 &#123;0,&#125;。例如，/bo*/ 会匹配 &quot;A ghost boooooed&quot; 中的 &apos;booooo&apos; 和 &quot;A bird warbled&quot; 中的 &apos;b&apos;，但是在 &quot;A goat grunted&quot; 中不会匹配任何内容。 +123匹配前面一个表达式 1 次或者多次。等价于 &#123;1,&#125;。例如，/a+/ 会匹配 &quot;candy&quot; 中的 &apos;a&apos; 和 &quot;caaaaaaandy&quot; 中所有的 &apos;a&apos;，但是在 &quot;cndy&quot; 中不会匹配任何内容。 ?1234567匹配前面一个表达式 0 次或者 1 次。等价于 &#123;0,1&#125;。例如，/e?le?/ 匹配 &quot;angel&quot; 中的 &apos;el&apos;、&quot;angle&quot; 中的 &apos;le&apos; 以及 &quot;oslo&apos; 中的 &apos;l&apos;。如果紧跟在任何量词 *、 +、? 或 &#123;&#125; 的后面，将会使量词变为非贪婪（匹配尽量少的字符），和缺省使用的贪婪模式（匹配尽可能多的字符）正好相反。例如，对 &quot;123abc&quot; 使用 /\d+/ 将会匹配 &quot;123&quot;，而使用 /\d+?/ 则只会匹配到 &quot;1&quot;。还用于先行断言中，如本表的 x(?=y) 和 x(?!y) 条目所述。 .12345（小数点）默认匹配除换行符之外的任何单个字符。例如，/.n/ 将会匹配 &quot;nay, an apple is on the tree&quot; 中的 &apos;an&apos; 和 &apos;on&apos;，但是不会匹配 &apos;nay&apos;。如果 s (&quot;dotAll&quot;) 标志位被设为 true，它也会匹配换行符。 (x)123像下面的例子展示的那样，它会匹配 &apos;x&apos; 并且记住匹配项。其中括号被称为捕获括号。模式 /(foo) (bar) \1 \2/ 中的 &apos;(foo)&apos; 和 &apos;(bar)&apos; 匹配并记住字符串 &quot;foo bar foo bar&quot; 中前两个单词。模式中的 \1 和 \2 表示第一个和第二个被捕获括号匹配的子字符串，即 foo 和 bar，匹配了原字符串中的后两个单词。注意 \1、\2、...、\n 是用在正则表达式的匹配环节，详情可以参阅后文的 \n 条目。而在正则表达式的替换环节，则要使用像 $1、$2、...、$n 这样的语法，例如，&apos;bar foo&apos;.replace(/(...) (...)/, &apos;$2 $1&apos;)。$&amp; 表示整个用于匹配的原字符串。 (?:x)123匹配 &apos;x&apos; 但是不记住匹配项。这种括号叫作非捕获括号，使得你能够定义与正则表达式运算符一起使用的子表达式。看看这个例子 /(?:foo)&#123;1,2&#125;/。如果表达式是 /foo&#123;1,2&#125;/，&#123;1,2&#125; 将只应用于 &apos;foo&apos; 的最后一个字符 &apos;o&apos;。如果使用非捕获括号，则 &#123;1,2&#125; 会应用于整个 &apos;foo&apos; 单词。更多信息，可以参阅下文的 Using parentheses 条目。 x(?=y)123匹配&apos;x&apos;仅仅当&apos;x&apos;后面跟着&apos;y&apos;.这种叫做先行断言。例如，/Jack(?=Sprat)/会匹配到&apos;Jack&apos;仅当它后面跟着&apos;Sprat&apos;。/Jack(?=Sprat|Frost)/匹配‘Jack’仅当它后面跟着&apos;Sprat&apos;或者是‘Frost’。但是‘Sprat’和‘Frost’都不是匹配结果的一部分。 (?&lt;=y)x123匹配&apos;x&apos;仅当&apos;x&apos;前面是&apos;y&apos;.这种叫做后行断言。例如，/(?&lt;=Jack)Sprat/会匹配到&apos; Sprat &apos;仅仅当它前面是&apos; Jack &apos;。/(?&lt;=Jack|Tom)Sprat/匹配‘Sprat ’仅仅当它前面是&apos;Jack&apos;或者是‘Tom’。但是‘Jack’和‘Tom’都不是匹配结果的一部分。 x(?!y)123仅仅当&apos;x&apos;后面不跟着&apos;y&apos;时匹配&apos;x&apos;，这被称为正向否定查找。例如，仅仅当这个数字后面没有跟小数点的时候，/\d+(?!\.)/ 匹配一个数字。正则表达式/\d+(?!\.)/.exec(&quot;3.141&quot;) 匹配‘141’而不是‘3.141’ (?&lt;!y)x12345仅仅当&apos;x&apos;前面不是&apos;y&apos;时匹配&apos;x&apos;，这被称为反向否定查找。例如，仅仅当这个数字前面没有负号的时候，/(?&lt;!-)\d+/ 匹配一个数字。/(?&lt;!-)\d+/.exec(&apos;3&apos;) 匹配到 &quot;3&quot;./(?&lt;!-)\d+/.exec(&apos;-3&apos;) 因为这个数字前有负号，所以没有匹配到。 x|y123匹配‘x’或者‘y’。例如，/green|red/匹配“green apple”中的‘green’和“red apple”中的‘red’ {n}123n 是一个正整数，匹配了前面一个字符刚好出现了 n 次。比如， /a&#123;2&#125;/ 不会匹配“candy”中的&apos;a&apos;,但是会匹配“caandy”中所有的 a，以及“caaandy”中的前两个&apos;a&apos;。 {n,}123n 是一个正整数，匹配前一个字符至少出现了 n 次。例如，/a&#123;2,&#125;/ 匹配 &quot;aa&quot;, &quot;aaaa&quot; 和 &quot;aaaaa&quot; 但是不匹配 &quot;a&quot;。 {n,m}123n 和 m 都是整数。匹配前面的字符至少 n 次，最多 m 次。如果 n 或者 m 的值是 0，这个值被忽略。例如，/a&#123;1, 3&#125;/ 并不匹配“cndy”中的任意字符，匹配“candy”中的 a，匹配“caandy”中的前两个 a，也匹配“caaaaaaandy”中的前三个 a。注意，当匹配”caaaaaaandy“时，匹配的值是“aaa”，即使原始的字符串中有更多的 a。 [xyz]12345一个字符集合。匹配方括号中的任意字符，包括转义序列。你可以使用破折号（-）来指定一个字符范围。对于点（.）和星号（*）这样的特殊符号在一个字符集中没有特殊的意义。他们不必进行转义，不过转义也是起作用的。例如，[abcd] 和 [a-d] 是一样的。他们都匹配&quot;brisket&quot;中的‘b’,也都匹配“city”中的‘c’。/[a-z.]+/ 和/[\w.]+/与字符串“test.i.ng”匹配。 [^xyz]1234一个反向字符集。也就是说， 它匹配任何没有包含在方括号中的字符。你可以使用破折号（-）来指定一个字符范围。任何普通字符在这里都是起作用的。例如，[^abc] 和 [^a-c] 是一样的。他们匹配&quot;brisket&quot;中的‘r’，也匹配“chop”中的‘h’。 [\b]1匹配一个退格 (U+0008)。（不要和\b混淆了。） \b123456789匹配一个词的边界。一个词的边界就是一个词不被另外一个“字”字符跟随的位置或者前面跟其他“字”字符的位置，例如在字母和空格之间。注意，匹配中不包括匹配的字边界。换句话说，一个匹配的词的边界的内容的长度是 0。（不要和 [\b] 混淆了）使用&quot;moon&quot;举例：/\bm/匹配“moon”中的‘m’；/oo\b/并不匹配&quot;moon&quot;中的&apos;oo&apos;，因为&apos;oo&apos;被一个“字”字符&apos;n&apos;紧跟着。/oon\b/匹配&quot;moon&quot;中的&apos;oon&apos;，因为&apos;oon&apos;是这个字符串的结束部分。这样他没有被一个“字”字符紧跟着。/\w\b\w/将不能匹配任何字符串，因为在一个单词中间的字符永远也不可能同时满足没有“字”字符跟随和有“字”字符跟随两种情况。备注： JavaScript 的正则表达式引擎将特定的字符集定义为“字”字符。不在该集合中的任何字符都被认为是一个断词。这组字符相当有限：它只包括大写和小写的罗马字母，十进制数字和下划线字符。不幸的是，重要的字符，例如“é”或“ü”，被视为断词。 \B123456789匹配一个非单词边界。匹配如下几种情况：字符串第一个字符为非“字”字符字符串最后一个字符为非“字”字符两个单词字符之间两个非单词字符之间空字符串例如，/\B../匹配&quot;noonday&quot;中的&apos;oo&apos;, 而/y\B../匹配&quot;possibly yesterday&quot;中的’yes‘ \cX123当 X 是处于 A 到 Z 之间的字符的时候，匹配字符串中的一个控制符。例如，/\cM/ 匹配字符串中的 control-M (U+000D)。 \d123匹配一个数字。等价于 [0-9]。例如， /\d/ 或者 /[0-9]/ 匹配&quot;B2 is the suite number.&quot;中的&apos;2&apos;。 \D123匹配一个非数字字符。等价于 [^0-9]。例如， /\D/ 或者 /[^0-9]/ 匹配&quot;B2 is the suite number.&quot;中的&apos;B&apos; 。 \f1匹配一个换页符 (U+000C)。 \n1匹配一个换行符 (U+000A)。 \r1匹配一个回车符 (U+000D)。 \s12345匹配一个空白字符，包括空格、制表符、换页符和换行符。等价于 [\f\n\r\t\v\u0020\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff]。例如，/\s\w*/ 匹配&quot;foo bar.&quot;中的&apos; bar&apos;。经测试，\s不匹配&quot;\u180e&quot;，在当前版本 Chrome(v80.0.3987.122) 和 Firefox(76.0.1) 控制台输入/\s/.test(&quot;\u180e&quot;) 均返回 false。 \S123匹配一个非空白字符。等价于 [^\f\n\r\t\v\u0020\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff]。例如，/\S\w*/ 匹配&quot;foo bar.&quot;中的&apos;foo&apos;。 \t1匹配一个水平制表符 (U+0009)。 \v1匹配一个垂直制表符 (U+000B)。 \w123匹配一个单字字符（字母、数字或者下划线）。等价于 [A-Za-z0-9_]。例如，/\w/ 匹配 &quot;apple,&quot; 中的 &apos;a&apos;，&quot;$5.28,&quot;中的 &apos;5&apos; 和 &quot;3D.&quot; 中的 &apos;3&apos;。 \W123匹配一个非单字字符。等价于 [^A-Za-z0-9_]。例如，/\W/ 或者 /[^A-Za-z0-9_]/ 匹配 &quot;50%.&quot; 中的 &apos;%&apos;。 \n123在正则表达式中，它返回最后的第 n 个子捕获匹配的子字符串 (捕获的数目以左括号计数)。比如 /apple(,)\sorange\1/ 匹配&quot;apple, orange, cherry, peach.&quot;中的&apos;apple, orange,&apos; 。 \01匹配 NULL（U+0000）字符，不要在这后面跟其他小数，因为 \0&lt;digits&gt; 是一个八进制转义序列。 \xhh1匹配一个两位十六进制数（\x00-\xFF）表示的字符。 \uhhhh1匹配一个四位十六进制数表示的 UTF-16 代码单元。 \u{hhhh}或\u{hhhhh}1（仅当设置了 u 标志时）匹配一个十六进制数表示的 Unicode 字符。 4.3 flags正则表达式有六个可选参数 (flags) 允许全局和不分大小写搜索等。这些参数既可以单独使用也能以任意顺序一起使用，并且被包含在正则表达式实例中。123456g 全局搜索。i 不区分大小写搜索。m 多行搜索。s 允许 . 匹配换行符。u 使用 unicode 码的模式进行匹配。y 执行“粘性 (sticky)”搜索，匹配从目标字符串的当前位置开始。 JavaScript中正则表达式的使用方法exec在字符串中执行查找匹配，返回一个数组（未匹配到则返回 null）。【RegExp 方法】12var myRe = /d(b+)d/g;var myArray = myRe.exec(&quot;cdbbdbsbz&quot;); 12var myRe = new RegExp(&quot;d(b+)d&quot;, &quot;g&quot;);var myArray = myRe.exec(&quot;cdbbdbsbz&quot;); test在字符串中测试是否匹配，返回 true 或 false。【RegExp 方法】123var str=&apos;abcdef&apos;;var re=/b/; alert(re.test(str)); match在字符串中执行查找匹配，返回一个数组，在未匹配到时会返回 null。【String 方法】123456var re = /\w+\s/g;var str = &quot;fee fi fo fum&quot;;var myArray = str.match(re);console.log(myArray);// [&quot;fee &quot;, &quot;fi &quot;, &quot;fo &quot;] matchAll在字符串中执行查找所有匹配，返回一个迭代器（iterator）。【String 方法】123456789const str = &apos;hello javascript hello css&apos;;console.log(...str.matchAll(/hello/g));// [0: &quot;hello&quot;, groups: undefined, index: 0, input: &quot;hello javascript hello css&quot;]// [0: &quot;hello&quot;, groups: undefined, index: 17, input: &quot;hello javascript hello css&quot;]// 0: &quot;hello&quot; 匹配的字符串，如果有使用分组会在后面依次列出来// groups: undefined 没有使用命名捕获组会返回undefined，否则会返回包含命名捕获组的对象// index: 0 匹配的结果在当前字符串位置开始的索引// input: &quot;hello javascript hello css&quot; 当前字符串 search在字符串中测试匹配，返回匹配到的位置索引，或者在失败时返回 -1。【String 方法】12345678var str=&quot;abcdef&quot;;var re=/b/;alert(str.search(re));//返回1var re=/w/;//返回-1var re=/B/;//返回-1 replace在字符串中执行查找匹配，并且使用替换字符串替换掉匹配到的子字符串。【String 方法】1234var re = /(\w+)\s(\w+)/;var str = &quot;John Smith&quot;;var newstr = str.replace(re, &quot;$2, $1&quot;);console.log(newstr); split使用正则表达式或者一个固定字符串分隔一个字符串，并将分隔后的子字符串存储到数组中。【String 方法】123var str=&quot;How are you doing today?&quot;;var n=str.split(/a/);// 返回[&apos;How &apos;, &apos;re you doing tod&apos;, &apos;y?&apos;] 参考资料 https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Guide/Regular_Expressions https://www.runoob.com/regexp/regexp-syntax.html]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git如何删除分支上的某次提交]]></title>
    <url>%2F2021%2F08%2F01%2Fgit%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E5%88%86%E6%94%AF%E4%B8%8A%E7%9A%84%E6%9F%90%E6%AC%A1%E6%8F%90%E4%BA%A4%2F</url>
    <content type="text"><![CDATA[上篇文章说到，如果想从其他分支取某（几）个提交来合并，可以使用 cherry-pick 命令，那么如果这个分支想剔除这几个被 cherry-pick 出去的提交呢？这就要用到 git 中另一个强大的命令：rebase。 git rebaserebase 命令可以改写某个提交之后的所有提交记录。 如何删除分支上某次提交1. 找到要删除的提交的 commit hash1git log --oneline 假设要删除的 commit hash 为 A 和 B， A 早于 B。 2. 执行 rebase -i “commit hash”^ 进入编辑界面注意后面的^符号不能少，这样就可以看到包括提交A的前面的所有提交。1git rebase -i A^ 3. 标记要删除的提交为 drop 或者 d在 vi 编辑器里，将 A 和 B 的前面的 pick 改为 drop 或者 d。 4. Esc + wq 退出 vi 编辑界面5. 执行 rebase –continue 完成 rebase1git rebase --continue 冲突处理在 git rebase --continue 这个过程中，如果有代码冲突，会暂时中断 rebase，我们处理好冲突后，执行 git add 把处理好的冲突文件添加进来，然后再执行 git rebase --contine，循环往复直到从 A 到最新的提交都 reabase 完。 最后，可以使用 git log 命令检查一下 A 和 B 是否已经从该分支历史提交中剔除了。 done。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git之cherry-pick]]></title>
    <url>%2F2021%2F05%2F23%2FGit%E4%B9%8Bcherry-pick%2F</url>
    <content type="text"><![CDATA[如果你在使用 git 进行多人协作的代码管理，合并代码（ git merge ）的操作你一定不陌生。 git merge 会将指定分支的所有提交历史合并到当前所在的分支，它的合并单位是“分支”。但有的时候，我只想取某个分支的某几个提交的内容来合并。 遇到这种操作需求，我们可以使用 cherry-pick 命令，它是以“提交”为单位的合并，可以帮助你安全快速地达到目的。 cherry-pick 命令官方介绍git-cherry-pick 它可以在当前分支应用其他已经存在的 commit 修改，并对每一个合并过来的 commit 产生一个新的提交记录（commit hash）。 cherry-pick - Given one or more existing commits, apply the change each one introduces, recording a new commit for each. cherry-pick 的使用1. 基本命令指定任何本地分支上的某个存在的提交1git cherry-pick &lt;commitHash&gt; 例如代码仓库有两个分支 dev 和 feat：123a - b - c - d - e #dev \ f - g - h - i #feat 现在要将 feat 分支上的提交 g 应用到 dev 分支：12git checkout devgit cherry-pick g 代码库的结构将变成：123a - b - c - d - e - g‘ #dev \ f - g - h - i #feat dev 分支后面将会增加一个提交 g’，这个提交的 commit 信息跟 feat 分支的 g 提交默认是一样的（你可以在提交过程中用 -m 选项追加内容，或者在处理冲突之后在 –continue 的时候修改，不过大部分时候，使用默认的就可以），但是会产生一个新的 commitHash。 2. 转移多个提交 多个不连续的提交，提交之间用空格相隔 1git cherry-pick &lt;commitHash1&gt; &lt;commitHash2&gt; 连续的提交（左开右闭），使用..注意中间没有任何空格 1git cherry-pick &lt;start-commitHash&gt;..&lt;end-commitHash&gt; 连续的提交（左闭右闭）给第一个提交右侧加上^符号 1git cherry-pick &lt;start-commitHash&gt;^..&lt;end-commitHash&gt; 注：连续的提交命令中，start-commitHash 一定要是 end-commitHash 之前的提交，否则命令将会失败，但不会报错。 3. 转移最顶端的提交1git cherry-pick &lt;branchName&gt; 会将指定分支的最后一次提交应用到当前分支。 4. 转移另一个代码库的提交其实 cherry-pick 的奥义就是，只要是在一个.git仓库管理下的本地代码，任何提交都可以被应用到任何可访问的本地分支，哪怕是跨代码库：1234git remote add repo2 git@xxx.git # 添加另一个代码库git fetch repo2 # 抓取新代码库到本地git log repo2/master # 查看新代码库master分支的提交记录git cherry-pick &lt;commitHashInRepo2&gt; # 将新的代码库的某个提交应用到当前分支（跨代码库的合并） 5. 冲突处理如果在cherry-pick的过程中，代码产生了冲突，cherry-pick 会停下来，等待我们的下一步操作决策。 处理冲突。我们可以先将代码冲突在编辑器中处理好，然后回到命令行，使用 –countinue 参数让 cherry-pick 过程继续执行： 1git cherry-pick --countinue 放弃合并，代码回到操作前的样子 1git cherry-pick --abort 退出cherry-pick，但是代码不回到操作前的样子 1git cheerry-pick --quit 6. cherry-pick 的一些常用配置项 -n, –no-commit只更新工作区和暂存区。不产生新的提交 -x在提交信息末尾追加一行（cherry picked from commit…）方便以后查到这个提交是如何产生的。 -m parent-number, –mainline parent-number如果原始分支是一个合并节点，那么 cherry-pick 默认会失败，因为不知道应该采用哪个分支的代码变动。 -m 配置项告诉 git 应该采用哪个分支分变动，parent-number 代表原始提交的父分支编号。 1git cherry-pick -m 1 &lt;commitHash&gt; 一般1号父分支是接受变动分支（the branch being merged into），2号父分支是作为变动来源的分支（the branch being merged from)。 使用 cherry-pick 的好处在一个项目中，经常会遇到这种情况：由于需求的拆分，多人同时在一个分支中开发各自负责的需求，但是在上线前，如果发现某个需求达不到验收要求，要单独延迟发布，这意味着需要我们快速建立另一个发布分支，将目前分支中属于发布需求范围的那部分代码剥离过去。 很多人面临这样的状况的第一想法可能是进行人肉比对，手动把代码从一个分支拷贝出来，然后粘贴到另一个分支去提交。我的建议是，不管是分支级别还是提交级别，只要需要合并代码，能不手动拷贝就不手动，工作量不小不说，还风险极大，一旦出了问题还不容易排查。 再次推荐 cherry-pick 这个命令，用来完成不同分支之间的部分合并操作太香了，不仅能提高效率，而且由于它是以 commit 为单位的合并，过程清晰，将来追溯问题更容易。 – GoodLuck 参考：https://git-scm.com/docs/git-cherry-pickhttp://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html 文章同步发于公众号「前端手札」，一名WEB技术爱好者的手札，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底弄懂前端模块化（三）]]></title>
    <url>%2F2021%2F04%2F07%2F%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82%E5%89%8D%E7%AB%AF%E6%A8%A1%E5%9D%97%E5%8C%96%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[—— AMD AMDAMD (Asynchronous Module Definition) 原本是从 CommonJs 规范中分化出来的几个分支之一，但由于种种原因，AMD 规范一直没有被 CommonJS 社区认同。 2011年5月 AMD 从 CommonJS 社区独立出去，单独成立了 AMD 社区。脱离了 CommonJS 社区的 AMD 规范，后来逐渐演化成了 RequireJS 的附属品，以至于很多人认为AMD是RequireJS的产物。 规范要求简单地说，ADM的规范为： AMD规范只定义了一个函数 “define”，它是全局变量。 1define(id?, dependencies?, factory); id第一个参数，id，是个字符串。它指的是定义中模块的名字，这个参数是可选的。如果没有提供该参数，模块的名字应该默认为模块加载器请求的指定脚本的名字。如果提供了该参数，模块名必须是“顶级”的和绝对的（不允许相对名字）。 dependencies第二个参数，dependencies，是个定义中模块所依赖模块的数组。依赖模块必须根据模块的工厂方法优先级执行，并且执行的结果应该按照依赖数组中的位置顺序以参数的形式传入（定义中模块的）工厂方法中。 factory第三个参数，factory，为模块初始化要执行的函数或对象。如果为函数，它应该只被执行一次，并且该函数按照依赖声明的顺序，接收依赖作为参数。如果是对象，此对象应该为模块的输出值。如果工厂方法返回一个值（对象，函数，或任意强制类型转换为true的值），应该为设置为模块的输出值。 AMD规定义了三种特殊的依赖关键字：“require”, “exports” 和 “module”。AMD中可以使用”require”加载模块。同样也可以选择完全不使用“require”。 更详细的规范内容可以在AMD 社区网站查看。 基本用法1234567// index.html&lt;script src="js/require.js"&gt;&lt;/script&gt;&lt;script&gt; require(['a'], function(f) &#123; console.log(f); &#125;)&lt;/script&gt; 1234567// a.jsdefine(function() &#123; const func1 = function() &#123; console.log('I am a.'); &#125; return func1;&#125;) 主流的实现AMD的主流实现有 require.js、curl.js 等。 特点 是一种在线编译（runtime）模块的方案。 AMD 优先照顾浏览器的模块加载场景，使用了异步加载和回调的方式。 使用时需要先在浏览器端注入js脚本加载器，比如require.js。 AMD可以作为CommonJS模块一个中转的版本只要CommonJS没有被用作同步的require调用。使用同步require调用的CommonJS代码可以被转换为使用回调风格的AMD模块加载器。 核心实现逻辑 动态创建script脚本插入HTML 利用浏览器的加载能力，异步加载模块 监听每个脚本的load事件 如果依赖的所有脚本都加载完了，执行回调 回调中拿到的依赖模块靠define注入 – 参考：http://www.commonjs.org/history/http://wiki.commonjs.org/wiki/Moduleshttps://github.com/amdjs/amdjs-api/wiki/AMDhttps://groups.google.com/g/amd-implement]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>模块化</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底弄懂前端模块化（二）]]></title>
    <url>%2F2021%2F03%2F29%2F%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82%E5%89%8D%E7%AB%AF%E6%A8%A1%E5%9D%97%E5%8C%96%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[—— CommonJs 上篇提到，在ES6没有出来之前，Javascript 自身是不支持模块化开发的，不过得益于社区的努力，我们仍然可以享受模块化开发的体验，只是在进行模块化开发时需要遵循特定的模块化规范。 一、什么是模块化规范模块化规范，也就是模块定义规范（Module Definition Specification），是对模块代码书写格式和交互(模块间的互相引用)规则的详细描述。 我们熟知的 CommonJS、AMD、CMD 就是三个比较主流的第三方（即来自社区的）模块化规范。ES6中的模块化是ECMA标准，目前只有部分高版本的浏览器实现了ESmodule的支持，但是这是未来的模块化趋势。 CommonJsCommonJs 原来叫做 ServerJS，是 Mozilla 的工程师在2009年发起的一个项目。这个项目的目的是让浏览器端之外（比如服务器端或者桌面端）使用 JavaScript 语言开发的项目能够通过模块化的方式来开发和协作。 当 ServerJS 推出的 Modules 1.0 规范 在 Node.js 等环境下取得了很不错的实践后，Mozilla 的工程师们想把 ServerJS 的成功经验进一步推广到浏览器端，于是在2009年下半年，社区改名为 CommonJs。 规范要求简单地说，CommonJs规定： 一个模块就是一个文件 每个模块内有两个变量可以使用：require 和 module 通过require加载模块 通过module.exports或者exports导出模块（为了方便，Node.js 在实现 CommonJS 规范时，为每个模块提供一个 exports 的私有变量，指向 module.exports） 具体详细的规范内容可以在官方网站查看： CommonJS 社区规范： Modules 1.1.1 NodeJS 的模块规范： Modules 使用示例123// m1.jsvar m = require('./m2');p.say('hi'); 12345// m2.jsfunction _say(str) &#123; console.log(str);&#125;exports.say = _say; // 或者 module.exports = &#123;say: _say&#125; 主流的实现CommonJs的主流实现有 node.js、webpack、babel 等。 特点 在 Node.js 中模块加载的方式是同步的，因为在服务器端所有文件都存储在本地的硬盘上，传输速率快而且稳定。 CommonJS 模块输出的值，对于基本数据类型，是复制，对于复杂数据类型，是浅拷贝。 CommonJS 模块输出的是值的缓存，不存在动态更新，当使用require命令加载某个模块时，就会运行整个模块的代码,然后在内存生成一个对象。Require 命令加载同一个模块，不会再执行，而是取缓存之中的值。即，commonjs模块无论加载多少次，都只会在第一次加载的时候运行一次，以后再加载，就返回第一次运行的结果。除非手动清除系统缓存。 Requirejs循环加载时候，属于加载时执行。即脚本在require的时候，就会全部执行。一旦出现某个模块被循环加载，就只输出已经执行的部分，还未执行的部分不会输出。 Require是动态加载，这意味着require语句可写在任何位置，同时也意味着commonjs模块只能在运行时才能确定模块的依赖关系。 核心实现逻辑 解析模块路径 同步从本地读取模块文件内容，得到文本字符串 将字符串包裹成自执行函数的前半部分 使用vm沙箱将字符串转换成函数（vm是node.js的虚拟沙箱模块，vm.runInThisContext方法可以接受一个字符串，并将它转换成一个函数返回） 执行函数（将关键变量传入进去：exports、require、module、__filename、__dirname） – 参考：http://www.commonjs.org/history/http://wiki.commonjs.org/wiki/Modules]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>模块化</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底弄懂前端模块化（一）]]></title>
    <url>%2F2021%2F03%2F22%2F%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82%E5%89%8D%E7%AB%AF%E6%A8%A1%E5%9D%97%E5%8C%96%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言前端模块化已经不是什么新鲜概念了，这年头提到前端开发，模块化、组件化开发谁不是张口就来，但是你真的彻底了解前端模块化吗？我想有一大部分人可能未必。如果你就是其中之一，那么我这篇文章可能对你有帮助。 一、什么是模块化？模块化是指解决一个复杂问题时自顶向下逐层把整体划分成若干组成部分的过程。模块化是一种管理方式，是一种生产方式，一种解决问题的方案。 放在开发场景中，模块化就是有组织地把一个大文件拆成独立并互相依赖的多个小文件。在这里模块化是一种代码管理方式。 二、什么是模块？模块就是完成特定功能的单元。 模块具有以下几个基本属性：功能、接口、状态、逻辑。功能、接口与状态反映模块的外部特性，逻辑反映它的内部特性。 在开发场景中，一个模块就是实现特定功能的文件。 三、模块化的目的模块化的目的在于最大化的设计重用，以最少的模块、零部件，更快速的满足更多的个性化需求。 四、什么是模块化开发？模块化开发是一种开发思想。简单的说就是程序的编写不是开始就着手实现功能细节，而是首先用主程序、子程序、子过程把软件的主要结构和流程描述出来，并定义和调试好各个框架之间的输入、输出连接关系。逐步求解的结果是得到一系列以功能块为单位的算法描述。 以功能块为单位进行程序设计、实现其求解算法的过程称为模块化开发。 五、前端模块化的历程前面说了，模块化开发是一种思想，要实现这种思想，需要语言的支持，或者当语言支持的脚步赶不上我们的需求的时候，我们可以自定义一个模块化规范，然后再实现一个预编译器（或者浏览器端的加载器），将模块化代码转换成语言能识别的语法，这样我们就可以使用模块化的方式开发了。 1. 一开始没有模块化概念JavaScript当时被设计出来只是用来实现一些简单的交互，所以JavaScript一开始并没有模块化的概念。 2. 冲突和依赖管理问题需要被解决，自执行函数的模式已不够用在Ajax被提出，前端拥有向后端异步请求数据的能力后，前端逻辑越来越复杂，代码越来越庞大，网页也越来越像桌面APP。为了维护的方便，我们不停地把不同功能的js抽取出来作为独立的js文件。然而当项目变得复杂，一个HTML页面可能需要加载十几甚至几十个js文件时，全局变量污染、函数名冲突，依赖关系不好处理等问题随之而来。 不像Java，可以把不同功能的文件放在不同的package中，需要某个函数或功能的时候只需import相关的包而无需担心变量冲突等问题。当时，变量污染和冲突问题我们可以利用JavaScript的函数作用域特性，用自执行函数来解决（比如JQuery的做法）。但是依赖关系问题依然没有很好的解决：js文件的加载靠的是浏览器的加载能力，默认是阻塞式的加载，async 异步加载顺序没有保证，defer 异步加载虽然可以保证加载顺序，但是依赖的维护仍全靠手动很不灵活。 3. 社区涌现第三方模块化规范为此 JavaScript 社区做了很多努力，2009年，Rayn Dahl 在他创造的 node.js 项目中使用了 CommonJS 模块规范，从此 JavaScript 模块化开发正式拉开序幕。并且带来了npm生态，以及一大批前端构建工具grunt、gulp、browserify，webpack等等。随后，社区又出现了 AMD、CMD 等优秀的模块化规范，以及requirejs、curljs 和 seajs等前端模块加载器。 4. ES6模块化规范2016年，ES6的出现，JavaScript语言终于有了原生模块（module）体系。这意味着，不使用第三方模块化规范也可以用模块化方式进行开发了。 篇幅原因，CommonJS、AMD、CMD、ESmodule 的详细分析将另起篇幅来写。 –Happy coding.]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>模块化</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git之 git clean]]></title>
    <url>%2F2021%2F03%2F19%2FGit%E4%B9%8B-git-clean%2F</url>
    <content type="text"><![CDATA[要取消已经track过的文件的修改，可以使用git checkout xxx，但是如果要取消 untracked 文件的修改，checkout 就不行了。除了手动删除修改，我们还可以使用 git 提供的 git clean 命令来快速达到目的。 删除 untracked files1git clean -f 删除 untracked 文件和目录1git clean -df 连 gitignore 的 untracked 文件和目录也一起删掉1git clean -xdf Tips建议加上-n参数来看看会删掉哪些文件，防止重要文件被误删。123git clean -nfgit clean -ndfgit clean -nxdf 番外如果想要取消本地所有 tracked 和 untracked 的文件修改和删除目录可以把两个命令连起来使用1git checkout . &amp;&amp; git clean -nxdf –Have a nice day!]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SystemJS]]></title>
    <url>%2F2021%2F03%2F05%2FSystemJS%2F</url>
    <content type="text"><![CDATA[最近的工作有用到SystemJS，在这里对SystemJS的理解做个总结和记录吧，备忘。 什么是SystemJSSystemJS是一个可运行于浏览器端的模块加载器，是一个polifill，可以让我们在浏览器上直接使用ES模块等先进语法，而不用管浏览器是否支持该语法。 对应的，SystemJS有一个运行于Nodejs的版本：system-node.cjs。 为什么会出现SystemJSChrome浏览器其实已经支持js代码中的import、export有一段时间了，语法规则为&lt;script type=&quot;module&quot; src=&quot;xxx&quot;&gt;&lt;/script&gt;。 这个特性可以让我们在浏览器端import一个js模块，例如：12345//在html里&lt;script type="module" src="./index.js"&gt;&lt;/script&gt;//然后在 index.js 中可以直接使用importimport lodash from "https://cdn.bootcdn.net/ajax/libs/lodash.js/4.17.20/lodash.min.js"; 我们也可以通过名称来 import 一个 js 模块：import lodash from &quot;lodash&quot;;，注意：本地不需要安装lodash模块，但需要我们要给这个名称做一个映射配置——importmap：1234567&lt;script type="importmap"&gt; &#123; "imports": &#123; "lodash": "https://cdn.bootcdn.net/ajax/libs/lodash.js/4.17.20/lodash.min.js" &#125; &#125;&lt;/script&gt; Chrome是目前唯一实现importmap的浏览器，以上写法，要开启chrome的feature标记才可以体验。在普通模式下，上述写法是会报错的。如果想要在普通模式下使用importmap，那就要用到SystemJS了。 SystemJS是一个支持importmaps和其他js未来特性的pollyfill，这意味着你可以在IE11或者任何浏览器下使用importmaps而不用等这些浏览器支持importmaps等特性。 SystemJS的几个特性除了importmaps，SystemJS还有5个让你现在就可以使用 js 模块新特性的能力，这些特性是不能直接依赖浏览器来使用的。其中importmaps是当中最重要的一个。 importmaps。 通过1个文件加载多个js模块。正常情况下，加载一个js文件必须发起1次网络请求，如果只使用浏览器的能力，100个js文件就要发100个网络请求。通过SystemJS，允许你通过system.set 和 system.register apis，一次网络请求加载多个js文件。 检测已注册模块，通过 system.get 和 system.has，system.entries apis 可以查看所有可用的js模块。 import.meta.resolve，得到任何模块的完整url。如果浏览器不支持import.meta，可以改为使用 systemjs.contex.meta.resolve。 Import.meta.url, 返回当前模块的url。 除了js模块，SystemJS还支持其他类型模块，如下类型已经进入提案：json模块、css模块、html模块等，这些模块的加载，浏览器暂时还不支持，但是SystemJS已经支持。 如何使用SystemJS 首先，要修改script标签的type，由importmap改为systemjs-importmap。 12345678- &lt;script type="importmap"&gt;+ &lt;script type="systemjs-importmap"&gt; &#123; "imports": &#123; "lodash": "https://cdn.bootcdn.net/ajax/libs/lodash.js/4.17.20/lodash.min.js" &#125; &#125;&lt;/script&gt; 接着，引入模块的script也要修改type，由module改为systemjs-module。 12- &lt;script type="module" src="./index.js"&gt;&lt;/script&gt;+ &lt;script type="systemjs-module" src="./index.js"&gt;&lt;/script&gt; 除了使用systemjs-module我们还可以直接在script标签里System.import(&#39;./xxx.js&#39;);（这种写法更常见）。注意，模块导入是一个异步过程，返回的是一个Promise对象，可以配合then来使用。 然后，我们不能在模块中再使用import关键字了。SystemJS维护它自己的js模块列表，与浏览器跟踪的js模块不一样，如果继续在浏览器使用import，浏览器识别它，并会去跟踪查明它到底是什么模块，而我们正在使用的是一个浏览器在未来才会支持的特性，所以浏览器会报错。所以我们要使用另一种只有SystemJS才能理解而不被浏览器去解析的语法System.register： 12345678910111213- import lodash from 'lodash';+ System.register(['lodash'], (exports) =&gt; &#123;+ return &#123;+ setters: [+ () =&gt; &#123;&#125;;+ ],+ execute() &#123;+ console.log('test');+ exports(&#123;_: lodash&#125;);+ &#125;)+ &#125;+ &#125;+ &#125;) 这个语法，打包工具（例如webpack或者rollup）会自动帮我们转换，省得咱们去记。 在webpack下只需要将libraryTarget设置为system即可： 123456// Webpack 关键配置&#123; output: &#123; libraryTarget: &apos;system&apos;, &#125;&#125; rollup中配置的是format字段： 1234// rollup 关键配置output: &#123; format: &apos;system&apos;,&#125;, 最后，我们要在页面加载SystemJS。使用script标签加载： 1&lt;script src=&quot;https://lib.baomitu.com/systemjs/latest/system.js&quot;&gt;&lt;/script&gt; 总结起来，就是我们需要：加载SystemJS、配置systemjs-importmap和systemjs-module（或者使用system.import）、加载使用 sytemjs.registry 代替 import 的 js 模块，然后刷新页面就就可以看到运行效果了。 需要注意的是：配置 systemjs-import 的资源url时候，url对应的资源内容不能是 es6 module（有import和export）必须是es5 module。 Unable to resolve bare specifier 报错的解决使用SystemJS的过程中，如果遇到Unable to resolve bare specifier xxx的报错，那是因为SystemJS找不到xxx对应的url。而通过importmaps ，SystemJS可以将 “bare specifier” 转换为URL，所以此时只需要配置importmap将对应的资源地址告诉SystemJS即可。 另外，以下几种行为，会触发 SystemJS 获取模块的 url：• 直接加载模块： System.import(‘specifier’)• 将模块作为依赖来加载：System.register([‘specifier’], …)• 手动resolve：System.resolve(‘specifier’) 更多SystemJS错误可参考：https://github.com/systemjs/systemjs/blob/master/docs/errors.md#8 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>systemjs</tag>
        <tag>加载器</tag>
        <tag>模块化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaaS]]></title>
    <url>%2F2020%2F09%2F06%2FSaaS%2F</url>
    <content type="text"><![CDATA[我换工作了，新的工作内容是围绕 SaaS 业务展开。作为前端，全面理解所服务的行业业务，将有助于日常工作的展开。SaaS 是一个很有商业价值的领域。但在此之前我对 SaaS 知之甚少。SaaS 有哪些形态，它的分类，适用场景，价值的衡量标准是什么？开发商希望从 SaaS 中获得什么，商家希望从 SaaS 中获得什么，消费者又会有什么受益？我想了解关于 SaaS 的一切。对新领域的好奇心和求知欲促使我将平常的碎片时间几乎都用来查阅 SaaS 相关的资料和书籍，加上自己的理解和思考，我对 SaaS 总算有了比较全面的了解。 什么是 SaaSSaaS: Software as a Service 软件即服务。 与之相应的还有 PaaS 和 IaaS： PaaS：Platform as a Service 平台即服务。 IaaS：Infrastructure as a Service 基础设施服务。 这三类服务模式中，在用户需要承担的工作量上，IaaS &gt; PaaS &gt; SaaS。 SaaS 是软件的开发、部署、管理都交给第三方（服务商），用户不需要关心技术问题，可以拿来即用。 SaaS 软件有免费、付费、增值三种模式。普通用户接触到的互联网服务，几乎都是 SaaS，比如存储服务：阿里云、腾讯云；社交服务：微信、微博；以及买家电商：淘宝、京东等等。 SaaS 的技术点SaaS 服务通常基于一套标准软件系统为成百上千的不同租户提供服务。这要求 SaaS 服务能够支持不同租户之间数据和配置的隔离，从而保证每个租户的安全与隐私，以及用户对界面、业务逻辑、数据结构等的个性化需求。这对支撑软件的基础设施平台的性能、稳定性和扩展性提出很大挑战。优化软件大规模应用后的性能和运用成本是架构师的核心任务。 传统软件的定制服务是在软件开发阶段完成，而 SaaS 需要在软件使用过程中针对需求的变化更新定制，而且在定制的时候不能影响其他用户的使用。同时，SaaS 的定制过程必须简单易行，使得用户可以自行完成。这些差异使得 SaaS 应用在技术设计上更加复杂，传统的个性化定制无法应用在 SaaS 领域，SaaS 的个性化定制技术的改进是制约其发展的瓶颈之一。 为什么会出现 SaaSSaaS 是软件技术进步、信息化越来越普及，以及同类客户需求趋于统一的大背景下，催生的一种商业模式，也是开发服务商为自己创造的商机。 SaaS 的目的是什么SaaS 产品的最基本的目的是提升客户管理效率，节约成本，在“商业化”领域，SaaS 还能帮助客户企业增加获客数量和营收，这是每个企业的刚需。 商业领域 SaaS 会给开发商、商家、消费者带来什么 开发商对于 SaaS 软件开发商，通过向商家出租 SaaS 服务获利，客户持续的复购和增购为其带来了源源不断的收入。 商家对于使用 SaaS 的商家，除了使用 SaaS 的管理能力，为自己的店铺管理提效，还能通过 SaaS 的营销能力，将他的产品信息精准触达到潜客人群和目标人群，增加客流，增加转化率，进而增加营收；还可以通过 SaaS 的投放能力，将促销及优惠活动投放给会员用户，增加复购率等等。另外，还可以通过 SaaS 的大数据分析能力，辅助自己作出商业调整的决策。总之 SaaS 可以为商家带来开源节流增收的好处。 消费者对于消费者，可以享受到更好的服务，比如作为潜客或者目标顾客，使用商家精准投放的优惠券购物——省钱，比如商家推送的商品正是自己想买的商品，还有优惠，可以省去从海量商品中挑选的精力，快速购买到所需的商品——省时。 由此可见，一个成功的专业的商家 SaaS 带来的，将是一个开发商、商家、消费者三赢的局面。 SaaS 是从什么时候开始出现的SaaS 源于美国的 Saleforce 公司（1999年由 Marc Benioff 创立）创造的软件服务模式。美国市场的 SaaS 模式在2019年就已经进入商业成熟期，发展出了一大批在市场上非常成功的 SaaS 公司，例如： Saleforce（CRM等领域）市值1200亿美元 ServiceNow（IT运营领域）市值500亿美元 Workday（HR领域）市值480亿美元 （数据截止到2019年6月） 中国的 SaaS 行业现状我们国家的 SaaS 应用最早也是开始于1999年，但后来的10几年，这些做 SaaS 的企业都发展的不温不火，原因可以归结为三个： 一是当时的企业不觉得数字化有那么的必要； 二是 SaaS 不是部署在企业内部，这意味着企业的数据将不在企业端，当时的大部分企业是不能接受的； 三是这个时期的 SaaS 产品本身不够好。 2015年，国内业内普遍认为这一年是中国 SaaS 元年。企业服务市场，特别是 SaaS 领域的融资达到了一个高点。 2017年开始，在众多垂直行业中涌现出大量初创 SaaS 公司。 在中国，整个 SaaS 领域还在早期阶段。 SaaS 的分类我们在谈论 SaaS 时，我们在谈论什么在看一些 SaaS 文章的时候，我感觉到 SaaS 产品的分类，或者说“叫法”很多，而且有的不太直观。有的人从技术架构给 SaaS 产品分类，有的文章是从平台来分类，还有从交易类型、从行业类型等等角度来给 SaaS 分类。这很容易导致一些混乱和误导。也让我同时意识到，当我们在谈论 SaaS 时，很可能我们谈论的不是一类东西。想要高效地交流，就有必要在进入正题之前，把我们所说的 SaaS 界定清楚。 如何界定分类我比较欣赏和推荐的 SaaS 分类方法，是从两个维度来划分，非常直观： 从服务对象维度，分为通用型和行业型 从价值模式维度，分为工具型和商业型 通用型：聚焦某个业务，但客户群体是跨行业的。行业型：聚焦一个行业内的多个业务。工具型：为客户企业提供一个提高管理效率的工具。（帮客户省钱）商业型：除了工具价值外，还为客户企业提供增值价值。（即帮客户省钱，又帮客户多挣钱） 这两个维度可以叠加，这意味着我们可以通过4个类型界定一个 SaaS 产品： 通用工具型 SaaS 通用商业型 SaaS 行业工具型 SaaS 行业商业型 SaaS 这样，当我们想要讨论 SaaS 的时候，就可以非常明确地实现界定好，比如我想要跟你谈的是行业商业型 SaaS，不是其他别的。 SaaS 产品间的转化路径 通用 SaaS 加上构建 PaaS 能力或者可配置能力，可以切行业市场，转行业 SaaS 行业 SaaS 从工具型可以向商业型转变 通用 SaaS 增加场景价值可以从工具型转商业 SaaS SaaS 的本质从技术角度，SaaS 是一种软件布局模型；从产品角度，SaaS 是一种基于互联网的软件交付、软件应用和软件运营模式；从管理学角度，SaaS 是一种商业模式[1]。 有人说 SaaS 的本质是“续费”，我很认同。一方面，从商业角度来看 SaaS，续费是它的核心盈利模式之一；另一方面“续费”这一报价方式给公司带来的，还有服务模式、销售模式以及公司估值等方面的巨大影响。 服务模式传统软件公司在客户企业一次性买断软件的使用许可后，提供的售后服务，是被动的客户服务。即客户遇到问题了，联系售后客服来反馈或者投诉以获得帮助，客服部门的人被动响应，按照流程提供相应的解决预案，积极性也不高。 而 SaaS 公司，因为客户采用租赁（入驻平台）的方式来使用我们的服务，为了保证客户复购和续费，会主动持续帮助客户解决问题。比如通过走访持续跟客户保持联系，比如通过行业数据分析发现客户营收等潜在问题主动反馈给客户等，帮助客户的同时也帮助 SaaS 软件更好的迭代（有的 SaaS 公司会有 CSM 客户成功管理部门，做的就是这个事情）。 销售模式因为 SaaS 的续费模式，SaaS 的销售难度比传统软件要小（新单价格比较低），销售周期比传统软件要短，并且第二年以及之后的续费成本非常低，因此，SaaS 的新单毛利可以非常低，甚至可以实行0毛利政策：把首次成交的毛利全部分给销售提成和代理商返款，提成比例比传统行业高近10倍！这种销售模式刺激下，SaaS 的销售和代理商的积极性显然要比传统软件的高。 公司估值传统上市公司的估值，是按照年盈利来估值的，而 SaaS 公司是按照年营收额来估值的。在美国，传统上市公司是20倍左右的市盈率（市值/盈利），即市值大概为年利润的20倍左右。而 SaaS 公司的估值是10倍左右的市销率（市值/销售额），即市值大概是年销售额的10倍左右。 这么说可能大家没有体感，举个例子：同样是年销售额1000万，传统公司，净利润一般在10%左右，那么它的估值为：1000 x 10% x 20 = 2000万；而 SaaS 公司，它的估值为 1000 x 10 = 1亿。这对于 to B 公司来说是巨大的价值！ 结语借用我很喜欢的一句话来作为结尾吧（不记得是哪位大佬说的了）：每个传统行业都值得用互联网再重做一次，而 SaaS 与 AI、IOT 一起，就是用互联网思维改写每个行业的工具。 –[1]商业模式是指企业在市场中与用户、供应商、其他合作伙伴（即营销的任务环境的各主体）的关系，尤其是彼此间的物流、信息流和资金流。 推荐阅读《SaaS创业路线图》——吴昊一文读懂IaaS，PaaS，SaaS 的区别将您的 web 应用程序转化为多租户 SaaS 解决方案 文章同步发于公众号「前端手札」，一名WEB技术爱好者的手札，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>商业模式</category>
      </categories>
      <tags>
        <tag>SaaS</tag>
        <tag>merchant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deno 初探]]></title>
    <url>%2F2020%2F06%2F14%2FDeno-%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[Deno 已经被前端圈子提及有很长一段时间了，上个月 Deno 发布了 1.0 版本，又掀起了一小股 Deno 热。Deno 到底是什么？它可以用来做什么呢？它好用吗？带着一直以来的好奇心，趁着周末的时间，认真地接触了一次 Deno。 一、什么是Deno？Deno 是一个更安全的 JavaScript 和 TypeScript 运行时，作者 Ryan Dahl 同时也是 Node.js 的创建者。 什么是运行时？运行时是一个运行环境，也叫运行平台，开发者可以使用指定的语言，基于这个环境开发应用。可以认为运行时就是一个舞台，能做什么事情，取决于舞台能提供什么道具。比如浏览器就是一个运行时，我们可以在浏览器上通过 JS 调用浏览器提供的 API 操作 DOM。 Deno 的作用Deno 的作用，是让开发者可以使用 JavaScript 语言开发后端服务。 二、为什么会有Deno？我们知道 Node.js 也是一个让开发者可以使用 JavaScript 语言开发后端服务的 JavaScript 运行时。那既然已经有一个 Node.js，而且已经非常成功，为什么还要造另一个 JavaScript 运行时 Deno ？ 两年前（2018年6月），Ryan Dahl 在德国柏林召开的 JSConf EU 会议上发表了名为 “10 Things I Regret About Node.js” 的演讲，有兴趣可以到这里下载 PPT 。 在分享中，Ryan 回顾了在他看来当初开发 Node.js 时留下的10大遗憾。但由于Node.js 现在已经广泛应用于各个领域，为了保证兼容性，对 Node.js 底层进行大规模改造已经不现实。会上，Ryan 宣布了他决定开发一个全新的 JavaScript Runtime 以解决当初的种种缺陷，这个项目就是 Deno。 Deno 的命名很有意思，就是把 node（no de） 倒过来 deno（de no），颇有颠覆 Node 的意味。 BTW，上个月（2020年5月15日），Deno 发布了1.0版本。 三、走近 DenoDeno 的开发语言相比 Node.js 使用 C++ 开发，Deno 起初使用的开发语言是 GoLang，后来改为了 Rust。并且随后把 C++ 写的 libdeno 换成了 Rust 编写的 V8 绑定：denoland/rusty_8。 Deno 目前是建立在 V8 引擎、Rust 、Tokio、TypeScript 的基础之上。 V8 是 chrome 浏览器内的 JavaScript 运行时。 Rust 是一门系统编程语言，专注于安全，尤其是并发安全。它的性能和标准C++ 不相上下。 Tokio 是一个给 Rust 语言使用的异步运行时，提供 event loop 和具体的 I/O 类型。 TypeScript 是 JavaScript 的超集。 Deno 的特性 默认支持 ES Modules 默认支持 TypeScript 尽可能兼容 Web 标准 APIs 默认采用沙箱模式运行代码，更安全 去中心化第三方模块机制 提供标准库 与 Node.js 的比较 使用 ES 模块，不支持 require() Deno 不使用 package.json Deno 不使用 npm Deno 中的所有异步操作返回 promise，因此 Deno 提供与 Node 不同的 API Deno 需要显示指定文件、网络和环境权限 第三方模块通过 URL 或者文件路径导入 当未捕获的错误发生时，Deno 总是会异常退出 兼容 Web 的运行时 APIs，更利于前后端的代码同构。 四、如何使用 DenoDeno 能够在 macOS、Linux 和 Windows 上运行。Deno 是一个单独的可执行文件，它没有额外的依赖。 1.安装在 macOS 下可以通过Shell命令安装： 1curl -fsSL https://deno.land/x/install/install.sh | sh 这个方式在国内安装会很慢，慢到下不下来。。。so，不推荐。 也可以通过HomeBrew 安装： 1brew install deno 这个方式可以安装下来，但是，安装的版本是 v0.20.0，很低的版本： 并且这个版本不带 upgrade 命令，升级 deno 的时候很不方便。so，也不推荐。 安利通过国内加速器（镜像源 https://x.deno.js.cn ）来安装： 1curl -fsSL https://x.deno.js.cn/install.sh | sh 也可以指定版本： 1curl -fsSL https://x.deno.js.cn/install.sh | sh -s v1.0.0 首次安装，可以看到提示，需要手动配置一下环境变量，配置语句也已经给出： 12$ touch ~/.bash_profile # 创建用户环境变量文件$ vim ~/.bash_profile # 打开文件，将刚才命令行提示给出的配置语句粘贴进去，保存退出。 让配置立即生效： 1$ source ~/.bash_profile 环境变量就设置好了，现在在任何一个新打开的命令行里面都可以使用 deno 命令了。 注意：如果之前使用 brew 安装过低版本的 deno，请使用 brew uninstall deno 卸载 deno 之后，再使用加速器安装高版本，不卸载直接安装高版本不会生效。（别问我为什么知道。。。都是泪。 其他操作系统环境的安装可参考 https://github.com/denoland/deno_install。 如果要升级本地的 Deno，可以运行 1deno upgrade 还可以安装指定的版本： 1deno upgrade --version 1.1.0 这个命令会从 github.com/denoland/deno/releases 获取最新的发布版本（一个可执行的二进制文件 zip 压缩包），然后解压并替换现有的版本。而 github release 的文件使用的是 aws，在国内访问不稳定。 So，升级也推荐使用国内加速器安装指定版本来达到目的。 2.测试安装1deno --version 如果打印出 Deno 版本，说明安装成功。 到这里，我们就安装好 Deno ，并且可以基于 Deno 进行开发了。 3.运行一个远程的项目跑一个远程项目（官方的demo） 1deno run https://deno.land/std/examples/welcome.ts 可以看到在控制台输出”Welcome to Deno 🦕”。 4.运行一个本地的项目起一个最简单的本地服务 123456789// http.jsimport &#123; serve &#125; from "https://deno.land/std@0.57.0/http/server.ts";const s = serve(&#123; port: 8000 &#125;);console.log("http://localhost:8000/");for await (const req of s) &#123; req.respond(&#123; body: "Hello World\n" &#125;);&#125; 可以看到 Deno 在引用第三方模块的方式为 ES6 的 import 语法，并且直接通过 URL 来引入，版本号也被锁定在了 URL 中。 另外，Deno 支持 顶层的 await 语法，不用与 async 语法配对使用了。 运行： 1deno run http.js 首次引入第三方包，Deno 会去下载这个包和它的依赖，这些包会被缓存到全局，下次再引入的时候，将直接读取缓存。 这里报了一个缺少网络权限的错，这是因为 Deno 采用沙箱模式运行代码，网络权限必须通过手动添加 flag （–allow-net）来开启。 带上网络权限运行： 1deno run --allow-net http.js 打开localhost://8000 可以看到一个简单的本地服务就跑起来了。 5.其他相关配置如果我们要高效地使用 Deno，最好还需要设置一些开发环境，比如环境变量、命令行自动补全、编辑器等。 环境变量 DENO_DIR：这是 Deno 在本地存放生成的代码和缓存下载的模块的路径，默认为 $HOME/Library/Caches/deno。 NO_COLOR：这个会关闭输出的文字颜色。 HTTP_PROXY 和 HTTPS_PROXY ：这两个变量用来设置 HTTP 和 HTTPS 的代理地址。 命令自动补全通过 deno completions 命令可以生成补全脚本。他会输出到 stdout，应该将它重定向到适当的文件。 Deno 支持的 shell 有 zsh、bash、fish、powershell、elvish。 编辑器插件我们可以给 VS Code 配置 Deno 的插件： vscode_deno 如果你是其他编辑器/IDE，可以参考官网推荐的插件 Deno 将来会取代 Node.js 吗？这也是很多前端者关心的话题，网络上两种声音都有，我的看法是：会共存，但不会取代。 首先，Node.js 的作者之所以开发 Deno 只是为了兑现他心目中对 JavaScript Runtime 的一个理想实现，并不是为了取代 Node.js； 其次，Node.js 经过十多年的发展，已经很成熟了（虽然在 Ryan 的眼里不那么完美），并且已经被广泛应用。个人认为，将来 Deno 要做的事情，Node.js 都能做，如果没有特别的因素（比如潜在的安全隐患等），已经使用了 Node.js 的应用，不大会改用 Deno 重构。 所以，以我目前的认知，我认为 Deno 如果能发展起来，应该会与 Node.js 共生，而不会取代 Node.js。 不管怎样，我很钦佩 Ryan，在 Node.js 获得如此成功之后，仍然怀揣对作品的理想追求，大胆分享自己在 Node.js 中犯的“错误”，开始 Deno 的征程，并且现在 Deno 正在以飞快的速度在迭代。就在昨天，Deno 又发布了 V1.1.0。 结语以上是我对 Deno 的一个初探，解答了什么是 Deno，它有什么作用，有哪些特点，与 Node.js 有什么不同，以及如何使用 Deno（虽然只浅浅地跑了最简单的程序，但足以让我感觉到 Deno 与 Node.js 在使用上的不同）。现在，总算对 Deno 的有了一个比较清晰的了解。 有兴趣交流的小伙伴可以在这里留言讨论：https://github.com/yc111/yc111.github.io/issues/2Deno 交流QQ群：698469316 -End- 参考Deno Manual：https://deno.land/manualDeno Doc：https://doc.deno.land/https/github.com/denoland/deno/releases/latest/download/lib.deno.d.tsDeno中文社区：https://denocn.org/Deno中文开发者社区：https://deno.js.cn/Deno中文手册：https://nugine.github.io/deno-manual-cn/Futures 和 Tokio 项目的前世今生：https://rustcc.cn/article?id=8af74de6-1e3d-4596-94ca-c3da45509f58 文章首发于于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>deno</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你有多久没有进行深度思考了？]]></title>
    <url>%2F2020%2F05%2F23%2F%E4%BD%A0%E6%9C%89%E5%A4%9A%E4%B9%85%E6%B2%A1%E6%9C%89%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E4%BA%86%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[近日在知乎无意中看到一篇「如何培养自己深度思考的习惯」的文章，里面的很多观点，我赞同不已。 其中一个观点我总结起来就是：“深度思考有两个方向：上推式思考，下推式思考。上推式思考的精髓就是 为什么；下推式思考的精髓就是 假设。” 这跟我一直以来的思维方式不谋而合，同时也再次引发我对深入思考这件事的思考。 另外，我还被文中引入的一个理论所吸引，那就是「奶嘴理论」，忍不住去查了下这个理论的来龙去脉，感觉对这个世界的本质，又多了一层认知。 一、奶嘴理论在互联网越来越发达的今天，我们深度思考的机会反而越来越少。我们的生活可能已经被一些娱乐、游戏、媒体信息给填满了，深度思考的能力在退化。 对于这种现象，或许我们会认为，这是信息化的发展导致的必然，是文明发展到一定阶段自然衍生的现象，但实际上，从某种程度上来说，这一切都是有人蓄意让其发生的。 1995年，美国旧金山举行过一个全球精英会议。500名政经精英在会议上，为全球化的世界进行分析与规划。大家一致认为： 二八定律真切地存在。 竞争会越来越激烈，而80%的人，将越来越贫穷，地位越来越边缘化。 于是，问题来了，这80%的“loser”，与剩余20%的精英之间，必然存在冲突。冲突如果剧烈，社会就会动荡。如何解决这一问题呢？ 美国当代著名的战略思想家布热津斯基就此提出了著名的 Titty Tainment 战略（奶嘴理论）。 这80%的人，他们不必也无法参与产品的生产和服务，同时80%的财富掌握在另外20%的人手中，为了安慰社会中“被遗弃”的人，避免阶层冲突，可以给这80%的被边缘者一个“奶嘴”，让他们心安理得接受被抛弃的命运。当80%被边缘者安分守己，无心挑战现有的统治阶级，20%的精英就能高枕无忧。 所谓“奶嘴”的安慰，就是采取温情、麻醉、半满足，娱乐化、低智化、游戏化、低成本、轻易就能获取刺激性快乐的办法，来卸除边缘化人口的不满。 布热津斯基认为，有两种娱乐方式能够实现这个想法：一是发泄型娱乐，比如开放色情产业、赌博产业，鼓励暴力网络游戏等，二是满足型娱乐，比如播出一些明星花边，家长里短，肥皂剧、偶像剧、真人秀等大众化视听娱乐。 用这些令人沉迷的消遣娱乐和充满感官刺激的产品填满人们的生活，转移其注意力和不满情绪，让这80%的人沉浸在这些“快乐”跟“安逸”之中，不知不觉丧失对现实问题的思考能力。 当娱乐大量占用人们的时间，人们慢慢地安于为他们量身打造的娱乐信息当中，便不会再抗争，也不会再思考，他们会期待媒体为他们进行思考，媒体替她们做出判断。 所以，娱乐要越多越好，游戏要越普及越好，综艺与真人秀要随处可见，低智的、无逻辑的、甚至堪称恶俗的偶像剧要一部接一部。当这些东西触手可及，底层人就会安分下来，快乐地、毫无怨言地、无知无觉地继续贫穷，继续无所得，然后虚度一生。 这一社会麻醉剂将会带来“马太效应”，沉迷的人继续沉迷，清醒的人保持清醒，人与人的差距，甚至阶层间的差距也就拉大了。 二、保持思考的重要性看过这个奶嘴理论，是不是有些细思极恐？无形之中，我们的生活，我们的发展道路似乎在被一双隐形的大手操控，而我们可能一边被牵着走，一边还以为这是自己内心的想法。 奶嘴理论的实施，理论上它将影响的对象是所有人，但是为什么那20%的人没有受到影响呢？我想不用我说，大家也应该知道了吧，那就是思考的力量。当一个人拥有清醒的头脑，独立思考的能力，就可以看清一些现象背后的本质，然后对事物有个比较全面的判断。这项技能，让TA可以摆脱奶嘴战略的影响，成为那20%的人。 那么，有人要说，我也知道天天刷剧看小说玩游戏不对，我也想有思考和控制自己的能力，但是我做不到啊，我一动脑筋就头疼，想不来，我可能天生没有思考的基因。 三、思考能力、观点是怎么形成的首先，我想说的是，有以上这些消极观点的人，随口都能说出一堆借口的人，你们已经被奶嘴战略侵袭已久，并且对自己的现状已经形成一套自洽的闭环理论，让自己可以心安理得地继续堕落。如果没有因此遇到特别大的挫折和打击，是很难走出这个闭环牢笼，因为它给你营造了一个低成本的虚假安逸感，而走出的过程会很痛苦。 其次，如果你还有一丝理智，靠自己走出来，也不是不可能。不过这个的前提，是你要知道思考能力、观点是怎么形成的，这样，你才可以通过摸索实践，唤起脑细胞的活动，重拾思考能力。 一般情况下，我们的观点形成，需要经历这么几个步骤： 直觉在我们什么都不知道的时候，在知识也缺乏，信息也缺乏，能力也不够的时候，我们对一个事情，首先有的是直觉。这个时候，靠的是思维的条件反射和以前的认知形成的潜意识，这是一种非常浅层次的思考，甚至算不上思考。 直觉受到挑战直觉很容易带来的一个东西，叫做偏见。随着你接触的事情越来越多，你的偏见总有一天会遭到挑战。 自我辩论当你看到另一些事情，或者接触到另一些观点，跟你之前的直觉不一致的时候，你可能会在头脑中产生辩论，因为你要给自己一个说法，到底哪一个才是对的，这个时候你就开始有了判断力，你的三观也在悄悄建立。 形成自己的观点最后你终于积累了很多的经验，在看了很多的观点之后，形成了自己比较认同的观点，这个观点相对来说，会比较兼顾，比较稳定，因为它经历了整个思考过程，一段时间内不会变化。 四、如何深度思考要实现一个目标，我们需要努力，努力需要一个方向，并且最好是正确的方向，否则，就是瞎忙。思考也是一样，没有方向的思考，不利于理清问题，沿着错误的方向思考，则会让事情耗时且无进展。 如何深度思考，我很赞同开篇提到的那两个方向：上推思维和下推思维。 上推思维上推式思考的精髓，就是“问为什么”。它可以很好地培养自己透过现象看本质的能力。 我们不能总是被信息主导着往下想，要想办法往上想，要想为什么，找问题的源头。当我们问到不能再问为什么的时候，就越接近事情的根本原因，然后我们再下结论，就完成了深度思考的过程。如果你一直被信息引导着下结论，你的思维会越来越肤浅。 下推思维下推式思考的精髓，叫做“假设”。它可以很好地培养自己的判断能力。 我们可以追溯证据来源及可靠性，可以平行对比，当然最多的，是通过提出假设，然后在假设成立的情况下，思考事情会怎么样，然后再反推这个假设是否合理。这有点像数学中经常用来解证明题的反证法。 五、弱思考能力的几个特征如果你不知道如何判断自己的思考能力是否OK，那么你可以通过以下几点来自我检测一下，这些列举的点是被认为思考能力较弱的一些特征： 不喜欢有深度的内容当看到需要动脑思考的内容，不能静下心去思考，而对一些虚构的故事情节非常能看得下去，容易沉浸在一些虚假的幻想当中。 情绪化用情绪代替思考，容易被别人的情绪所影响，而不是对方表达的内容。 混淆情感跟逻辑容易被情感绑架，当一句话中情感的部分被你认同，里面的逻辑你会无条件地接纳。 喜欢说经验未能意识到经验是特定场景才能成立的个例，如果不加以提炼升华为更通用的理论，很容易以偏概全。 把假设当结果对事情的前提完全没有质疑意识，也就很难发现自己基于这个前提之下的所有思考的基石，很有可能根本都站不住脚。 用现象代替原因未能透过现象看到本质，思考浅尝则止，经常导致一通努力过后但是效果不佳。 人云亦云从众思想，大家都这么说，那一定是没错；向来都是这样，那一定是没问题。缺乏对大众舆论的质疑精神。 六、一些我认为很好的建议： 拒绝低幼化的语言刺激语言会影响我们的思维，甚至有人认为谁掌握了语言，谁就掌握了思维。那么什么是低幼化的语言刺激？绝大多数的网络流行语都是。诸如“我也是醉了”“666”“扎心”“你看这个面，它又长又宽”……所以日常生活中，尽量能拨出一定时间，看深度的、优秀的数据和文章，保持自己对语言的理解和运用能力。 拒绝抢夺注意力的低劣产品如果可以，拒绝从众，拒绝那些肤浅的综艺、影视剧、热点消息、娱乐圈资讯，只看最优秀的作品。不要让自己成为愉悦感的奴隶。不动脑子，能带来短期的愉悦和轻松，但长期来看，它只能导向空虚和无聊。 为自己设定有意义的目标请找到一件能够带给你长期收益和幸福感的事情，把它安排进每天的日程中。它可以帮助你对抗庸常，平凡，让你保持头脑清醒。 结语当你满足于低质量的消遣和享乐，自律会一点一点丧失，意志力会逐渐瘫软。你不会再思考，也不再向往艰难的事业。你会恐惧挑战，恐惧前行。你会在一个接一个的综艺中，在一坨又一坨的碎片资讯里，一阵接一阵的低质量欢愉中，走向你的颓废。 你有多久没有进行深度思考了？你是否经常置身于充满感官刺激的娱乐、碎片化的信息和无尽的游戏中？你是否意识到，你的的注意力全部被娱乐、信息或者游戏占据，时间全部被消耗？ 如果你中招了，不妨从现在开始，保持思维上的警惕，远离一切让你停止思考的事情，刻意坚持思考。 随着深度思考成为了习惯，你也将逐渐成为更优秀的人。 – 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>thought</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Electron实战（一）安装]]></title>
    <url>%2F2020%2F04%2F25%2FElectron%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言我们知道，JavaScript 是用来开发网站的脚本语言。Javascript 开发出来的网页必须依赖浏览器来解析。 而桌面客户端，通常是由 C++ 、C# 等语言来完成。不过现在，我们可以用 JavaScript 来开发桌面客户端了！当然，要借助一点外力，那就是：Electron。 什么是Electron？Electron 是一个使用 JavaScript，HTML 和 CSS 等Web技术构建跨平台的桌面应用程序的框架。这意味着，如果你可以建一个网站，你就可以建一个桌面应用程序。 Electron 基于 Chromium 和 Node.js，它可以让你使用纯 JavaScript 调用丰富的原生(操作系统) APIs 来创造桌面应用。你可以把它看作一个 Node. js 的变体，只不过它专注于桌面应用而不是 Web 服务器端。 但这不意味着 Electron 是某个图形用户界面（GUI）库的 JavaScript 版本。相反，Electron 使用 web 页面作为它的 GUI，所以你可以把它看作成一个被 JavaScript 控制的，精简版的 Chromium 浏览器。 历史2013年4月，Atom 编辑器问世，作为实现它的底层框架 Atom Shell 逐渐被熟知。 2014年5月，Atom Shell 开源。 2015年4月，Atom Shell 改名为Electron。 用Electron开发的桌面应用Electron 已经被多个开源应用软件所使用，除了 Atom，著名的编辑器 VsCode 也是基于 Electron 实现的。 打开 VsCode，点击帮助菜单中的Toggle Developer Tools，可以在界面上看到我们熟悉的 Chrome devtool，如下图： Electron 程序基本结构从开发的角度来看, Electron application 本质上是一个 Node.js 应用程序。与 Node.js 模块相同，应用的入口是 package.json 文件。一个最基本的 Electron 应用一般来说会有如下的目录结构： 1234your-app/ ├── package.json ├── main.js └── index.html 说了这么多，是不是有些心痒痒，迫不及待想知道怎么上手electron，用 JS 来捣鼓桌面应用了？别着急，我们先把开发环境搭好。 安装ElectronElectron 通过 npm 来安装： 1npm install electron --save-dev 但因为默认会从 GitHub 上下载，即使将 npm register 指向 taobao 镜像也不行，它内部还是会通过 GitHub 的发布下载页面来下载 electron 的二进制 release 文件，如果你不能翻墙，安装会很慢，基本上是下不下来。 所以如果你不能翻墙，又想要顺利下载 electron，就得自定义 electron 的镜像和缓存。 自定义镜像你可以通过环境变量来覆盖 Electron 二进制文件的URL和文件名。这个URL将被 @electron/get 使用，格式如下： 1url = ELECTRON_MIRROR + ELECTRON_CUSTOM_DIR + &apos;/&apos; + ELECTRON_CUSTOM_FILENAME 例如，使用 Electron 的中国镜像（taobao）： 1ELECTRON_MIRROR=&quot;https://cdn.npm.taobao.org/dist/electron/&quot; 我们需要在项目根目录下，添加一个名为 .npmrc 的文件，将上面的镜像配置写进去。这样当我们进行 npm install 的时候，就会读取项目根目录下的 .npmrc 文件使用你配置的镜像地址来下载了。 自定义缓存或者，你可以直接覆盖本地缓存。@electron/get 会在本地的特定目录缓存下载下来的二进制文件，来缓解你的网络压力，提升安装速度。所以我们可以使用该缓存文件夹来提供 Electron 的定制版本，或者避免进行网络连接。 在不同操作系统下，Electron 默认的缓存目录如下： Linux: $XDG_CACHE_HOME or ~/.cache/electron/ MacOS: ~/Library/Caches/electron/ Windows: $LOCALAPPDATA/electron/Cache or ~/AppData/Local/electron/Cache/ 另外：在使用旧版本 Electron 的环境中，我们也可以在 ~/.electron 中找到缓存。我们还可以通过提供 electron_config_cache 环境变量，来重写本地缓存路径。 缓存包含两部分内容： 版本的官方zip文件 校验和（存储格式为文本文件） 典型的缓存可能如下所示： 1234├──httpsgithub.comelectronelectronreleasesdownloadv1.8.1electron-v1.8.1-darwin-x64.zip│ └── electron-v1.8.1-darwin-x64.zip├──httpsgithub.comelectronelectronreleasesdownloadv1.8.1SHASUMS256.txt│ └── SHASUMS256.txt 我们可以直接从淘宝源下载二进制包electron-v1.8.1-darwin-x64.zip，在缓存路径下（例如我这里是 Mac 中的 ~/Library/Caches/electron/ ）新建上述目录结构，放进去。 electron 淘宝源下载地址（有两个，任意选一个下载就行）： 1.https://npm.taobao.org/mirrors/electron/8.1.1/electron-v8.1.1-darwin-x64.zip 2.https://cdn.npm.taobao.org/dist/electron/v8.1.1/electron-v8.1.1-darwin-x64.zip 校验和淘宝源下载地址： https://npm.taobao.org/mirrors/electron/8.1.1/SHASUMS256.txt 配置完缓存后，再来 npm install ，npm 会先从缓存目录中读取二进制缓存，由于我们已经下载好了，npm 会直接使用缓存，而不会再去网络上获取了。 结语现在，我们已经准备好了 electron 的开发环境了，接下来我们将要开发一个最简单的 elecrton 应用。（下一篇待续） 有兴趣交流的小伙伴可以在这里留言讨论：https://github.com/yc111/yc111.github.io/issues/1 文章首发于于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>electron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底弄懂GMT、UTC、时区和夏令时]]></title>
    <url>%2F2020%2F04%2F24%2F%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82GMT%E3%80%81UTC%E3%80%81%E6%97%B6%E5%8C%BA%E5%92%8C%E5%A4%8F%E4%BB%A4%E6%97%B6%2F</url>
    <content type="text"><![CDATA[格林威治时间、世界时、祖鲁时间、GMT、UTC、跨时区、夏令时，这些眼花缭乱的时间术语，我们可能都不陌生，但是真正遇到问题，可能又不那么确定，不得不再去查一查，处理完可能过段时间又忘记。今天，我们彻底来梳理一下它们。 一、GMT什么是GMTGMT（Greenwich Mean Time）， 格林威治平时（也称格林威治时间）。 它规定太阳每天经过位于英国伦敦郊区的皇家格林威治天文台的时间为中午12点。 GMT的历史格林威治皇家天文台为了海上霸权的扩张计划，在十七世纪就开始进行天体观测。为了天文观测，选择了穿过英国伦敦格林威治天文台子午仪中心的一条经线作为零度参考线，这条线，简称格林威治子午线。 1884年10月在美国华盛顿召开了一个国际子午线会议，该会议将格林威治子午线设定为本初子午线，并将格林威治平时 (GMT, Greenwich Mean Time) 作为世界时间标准（UT, Universal Time）。由此也确定了全球24小时自然时区的划分，所有时区都以和 GMT 之间的偏移量做为参考。 1972年之前，格林威治时间（GMT）一直是世界时间的标准。1972年之后，GMT 不再是一个时间标准了。 二、UTC什么是UTCUTC（Coodinated Universal Time），协调世界时，又称世界统一时间、世界标准时间、国际协调时间。由于英文（CUT）和法文（TUC）的缩写不同，作为妥协，简称UTC。 UTC 是现在全球通用的时间标准，全球各地都同意将各自的时间进行同步协调。UTC 时间是经过平均太阳时（以格林威治时间GMT为准）、地轴运动修正后的新时标以及以秒为单位的国际原子时所综合精算而成。 在军事中，协调世界时会使用“Z”来表示。又由于Z在无线电联络中使用“Zulu”作代称，协调世界时也会被称为”Zulu time”。 UTC 由两部分构成： 原子时间（TAI, International Atomic Time）:结合了全球400个所有的原子钟而得到的时间，它决定了我们每个人的钟表中，时间流动的速度。 世界时间（UT, Universal Time）:也称天文时间，或太阳时，他的依据是地球的自转，我们用它来确定多少原子时，对应于一个地球日的时间长度。 UTC的历史1960年，国际无线电咨询委员会规范统一了 UTC 的概念，并在次年投入实际使用。 “Coordinated Universal Time”这个名字则在1967年才被正式采纳。 1967年以前， UTC被数次调整过，原因是要使用闰秒（leap second）来将 UTC 与地球自转时间进行统一。 三、GMT vs UTCGMT是前世界标准时，UTC是现世界标准时。UTC 比 GMT更精准，以原子时计时，适应现代社会的精确计时。但在不需要精确到秒的情况下，二者可以视为等同。每年格林尼治天文台会发调时信息，基于UTC。 四、时区随着火车铁路与其他交通和通讯工具的发展，以及全球化贸易的推动，各地使用各自的当地太阳时间带来了时间不统一的问题，在19世纪催生了统一时间标准的需求，时区由此诞生。 时区是如何定义的从格林威治本初子午线起，经度每向东或者向西间隔15°，就划分一个时区，在这个区域内，大家使用同样的标准时间。 但实际上，为了照顾到行政上的方便，常将1个国家或1个省份划在一起。所以时区并不严格按南北直线来划分，而是按自然条件来划分。另外：由于目前，国际上并没有一个批准各国更改时区的机构。一些国家会由于特定原因改变自己的时区。 全球共分为24个标准时区，相邻时区的时间相差一个小时。 在不同地区，同一个时区往往会有很多个不同的时区名称，因为名称中通常会包含该国该地区的地理信息。在夏令时期间，当地的时区名称及字母缩写会有所变化（通常会包含“daylight”或“summer”字样）。 例如美国东部标准时间叫：EST，Estern Standard Time；而东部夏令时间叫：EDT，Estern Daylight Time。 想查看世界所有时区的名字可以访问这个网站：https://www.timeanddate.com/time/zones/ 四、夏令时什么是夏令时DST（Daylight Saving Time），夏令时又称夏季时间，或者夏时制。 它是为节约能源而人为规定地方时间的制度。一般在天亮早的夏季人为将时间提前一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。 全球约40%的国家在夏季使用夏令时，其他国家则全年只使用标准时间。标准时间在有的国家也因此被相应地称为冬季时间。 在施行夏令时的国家，一年里面有一天只有23小时（夏令时开始那一天），有一天有25小时（夏令时结束那一天），其他时间每天都是24小时。 绿色部分为2019年统计的在全球施行冬夏令时的国家和地区。 夏令时的历史1784年，美国驻法国大使本杰明·富兰克林（Benjamin Franklin）提出“日光节约时间制”。1908年，英国建筑师威廉·维莱特（William Willett）再次提出，但当时该提案并未被采纳。 1916年，处于一战时期的德国政府下令将时钟推至一个小时后，通过获得额外一小时的日光来节省战争所需的煤炭，成为第一个实行夏时制的国家。随后，英法俄美四个一战参战国纷纷效仿。 美国在一战结束后于1919年取消夏时制，但在1942年二战时，美国重新启动夏令时制，1966年正式立法确定永久使用。1973至1975年石油危机爆发期间，美国连续两年延长夏令时制，以节省石油。 欧洲大部分国家则是从1976年——第四次中东战争导致首次石油危机（1973年）的3年后才开始施行夏令时制。 1986年4月，中国国务院办公厅发出《在全国范围内实行夏时制的通知》，要求全民早睡早起节约能源：每年4月中旬的第一个星期日2时，将时钟拨快一小时；10月中旬第一个星期日的2时，再将时钟拨慢一小时。但此夏令时只实行了6年，在1992年停止施行，主因是中国东西地域广阔却只奉行一个北京时间，实时夏令时制带来很多不切实际的反效果。 夏令时的争议从过去的100多年来看，夏令时往往是在国家发生严重危机（如战争和能源短缺）的情况下才会受到青睐。而在相对和平的近10年里，这种时间制度则变得越来越不受欢迎。 它会使得人们的生物钟被扰乱，常常陷入睡眠不足的情况，不仅对人体健康有害、导致车祸，还会对旅游、航空领域造成极大的混乱。 另外，冬、夏令时究竟能否起到节能的作用，也仍有待商榷。美国一项截至2014年3月的研究表明，这种时间转换制度最多能在3、4月帮助美国减少1%的用电量，而美国国家标准局则认为，夏令时对用电量没有丝毫影响。 在俄罗斯，此前的一份报告也显示，夏令时帮助俄罗斯每年节约的电量，仅相当于两三个火力发电厂的发电量，十分的“鸡肋”。 去年（2019年）3月26日，作为全世界第一个提出并实行夏令时的国家，德国，在欧洲议会上以410比192的赞成票通过了取消冬、夏令时转换制提案，拟定于2021年4月起，所有欧盟国家不再实行冬、夏令时转换。待各成员国形成最终法案后，将选择永久使用夏令时时间或是冬令时时间。 五、本地时间在日常生活中所使用的时间我们通常称之为本地时间。这个时间等于我们所在（或者所使用）时区内的当地时间，它由与世界标准时间（UTC）之间的偏移量来定义。这个偏移量可以表示为 UTC- 或 UTC+，后面接上偏移的小时和分钟数。 六、JavaScript中的Date得到本地时间，在不同时区打印 new Date() ，输出的结果将会不一样：1new Date(); 得到本地时间距 1970年1月1日午夜（GMT时间）之间的毫秒数：1new Date().getTime(); 返回本地时间与 GMT 时间之间的时间差，以分钟为单位：1new Date().getTimezoneOffset(); 如何在任何地方都能正确显示当地时间（只要知道该地的timezone）：12345678910111213//目标表时间，东八区let timezone = 8；//获取本地时间与格林威治时间的时间差(注意是分钟，记得转换)const diff = new Date().getTimezoneOffset();//根据本地时间和时间差获得格林威治时间const absTime = new Date().getTime() + diff * 60 * 1000;//根据格林威治时间和各地时区，得到各地时区的时间let localTime = new Date(absTime + timeZone * 60 * 60 * 1000)；//处理夏令时(isDST为自己封装的处理方法)if(isDST(localTime, country)) &#123; localTime = new Date(absTime + (timeZone + 1) * 60 * 60 * 1000)；&#125;return localTime; 结语以上分别从定义、来源等维度解释和扩展说明了GMT、UTC、时区和夏令时的概念、历史、意义，并在最后列举了这些概念在JS项目中的一个非常实用的应用。 简单地讲， GMT 是以前的世界时间标准；UTC 是现在在使用的世界时间标准；时区是基于格林威治子午线来偏移的，往东为正，往西为负；夏令时是地方时间制度，施行夏令时的地方，每年有2天很特殊（一天只有23个小时，另一天有25个小时）。 从源头上彻底了解了这些概念，将会让我们在处理与时间相关的问题时如虎添翼。 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[疫情地图（公益）]]></title>
    <url>%2F2020%2F04%2F10%2F%E7%96%AB%E6%83%85%E5%9C%B0%E5%9B%BE(%E5%85%AC%E7%9B%8A%E9%A1%B9%E7%9B%AE)%2F</url>
    <content type="text"><![CDATA[愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声，有一分热，发一份光，就令萤火虫一般，也可以在黑暗里发一点光，不必等候炬火。此后如竟没有炬火，我便是唯一的光。 上面这个网站就是我们发布的疫情地图，我是这个项目的开发者。开发时忙到飞起，发布后狠狠休息了几天，今天终于缓过来，决定把这一段难忘经历好好写一写。 结缘公益今天是2020年4月9日，距离我们发布全球疫情地图已经过去了3周。昨天凌晨，武汉解封，这意味着国内疫情战争的胜利，虽然防范仍然不能松懈，但是紧张的疫情终于告一段落！与国内形成鲜明对比的，是欧美各国日益严峻的 COVID-19 感染和死亡情况。这是今天的全球数据：美国以40多万确诊数高居第一，中国已经降到第六。 而3个月前，1月23日，武汉宣布封城。微博，公众号，b站，百度等各大社交、新闻媒体都密集地推送着新冠肺炎的新闻、事态、故事、和求助。 1月27日我在知乎发表了一篇「《新型冠状病毒肺炎预防手册》电子书」的文章，把有幸从湘雅医学院老师那获取到的一份从学术角度分析的实用科普手册，分享了出去，短时间内就有几千人阅读。在原帖的基础上，我不时地把我收集到的小tip更新上去，希望为新冠肺炎防护知识的普及作出一点微小的贡献。 本以为，我对抗击疫情的能做的事就仅限于此了。 直到，1月30日，我在浏览知乎的时候，无意看到一篇关于新冠疫情志愿者组织的文章，通过里面贴出的二维码，我加入了其中一个组织——nCoV疫情地图项目组。 负责开发很快有相关人找到了我。简单沟通后，我开始着手开发。 用了不到2天时间，我搭建好框架并做了一版仿丁香园的 Demo，发了过去。 2月1日，组织方表示，将在我的代码基础上进行开发，我也顺理成章成为了这个志愿者项目的前端负责人。 之后，不断有新的志愿者加入进来，群成员不断壮大，我同时担起了分配任务的职责。还好我搭的框架够健壮，分配的任务都可以很有逻辑地在框架中找到位置。我们的代码开源托管在 GitHub 上，为了在 GitHub 上更好地多人协作，我不得不马上制定了 GitHub 协作规范，约定分支管理、pr 和代码审核流程。事实证明效果非常好，大家开始有意识地通过 pr 来贡献代码。 一切都进展的如火如荼，一片欣欣向荣的景象。 然而这场顺利的场景没有持续多久。 首先是年假结束，参与开发的人陆续开始上班，逐渐退出。然后是我们在2月中旬遭受了一个非常大的组织动荡，让前一秒还在贡献代码的我们有些措手不及。。。由于影响较大，志愿者们的积极性受到了很大的打击，而此时，我们的项目还只开发了不到三分之一。。。 舍弃旧版消沉了几天，不忍看到项目就此夭折，我决定尝试独自奋战，完成它。 我做了这些事情： 1. 精简需求首先，我砍掉了之前产品组提出的需求中的非核心的功能，将业务聚焦到实时地图和数据播放着两个核心功能上。 2. 重新设计交互然后，我舍弃了之前设计组提供的半成品设计稿，以自己的设计经验（我曾是一名设计师），重新设计了交互和视觉。 最大化地图的视野，突出重点信息，尽可能地做到简洁和体验友好。 地图控制栏： 疫情时间轴，可以自动播放、手动上一天下一天，也可以直接点击查看某一天的数据： 全球 COVID-19 病例累计dashboard： 全球感染国家的确诊、死亡、治愈统计表，可以按不同维度排序，点击国家地图联动定位到该区域： 3. 重构代码之前由于人多手杂，又追求快，地图业务逻辑代码交织耦和在一块，非常不利于复用、扩展和维护。于是我花了一些时间，重构了一把。 4. 增强功能在开发的过程中我随手给网站加上了一些增强的功能： 支持换肤 支持多语言 支持移动端友好 这些做完，几乎是推翻了所有原有的功能和设计，完成了一版全新的疫情地图！ 现在，距离一个可用产品，还差数据接口和部署两步。 搞定后台疫情数据和数据接口本应由后端开发组提供，但是始终没有动静，估计是无法等到了。不等了，我自己来吧！ 1. 解决数据问题造数据库已来不及，只能爬数据。通过对丁香园、百度疫情地图、新浪等公开的网站的数据结构分析，锁定MapBox官网上的疫情地图网页，上面的数据非常符合我的需求。 研究了它的网站接口后，我用 nodejs + express 成功爬取到了我需要的疫情数据。 随着将其封装为数据API接口、在 nodejs 服务端配置 cors 解决完跨域的问题，数据接口服务搞定！ 2.解决部署在自己购买的阿里云服务器上，我将80端口交给了 nginx ，便于以后做集群和负载均衡。 用 nodejs + express + pm2 部署了好了一个支持 history 前端路由的静态资源服务器。 然后通过 nginx 将两个服务（数据 api 接口服务器和网站静态资源服务器）进行反向代理。 最后将前端打包后的资源文件往public目录一放。 部署也搞定了！ 3.性能优化目前，打开网站，基本上5秒内首屏即可加载完毕（当然，还需要继续优化），这个速度已经是我做了性能优化的结果，有兴趣可以看我之前的这篇文章「一次网上优化全记录」，详细记录了我将首屏加载由1分钟优化到5秒的过程。 发布做完所有我认为可以做的事情之后，3月16日，我将在自己的服务器部署的最终版 coronovirus-map 地址，发给了组织方(当时来不及买域名，给的裸的ip地址)。 组织群里惊喜不已，沉寂好久的群也开始变得热闹起来，接下来的事情，我就轻松了。负责宣传的志愿者们张罗着在组织的新公众号「地图学人」上发表了文章：「关于疫情，这是独一份的热图——nCoV疫情地图（PC端）发布」，隆重地官宣了一番。 当天，地图就有美国、加拿大、澳大利亚等境外的用户在访问了。 另外，我居然收到了加入的另一个自愿者组织——武汉2020发送的公益志愿者证书，我在那个组织只是冒泡咨询，远没有在这个组织做的事情多，然而却发给了我这么有仪式感的证书，感觉逼格比我们高得多啊🤪 3月19日，由组织发起人的推荐，我接受了中国日报 China Daily 新闻记者的采访。 4月1日，ChinaDaily 在 Youth 板块刊登了对我们的报道。 写在后面covid-19 疫情在世界范围内还没有结束，通过这份地图，我们可以很直观地看到整个疫情在世界范围内一路演变的历程。美国和欧洲感染率一度以指数级在增长。希望疫苗能早日研发出来。在那之前，这份地图将持续承担展示全球疫情态势的任务，为用户提供疫情数据可视化的服务。 感谢当初没有无视那些二维码的自己，才能有这样一个契机，用自己擅长的的专业能力为抗击疫情做了微小的贡献。 感谢这些自愿者组织的发起人们，让我们一群互不相识的人聚在了一起，用善意为疫情做了有意义的事情（虽然过程中也有波折）。 一直以来我都很想尝试做一次完整的全栈，说起来，也要感谢这次公益项目，给了我实践的机会。 不要小看自己所做的事，哪怕是非常微小的帮助，也是很有价值的。 很喜欢鲁迅先生在他的杂文集《热风》中说过的一段话： 愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声，有一分热，发一份光，就令萤火虫一般，也可以在黑暗里发一点光，不必等候炬火。此后如竟没有炬火，我便是唯一的光。 愿这个世界越来越好！ —附上我们的疫情地图地址：http://map.champyin.com/situation 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>map</tag>
        <tag>covid_19</tag>
        <tag>mapbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发一个时间小程序]]></title>
    <url>%2F2020%2F04%2F08%2F%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E6%97%B6%E9%97%B4%E5%B0%8F%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言跟异国他乡的朋友们微信聊天的时候，经常面临时差的问题。我每次想要确定对方现在是几点，总是要口算一下，有时忘记具体时差，或者涉及跨天，还得打开浏览器查一下，很不方便。有什么方法可以把朋友们所在城市的时间集中起来随时供自己查看呢？于是想到了微信小程序。找了找市面上的时间小程序，不是功能太杂就是小广告太多，不满意。天音：为什么不自己动手量身打造一个呢？ 行动起来。 首先快速明确需求很简单： 需要展示时间的城市初定：加州、纽约，再加北京做对比 需要显示具体的时分秒，和年月日 需要实时变化 在其他国家也能正确展示时间 然后创建项目开撸 怎么创建和前期的准备就不在这里展开了，相信不少人都熟悉。如果不熟悉小程序开发的可以参考官网 或者我的另一篇文章如何开发微信小程序 ，上面有对如何开发小程序的简明扼要的的介绍。 关键逻辑这个小程序的核心是时间的处理。如何得到其他地区的时刻信息？ 这还不简单？先获取本地时刻，然后加上或者减去另外一个地点与国内（北京时间）的时差（小时），最多再处理一下跨天的情况，不就得到其他地点的时刻了？ 我一开始也是这么想的，做完觉得还挺美，准备提交的时候，突然意识到问题：我时差全是基于北京时间计算的，换在其他国家访问，获取的本地时间已经不是北京时间了，时差应该变才对，写死了时差可还行？！发布一个只能在国内使用的鸡肋时间工具，可不是我的风格！ 捣鼓一阵，新方案出炉： 想办法获得零时区的时间 获取不同地区与零时区的时差（时区） 用零时区的时间加减与零时区的时差（时区），得到各地的绝对时间 1. 获得零时区的时间零时区，也叫中时区，位于英国格林威治本初子午线上。该时区的地方时，叫做格林威治时间，也叫世界时。 我们不能直接获得格林威治时间，但是我们可以获得本地与格林威治的时间差：1const diff = new Date().getTimezoneOffset() // 单位为分钟 然后根据本地时间和时间差获得格林威治时间：1const absTime = new Date().getTime() + diff * 60 * 1000; 2. 查询各地时区格林威治本初子午线将地球划分为东西两个半球，格林威治本初子午线为零时区，往西依次为西一区到西十一区，往东依次为东一区到东十一区，西十二区和东十二区重合成为东西十二区，一共划分了24个时区，每个时区相差正好是1个小时。 北京是东八区，纽约是西五区，加州是西八区。 完整时区地图： 3. 计算各地的绝对时间东时区的时刻比零时区快，西时区的时刻比零时区慢，所以东时区为正，西时区为负，所有时间计算记得转换为毫秒。1let localTime = new Date(absTime + timeZone * 60 * 60 * 1000); 获取任何时区的绝对时间的完整核心代码：123456789101112131415161718/** * timeZone: 东n区为正，西n区为负, 单位为小时 */const getFullTimeInfo = (timeZone, country, spliter) =&gt; &#123; //获取本地时间与格林威治时间的时间差(注意是分钟，记得转换) const diff = new Date().getTimezoneOffset(); //根据本地时间和时间差获得格林威治时间 const absTime = new Date().getTime() + diff * 60 * 1000; //根据格林威治时间和各地时区，得到各地时区的时间 let localTime = new Date(absTime + timeZone * 60 * 60 * 1000) return &#123; time: formatTime(localTime, spliter) &#125;;&#125; 发布很快，第一版就完成了。 刚开始这个样子略丑，有点裸奔的赶脚。不过第一版最主要是核心功能，简陋的界面只是暂时的。 给当地的朋友检验确定时间展示正确后，提交代码、提交审核，2天后收到审核通过的通知（吐槽腾讯的审核效率😓），然后在小程序管理平台点击发布，哦了。 扫描二维码，打开小程序，然后收藏。以后要看时间了，微信主界面向下一拉，打开我的时间工具，一眼就看到想要知道的时间信息，确实比之前便捷多了。功能虽然简单，界面虽然简陋，但是妥妥滴满足我的需求。 迭代用了一阵子，觉得样式啥的还是得丰富丰富，于是花了一些时间做了一次改版，实时时间以时钟效果展示，并且修改了布局，顺便重构了一下代码，便于新增地区。 嗯，效果似乎还行～ 改BUG前几天跟澳洲的朋友聊天，聊着聊着居然发现了我的程序的一个潜在BUG。 那天是4月4日的早晨（北京时间），我跟朋友吐槽我的一个疑惑：查询悉尼时区为东十区（即与北京相差2小时），但是为啥查询悉尼时间却与北京相差3小时（所以我当时程序中是把悉尼作为东十一区来计算的）。朋友说：是的没错，我们这里现在在使用夏令时，等夏令时结束就恢复2个小时时差了。然后一查，今年澳洲夏令时将在4月5号凌晨3点结束。。。 也就是说，距离这个BUG发作还有不到一天的时间。。。 马上打开电脑，改BUG。。。 根据资料，获得美国和澳大利亚的夏令时规则： 美国每年的3月第二个星期日02:00:00，时钟向前调整1小时，变为03:00:00，开始夏令时。每年的11月第一个星期日02:00:00，时钟向后调整1小时，变为01:00:00，结束夏令时。 澳大利亚每年的10月第一个星期日02:00:00，时钟向前调整1小时，变为03:00:00，开始夏令时。每年的4月第一个星期日03:00:00，时钟向后调整1小时，变为02:00:00，结束夏令时。 关于夏令时，也挺有意思，有空我会另开一个篇幅来专门讲述。 将夏令时的判断逻辑加上：1234567891011121314151617181920212223242526/** * timeZone: 东n区为正，西n区为负, 单位为小时 */const getFullTimeInfo = (timeZone, country, spliter) =&gt; &#123; //获取本地时间与格林威治时间的时间差(注意是分钟，记得转换) const diff = new Date().getTimezoneOffset(); //根据本地时间和时间差获得格林威治时间 const absTime = new Date().getTime() + diff * 60 * 1000; //根据格林威治时间和各地时区，得到各地时区的时间 let localTime = new Date(absTime + timeZone * 60 * 60 * 1000)+ // 考虑夏令时+ // judgeDST 是我封装好的一个判断夏令时的方法+ const isDST = judgeDST(localTime, country);+ if (isDST) &#123;+ localTime = new Date(absTime + (timeZone + 1) * 60 * 60 * 1000)+ &#125; return &#123; time: formatTime(localTime, spliter).split(':').slice(0,2).join(':'), isDST &#125;;&#125; 有了现在的版本： 以后对这个小工具我还会不断优化，会越来越灵活，比如支持地区选择，这样每个人都可以定制自己的时差表了。可以期待一下哦～ 最后附上小程序二维码，扫一扫即可体验。 –还是毛爷爷说得好：自己动手丰衣足食。 Happy coding :) 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何开发微信小程序]]></title>
    <url>%2F2020%2F04%2F07%2F%E5%A6%82%E4%BD%95%E5%BC%80%E5%8F%91%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[小程序是一种不需要下载安装即可使用的应用。它是连接用户与服务的新方式，它实现了应用“触手可及” 的梦想，用户通过扫一扫或者搜一下即可打开应用，应用将无处不在，随时可用，用完即走。 2017年1月，微信正式推出微信小程序。同年9月，支付宝也推出了支付宝小程序。2018年7月，百度也不甘落后，推出百度智能小程序。从此BAT三巨头都进军了小程序领域。 此篇是微信小程序开发的一个简明介绍和关键说明。 微信小程序的主要开发语言是 JavaScript，如果你使用过 Vue 或者 React，你将会对微信小程序的开发有一种亲切感，它们的一些理念有一些类似，比如数据绑定、数据驱动视图等。 不过跟开发普通网页不同，开发微信小程序需要进行一些特定的准备工作。 一、准备工作 注册小程序账号注册地址 获取AppID位于小程序管理平台的菜单 “开发”-“开发设置” 安装小程序开发者工具下载地址 配置项目 打开小程序开发者工具，用微信扫码登录开发者工具 新建项目 选择小程序项目 选择在本地准备好的代码路径 填入第二步获取到的AppID 完成，进入开发界面 微信开发者工具会很贴心地为我们初始化好一个默认的工程，好让我们不用从零开始编写。 二、一些重要的概念 小程序的组成小程序包含一个描述整体程序的 app 和多个描述各自页面的 page。 一个小程序主体部分由三个文件组成，必须放在项目的根目录： app.js 小程序逻辑 app.json 小程序公共配置——相当于html app.wxss 小程序公共样式表（非必须）——相当于css 一个小程序页面由四个文件组成： .js文件 页面逻辑 .wxml文件 页面结构 .json文件 页面配置（非必须） .wxss文件 页面样式表（非必须） 为了方便开发者减少配置项目，描述页面的四个文件必须具有相同的路径与文件名。 最终，一个小程序的基本目录结构，大致长这个样子： 12345678910|—pages/| |—about/| |—about.js| |—about.json| |—about.wxml| |—about.wxss|—app.js|—app.json|—app.wxss|—project.config.js // 工具配置,存放开发者对开发工具的一些个性化配置，例如界面颜色、编译配置等 宿主环境每个小程序都是运行在它所在的微信客户端上的，通过微信客户端给他提供的运行环境，小程序可以直接获取微信客户端的原生体验和原生能力。 基本架构小程序的运行环境分为渲染层和逻辑层，其中 WXML 模板和 WXSS 样式工作在渲染层，JS 脚本工作在逻辑层。 其中渲染层的界面使用 WebView 线程进行渲染，逻辑层采用 jsCore 线程运行。一个小程序存在多个界面，所以渲染层存在多个 WebView 线程，这两个线程的通信会经由微信客户端（Native）做中转，逻辑层发送网络请求也经由 Native 转发。 三、小程序语法 WXML 语法参考 WXS 语法参考 四、小程序发布流程 在开发工具里，提交代码，填写版本信息 在小程序管理平台提交审核 收到审核通过通知后，在小程序管理平台，点击发布 小程序将会发布到线上提供服务，可以下载二维码让别人扫码使用了]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub疑似遭受中间人攻击]]></title>
    <url>%2F2020%2F03%2F27%2FGitHub%E7%96%91%E4%BC%BC%E9%81%AD%E5%8F%97%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[昨天下午4点多起，github pages 突然不能访问，今早，GitHub 官网也出现不能访问的情况。访问这些网站时，浏览器统一检测出证书无效。 现在是2020年3月27日北京时间13点，目前 github.com 和 pages.github.com 已经恢复访问。 这是昨天我在访问 github pages 页面的截图： 提示ERR_CERT_AUTHORITY_INVALID网站证书无效。并告诉我：您目前无法访问 pages.github.com，因为此网站使用了 HSTS。网络错误和攻击通常是暂时的，因此，此网页稍后可能会恢复正常。​ 而我在国外的朋友访问却没有问题，开始我还天真地以为是被墙了，后来晚上看到有朋友在朋友圈讨论此事，这才认真去看了下浏览器收到的网站证书： GitHub网站证书居然使用QQ邮箱？AYK？！显然，这不是被墙，这是被攻击了啊。这些网站的证书被攻击者使用的自签名证书代替，导致浏览器无法信任，从而阻止用户访问。这次攻击可能只针对中国IP的访问者，外网并未受到影响。 兴趣来了，这个留下qq邮箱的人是攻击者吗？ 可能是，也可能不是（这不是废话吗 - -!）。可能是攻击者自信放出自己的邮箱，也有可能是攻击者不小心暴露了自己的邮箱，但也有可能是攻击者放出的烟雾弹，这个qq号只是混淆视听的假线索。 Anyway，不管怎样，也不妨碍我们去简单人肉这个qq号的主人是谁。搜索qq号 346608453 ，这是一个网名为心即灵山的用户： 经查资料，这不是 GitHub 第一次遭受攻击，早在2015年，就受到过一次大规模的中间人攻击，github官方日志： 翻译：我们正在遭受github历史上最大的DDOS(分布式拒绝服务)攻击，攻击从3月26号，周四下午两点开始，攻击手段组合了多种攻击方式，从一些老式的攻击手段到新式，通过浏览器让毫不相干的围观群众参与到对github攻击流量的贡献，根据我们收到的报告推断，我们相信攻击的目的是让我们删除某些特定的内容。 关于中间人攻击，我在百度百科找到了还算通俗易懂的解释： 中间人攻击（Man-in-the-MiddleAttack，简称“MITM攻击”）是一种“间接”的入侵攻击，这种攻击模式是通过各种技术手段将受入侵者控制的一台计算机虚拟放置在网络连接中的两台通信计算机之间，这台计算机就称为“中间人”。这是一种由来已久的网络入侵手段，并且当今仍然有着广泛的发展空间，如SMB会话劫持、DNS欺骗等攻击都是典型的MITM攻击。简而言之，所谓的MITM攻击就是通过拦截正常的网络通信数据，并进行数据篡改和嗅探，而通信的双方却毫不知情。——百度百科 中间人攻击举例：假设爱丽丝（Alice）希望与鲍伯（Bob）通信。同时，马洛里（Mallory）希望拦截会话以进行窃听并可能在某些时候传送给鲍伯一个虚假的消息。 首先，爱丽丝会向鲍勃索取他的公钥。如果Bob将他的公钥发送给Alice，并且此时马洛里能够拦截到这个公钥，就可以实施中间人攻击。马洛里发送给爱丽丝一个伪造的消息，声称自己是鲍伯，并且附上了马洛里自己的公钥（而不是鲍伯的）。 爱丽丝收到公钥后相信这个公钥是鲍伯的，于是爱丽丝将她的消息用马洛里的公钥（爱丽丝以为是鲍伯的）加密，并将加密后的消息回给鲍伯。马洛里再次截获爱丽丝回给鲍伯的消息，并使用马洛里自己的私钥对消息进行解密，如果马洛里愿意，她也可以对消息进行修改，然后马洛里使用鲍伯原先发给爱丽丝的公钥对消息再次加密。当鲍伯收到新加密后的消息时，他会相信这是从爱丽丝那里发来的消息。 整个过程大致会是这样： 爱丽丝发送给鲍伯一条消息，却被马洛里截获：爱丽丝 “嗨，鲍勃，我是爱丽丝。给我你的公钥” –&gt;马洛里鲍勃 马洛里将这条截获的消息转送给鲍伯；此时鲍伯并无法分辨这条消息是否从真的爱丽丝那里发来的：爱丽丝马洛里 “嗨，鲍勃，我是爱丽丝。给我你的公钥” –&gt;鲍伯 鲍伯回应爱丽丝的消息，并附上了他的公钥：爱丽丝马洛里&lt;– [鲍伯的公钥] –鲍伯 马洛里用自己的公钥替换了消息中鲍伯的公钥，并将消息转发给爱丽丝，声称这是鲍伯的公钥：爱丽丝&lt;– [马洛里的公钥] –马洛里鲍勃 爱丽丝用她以为是鲍伯的公钥加密了她的消息，以为只有鲍伯才能读到它：爱丽丝 “我们在公共汽车站见面！” –[使用马洛里的公钥加密]–&gt;马洛里鲍勃 然而，由于这个消息实际上是用马洛里的公钥加密的，所以马洛里可以解密它，阅读它，并在愿意的时候修改它。他使用鲍伯的公钥重新加密，并将重新加密后的消息转发给鲍伯：爱丽丝马洛里 “在家等我！” –[使用鲍伯的公钥加密]–&gt;鲍伯 鲍勃认为，这条消息是经由安全的传输通道从爱丽丝那里传来的。 其实马洛里一直夹在它们会话的中间，进行拦截和转发，必要时对内容进行篡改，而爱丽丝和鲍勃均毫不知情。这就是中间人攻击。 这个例子很形象地说明了在网络安全上的一个关键：通信双方需要某种方法来确定他们是真正拿到了属于对方的公钥，而不是拿到来自攻击者的公钥。否则，这类攻击一般都是可行的，在原理上，可以针对任何使用公钥——密钥技术的通讯消息发起攻击。 幸运的是，有各种不同的技术可以帮助抵御 MITM 攻击，比如最文章最开始提到的 HSTS。目前大多数网站都开启了加密技术对抗劫持，因此遇到证书伪造的攻击，用户访问会被阻止，用户的损失止步于打开不了网页。 – 关于什么是HSTS，推荐大家看这篇文章：HSTS详解 更多关于中间人网络攻击的信息，有兴趣可以一读这篇：对github的中间人攻击]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>网络攻击</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发一个Vue插件]]></title>
    <url>%2F2020%2F03%2F05%2F%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAVue%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Vue 项目开发过程中​，经常用到插件，比如原生插件 vue-router、vuex，还有 element-ui 提供的 notify、message 等等。这些插件让我们的开发变得更简单更高效。那么 Vue 插件是怎么开发的呢​？​如何自己开发一个 Vue 插件然后打包发布到npm？ 本文涉及技术点： Vue 插件的本质 Vue.extend() 全局方法 如何手动挂载 Vue 实例 Vue.use() 的原理 如何打包成 umd 格式 发布前如何测试 npm 包 一、定义什么是Vue插件，它和Vue组件有什么区别​？​来看一下官网的解释： “插件通常用来为 Vue 添加全局功能。”“组件是可复用的 Vue 实例，且带有一个名字。”—— Vue.js 官网 Emmmm，似乎好像有种朦胧美。。。 我来尝试解释一下，其实， Vue 插件 和 Vue组件 只是在 Vue.js 中包装的两个概念而已​，不管是插件还是组件，最终目的都是为了实现逻辑复用。它们的本质都是对代码逻辑的封装，只是封装方式不同而已。在必要时，组件也可以封装成插件，插件也可以改写成组件，就看实际哪种封装更方便使用了。 除此之外，插件是全局的，组件可以全局注册也可以局部注册。 我们今天只聚焦 Vue 插件。 插件一般有下面几种： 添加全局方法或者属性。如: vue-custom-element 添加全局资源：指令/过滤器/过渡等。如 vue-touch 通过全局混入来添加一些组件选项。如 vue-router 添加 Vue 实例方法，通过把它们添加到 Vue.prototype 上实现。 一个库，提供自己的 API，同时提供上面提到的一个或多个功能。如 vue-router—— Vue.js 官网 二、插件的使用插件需要通过 Vue.use() 方法注册到全局，并且需要在调用 new Vue() 启动应用之前完成。之后在其他 Vue 实例里面就可以通过 this.$xxx 来调用插件中提供的 API 了。 下面以实现一个简易的提示框插件 toast 为例，给大家介绍怎么一步一步开发和发布一个 Vue 插件。 希望达到的效果：在 main.js 中 use：12345// src/main.jsimport Vue from 'vue'import toast from '@champyin/toast'Vue.use(toast) 在 App.vue 的生命周期 mounted 方法里调用 this.$toast()：1234567891011121314151617181920// src/App.vue&lt;template&gt; &lt;div&gt; &lt;button @click=&apos;handleClick&apos;&gt;Toast&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &apos;demo&apos;, methods: &#123; handleClick() &#123; this.$toast(&#123; type: &apos;success&apos;, msg: &apos;成功&apos;, duration: 3 &#125;) &#125; &#125;&#125;&lt;/script&gt; 运行后在页面上点击按钮，弹出 成功 的提示，然后3秒后消失。 在线地址：http://champyin.com/toast/ 三、插件开发1. 编写 toast 的本体。在 Vue 项目（你可以使用 Vue-cli 快速生成一个 Vue 项目，也可以自己用 webpack 搭建一个）的 src 目录下创建 components/Toast/index.vue 文件。12345678910111213141516171819202122232425262728293031323334353637// src/components/Toast/index.vue&lt;template&gt; &lt;transition name='fade'&gt; &lt;div class='uco-toast' v-if='isShow'&gt; &lt;span :class='iconStyle'&gt;&lt;/span&gt; &lt;span&gt;&#123;&#123;msg&#125;&#125;&lt;/span&gt; &lt;/div&gt; &lt;/transition&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data() &#123; return &#123; isShow: false, type: 'success', msg: '成功', duration: 1, &#125;; &#125;, computed: &#123; iconStyle() &#123; return `tfont icon-$&#123;this.type&#125; toast-icon`; &#125;, &#125;, mounted() &#123; this.isShow = true; setTimeout(() =&gt; &#123; this.isShow = false; &#125;, this.duration * 1000); &#125;,&#125;;&lt;/script&gt;&lt;style lang='less' scoped&gt;// 样式略&lt;/style&gt; 现在 toast 本体完成了，但是它里面的数据目前没法改变，因为我没有给它定义 props 属性。这不是 bug，而是，插件并不是通过 pops 来传值的。 2. 手动挂载 toast 实例的 dom为了给插件传值，可以利用基础 Vue 构造器 Vue.extend() 创建一个“子类”。这个子类相当于一个继承了 Vue 的 Toast 构造器。然后在 new 这个构造函数的时候，给 Toast 的 data 属性传值，然后手动调用这个实例的 $mount() 方法手动挂载，最后使用原生JS的 appendChild 将真实 DOM （通过实例上的 $el 属性获取）添加到 body 上。 在 src 目录下新建 components/Toast/index.js 文件：12345678910111213141516171819202122// src/components/Toast/index.jsimport Vue from 'vue';import Toast from './index.vue';// 使用 Vue.extend() 创建 Toast 的构造器const ToastConstructor = Vue.extend(Toast);const toast = function(options = &#123;&#125;) &#123; // 创建 Toast 实例，通过构造函数传参， // 并调用 Vue 实例上的 $mount() 手动挂载 const toastInstance = new ToastConstructor(&#123; data: options &#125;).$mount(); // 手动把真实 dom 挂到 html 的 body 上 document.body.appendChild(toastInstance.$el); return toastInstance;&#125;;// 导出包装好的 toast 方法export default toast; 3. 暴露 install 方法给 Vue.use() 使用。 为了支持 Vue.use()，Vue.js 的插件应该暴露一个 install 方法。这个方法的第一个参数是 Vue 构造器，第二个参数是一个可选的选项对象。—— Vue.js 官网 通过 Vue.js 源码也可以看出，Vue.use() 方法所做的事情就是调用插件或者组件的 install 方法，然后把全局 Vue 传进去供插件和组件使用。123456789101112131415161718192021222324// https://github.com/vuejs/vue/blob/dev/src/core/global-api/use.js/* @flow */import &#123; toArray &#125; from '../util/index'export function initUse (Vue: GlobalAPI) &#123; Vue.use = function (plugin: Function | Object) &#123; const installedPlugins = (this._installedPlugins || (this._installedPlugins = [])) if (installedPlugins.indexOf(plugin) &gt; -1) &#123; return this &#125; // additional parameters const args = toArray(arguments, 1) args.unshift(this) if (typeof plugin.install === 'function') &#123; plugin.install.apply(plugin, args) &#125; else if (typeof plugin === 'function') &#123; plugin.apply(null, args) &#125; installedPlugins.push(plugin) return this &#125;&#125; 在 src 目录下新建 components/index.js 文件，定义一个 install 方法，在里面将 toast 实例放到 Vue.prototype 上作为 Vue 实例的方法暴露到全局。1234567891011121314151617// src/components/index.jsimport toast from './Toast/index';import '../icon/iconfont.css';// 准备好 install 方法 给 Vue.use() 使用export function install(Vue) &#123; if (install.installed) return; install.installed = true; // 将包装好的 toast 挂到Vue的原型上，作为 Vue 实例上的方法 Vue.prototype.$toast = toast;&#125;// 默认导出 installexport default &#123; install,&#125;; 现在插件就开发完成了，可以在当前项目中本地引用这个插件了。12345678//在 main.js 中import toast from src/components/index.js;Vue.use(toast);//在 App.vue 中handleClick()&#123; this.$toast();&#125; 四、发布到npm为了方便其他人也可以使用到这个插件，我们可以把它发布到 npm 上去。发布的步骤很简单，但是发布之前，需要有一些小配置和一些注意的地方。 1. 打包配置首先我们要把它打包成可以给浏览器解析的 UMD 格式的的模块，并且去掉对 Vue.js 的打包，这样别人在 Vue 项目中使用这个插件的时候就不会有两份 Vue 或者出现 Vue 版本冲突的问题，以保证可以更好被独立引用。 如果你是用 Vue-cli 生成的项目，那只需要在你的 npm 脚本中配置一下库的打包命令：12// package.json"build:lib": "vue-cli-service build --target lib --name toast --dest lib src/components/index.js" 命令说明：12345678910111213141516--target：构建的目标 targetType 有三个选项：lib | wc | wc-async lib：库 wc：web component wc-async：异步的 web component--name：库或组件的名字 当入口为单一文件时，name为库或组件的文件名 当入口为global表达式时，name为每个库或组件文件名字的前缀[entry]：打包入口 可以是.vue文件，也可以是.js文件 当注册多个web component时，入口可以是一个global表达式，如 components/*.vue--dest：输出目录 默认为dist目录，也可以修改为自定义的目录 然后运行 npm run build:lib，即可在 lib 目录下生成如下文件：123toast.umd.js 一个直接给浏览器或者AMD loader 使用的 UMD 包toast.umd.min.js 一个压缩版 UMD 构建版本toast.common.js 一个给打包器用的CommonJS包 如果你是用 webpack 搭建的 Vue 项目，那就需要在 webpck 中配置一下 output.libraryTarget 等属性：12345678910111213141516171819202122232425262728// build/webpack.lib.conf.jsconst path = require('path');const &#123; CleanWebpackPlugin &#125; = require('clean-webpack-plugin');module.exports = &#123; mode: 'production', entry: './src/components/index.js', output: &#123; path: path.resolve(__dirname, '../lib'), filename: 'toast.js', library: 'toast', libraryTarget: 'umd', libraryExport: 'default', umdNamedDefine: true, globalObject: 'typeof self !== \'undefined\' ? self : this', &#125;, externals: &#123; vue: &#123; root: 'Vue', commonjs: 'vue', commonjs2: 'vue', amd: 'vue', &#125;, &#125;, plugins: [ new CleanWebpackPlugin(), ],&#125;; 然后运行 npm run build:lib，即可在 lib 目录下生成如下文件：1toast.js 直接给浏览器或者AMD loader 使用的 UMD 包 2. 发布前的测试发布前，我们需要配置一下 package.json 里的 name 和 main 字段：name 的值是最终包的名字，install 和 import 的就是这个名字（请确保全网唯一）。main 的值是包的入口文件路径（相对当前文件的路径），一定要填写正确，否则包无法被引用。12"name": "@champyin/toast","main": "lib/toast.js", 为了确保包的配置没有问题，我们可以利用 npm link 命令在本地测试一下包的使用情况。使用npm link测试包的使用估计很多人都会，就不赘述了。如果有需要可以看我的另一篇中文章npm link详解。 这个时候，我们其实就可以发布了，但是为了防止把不必要的文件发布出去（比如测试用例和demo）浪费人家下载的流量，我们最好是建一个 .npmigore 文件，语法跟 .gitignore 相同。 3. 发布发布的方法很简单(不过首先你要有个 npm 账号)，在 package.json 所在的目录下执行这两句就可以了：12npm add usernpm publish 关于更详细的发布教程，我在另一篇文章有专门细说：如何发布一个npm模块。 4. 安装测试其实到了这一步一99.99%是不会出错了，安装一遍只是为了那 0.01% 的万一。 在另一个 Vue 项目里（注意不能在开发toast的项目里哈），从 npm 安装自己刚才发布的包：1npm i -D @champyin/toast 然后在项目中使用一下自己的插件，点击按钮就会弹出 toast 小提示了。12345678//在 main.js 中import toast from '@champyin/toast';Vue.use(toast);//在 App.vue 中handleClick()&#123; this.$toast();&#125; 项目体验地址：http://champyin.com/toast/npm 地址：https://www.npmjs.com/package/@champyin/toast欢迎给我提 issue：https://github.com/yc111/toast/issues Happy coding :) 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。 更多参考：https://cn.vuejs.org/v2/guide/plugins.htmlhttps://cn.vuejs.org/v2/api/#Vue-extend-optionshttps://cli.vuejs.org/zh/guide/build-targets.htmlhttps://webpack.js.org/guides/author-libraries/https://docs.npmjs.com/cli-commands/link.htmlhttps://docs.npmjs.com/cli-commands/pack.htmlhttps://www.npmjs.com/package/@champyin/toast]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[踩坑img src="[object Module]"]]></title>
    <url>%2F2020%2F03%2F03%2F%E8%B8%A9%E5%9D%91img-src-object-Module%2F</url>
    <content type="text"><![CDATA[为了快速测试自己开发的某个插件功能，我通常都是用webpack快速搭建一个vue项目，这样可以保证没有其他未知因素地干扰。这次也同往常一样顺利，直到，我的插件需要内置一张图片。。。 问题图片没有出来，查看控制台，img标签的src属性变成了&quot;[object Module]&quot;。图片并没有按照预期编译返回url字符串，而是一个模块对象。 分析我就奇怪了，以前都是这么配置的，从没出过问题。 冷静思考，其实有一点不一样，那就是新安装的依赖插件版本可能比以前的高。而且既然是图片打包的问题，那就优先排查图片处理插件。 一番操作猛如虎，果然！就是新版本惹的祸！ file-loader 从 5.0 版本开始，将默认输出改成了 esModule 模块！ url-loader 从 3.0 版本开始，将默认输出改成了 esModule 模块！ 解决接下来我手动添加了配置 esModule: false（改成输出commonJS模块）。123456789101112&#123; test: /\.(png|jpe?g|gif|bmp)$/, use: [ &#123; loader: 'url-loader', options:&#123; limit: 1024 * 8, + esModule: false &#125; &#125; ]&#125; 问题解决！ 总结遇到打包错误不要慌乱，不要回避问题。用单一变量法进行排除，以及逻辑判断大致定位问题，然后查看插件版本的 BREAKING CHANGES 记录，基本可以找到答案。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>vue</tag>
        <tag>url-loader</tag>
        <tag>file-loader</tag>
        <tag>img</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git之 git stash]]></title>
    <url>%2F2020%2F02%2F25%2FGit%E4%B9%8B-git-stash%2F</url>
    <content type="text"><![CDATA[我有时会遇到这样的情况：正在 dev 分支上开发某个项目，这时有人反馈了一个 bug，需要紧急修复，但是正在开发的内容又不想现在提交，因为只完成了一半（强迫症不想增加一个脏的提交，然后惦记着日后做 rebase，麻烦）。或者是很嗨地开发完了一个功能，快要提交的时候才发现当前所在分支竟然是 master，而这本应是在 dev 分支开发的内容（两条分支并不同步，可能因冲突而不能直接切换分支）。 这些时候，我 prefer 使用 git stash（git存储）来快速处理。 一、git stash 的作用 git stash 可以获取你工作目录的中间状态，并将它保存到一个未完结变更的本地堆栈中，让当前工作区变干净。 stash 中的内容随时可以重新应用，而且不仅可以恢复到原先开发的分支，还可以应用到其他任意指定的分支上。 所以你就可以在 git stash 后，顺利地切换到另一个分支去修改 bug，修改完提交后，再切回 dev 分支。然后使用 git stash pop 来恢复之前的进度继续开发新功能。也可以在 git stash 后，从 master 切换到 dev 分支，然后使用 git stash pop 把在 master 上 stash 的内容恢复到 dev 上，然后在 dev 分支上提交。 二、git stash 的作用范围git stash 默认会存储以下文件： unstaged changes：未添加到暂存区的 git track 文件（曾经 add 过，然后修改了） staged changes：添加到暂存区的文件（add 了但还没 commit） 默认不会存储以下文件： untracked files：在工作目录中的新文件（从未 add 过） ignored files：被忽略的文件（符合 .gitigore 文件里的规则的文件） 总结起来，也就是默认只针对你修改过的被追踪的文件和暂存的变更，其他的不管。 三、stash 存到哪里去了git 会在 .git/refs/ 目录下建立一个 stash 文件，存放最后一个 stash 的节点指针。然后在 .git/logs/refs/ 目录下建立一个 stash 文件，存放所有的 stash 记录（每条记录包括下一个节点指针、当前节点指针、作者、邮箱、hash、stash message 六个字段 ）。 四、git stash 的用法stash 当前修改1git stash 这个命令把当前工作区所有未提交的修改（不包括untrack 和 ignore 的）都保存起来，同时会给每次 stash 添加默认的 message（来自于最后一次commit的message），所以如果你在未commit的期间进行了多次stash，会产生看上去一样的stash记录（其实不一样），因为message完全相同。 所以，一般我会使用git stash save命令取代git stash，给每次stash填写一个message作为标识。1git stash save &lt;message&gt; 查看 stash1git stash list 输出如下：1234$ git stash liststash@&#123;0&#125;: On feature/fix: conflict2 # 自己添加的 messagestash@&#123;1&#125;: On feature/fix: change c stash@&#123;2&#125;: WIP on feature/fix: 6488467 update # 未加message的stash，获取的最后一次提交日志 重新应用缓存的 stash1git stash pop 输出如下：12345678910$ git stash popOn branch feature/fixChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)Dropped refs/stash@&#123;0&#125; (aed4ca7d79520beebd22af25bc2b21964fa3a0f2) 这个指令将缓存栈中的第一个stash中对应的修改应用到当前的工作目录下，并将这个stash删除。 你也可以指定 stash list 中的任意一个 stash 来恢复：12git stash pop stash@&#123;num&#125;git stash pop stash@&#123;2&#125; # 恢复 stash list 中的第三个到当前工作目录 你也可以只应用某个 stash，而不自动删除它，在需要多次应用某个 stash 的时候适用。1git stash apply stash@&#123;num&#125; 移除 stash1git stash drop stash@&#123;num&#125; 删除掉某个 stash 缓存。git stash pop 其实就相当于 git stash apply stash@{0} + git stash drop stash@{0} 你也可以一次删除所有的 stash 缓存：1git stash clear 查看指定 stash 的 diff1git stash show 查看 stash 中第一个缓存与当前目录的修改数量。也可以指定stash的名字。例如：123$ git stash show stash@&#123;0&#125; readme.txt | 1 + 1 file changed, 1 insertion(+) 也可以在命令后添加 -p 或者 -patch 查看具体的修改diff。输出结果如下：12345678910$ git stash show stash@&#123;0&#125; -pdiff --git a/readme.txt b/readme.txtindex 1fd5ae1..08106f6 100644--- a/readme.txt+++ b/readme.txt@@ -4,3 +4,4 @@ test dev add feature +change c 冲突的处理从 stash 里应用缓存的时候，可能会跟当前工作目录上的内容有冲突。1234567891011$ git stash apply stash@&#123;0&#125;Auto-merging readme.txtCONFLICT (content): Merge conflict in readme.txt$ git statusOn branch feature/fixUnmerged paths: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) (use &quot;git add &lt;file&gt;...&quot; to mark resolution) both modified: readme.txt 这个时候，stash 会在自动合并文件内容后，标出冲突所在。12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstreamchange b=======&gt;&gt;&gt;&gt;&gt;&gt;&gt; Stashed changeschange c Git用 &lt;&lt;&lt;&lt;&lt;&lt;&lt;、=======、&gt;&gt;&gt;&gt;&gt;&gt;&gt; 标记出冲突中不同来源的内容。其中：&lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream 指当前工作区的内容。======= 是分割线。&gt;&gt;&gt;&gt;&gt;&gt;&gt; Stashed changes 指 stash 缓存的修改内容。 只需跟解决其他冲突一样，处理完冲突（选择保留哪段代码或者都不要重新写）之后，add 和 commit 这个文件即可。 从 stash 创建分支有时候，在当前分支对某次 idea 进行了 stash 之后，又在这个分支做了大量 commit、pull、merge 等操作，再想进行 stash pop 已经很明显会造成冲突，但是你不想处理冲突又很想继续之前的进度完成自己的 idea，有个更方便的方法让你无冲突地恢复你储藏的变更：1git stash branch &lt;new-branch-name&gt; 它会创建一个新的分支，检出你在stash时所处的提交，重新应用你的工作，如果成功，将会丢弃储藏。 暂存未跟踪或忽略的文件刚才有提到，git stash 的默认作用范围不包括未跟踪和忽略的文件，其实你也可以强行暂存他们：12git stash -u #（或者 --include-untracked）stash untracked 文件 git stash -a #（或者 --a）stash 当前目录下的所有修改 总结工具千千万，使用工具的方法千千万，条条大路通罗马，如果没有git stash命令，我们确实照样可以使用 git 做日常代码管理（只是有时不那么便利罢了），但是如果有这么一个高效工具却不去使用那就是给自己添堵了。 最后我想说：I love git！ –git官方文档]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>stash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx安装（linux环境）]]></title>
    <url>%2F2020%2F02%2F21%2Fnginx%E5%AE%89%E8%A3%85%EF%BC%88linux%E7%8E%AF%E5%A2%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Nginx 是一款高性能的 Web 和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。它的开发者是俄罗斯工程师：Igor Sysoev。这篇是针对 Linux 操作系统的安装。 在 linux 下安装 nginx 有两种方式：一种是源码编译，一种是yum安装。 一、通过源码编译方式的安装步骤step1: wget下载nginx源码1wget https://nginx.org/download/nginx-1.17.1.tar.gz step2: tar命令解压1tar zxvf nginx-1.17.1.tar.gz step3: 安装gcc编译工具1yum install gcc gcc-c++ step4: 安装其他库跟工具1yum install pure pure-devel openssl openssl-devel zlib zlib-devel step5: 编译源码并安装12cd nginx-1.17.1make &amp;&amp; make install step6: 启动niginx1/usr/local/nginx/sbin/nginx Done！ 但是，我觉得步骤实在太繁琐，个人不喜欢这种方式。 二、通过 yum 安装的步骤 （推荐）这也是官方推荐的安装方式nginx官网文档 step1: 进入 yum repos 配置目录1cd /etc/yum.repos.d step2: 配置 nginx.repo从官网提供的稳定版和最新版的repo信息(如下)复制一下123456789101112131415[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true 然后在ssh终端配置 nginx.repo12vi nginx.repo # 新建 nginx.repo 文件，将官网提供的稳定版和最新版的repo信息粘贴进去:wq # 保存并退出 vi step3: 安装1yum install nginx -y step4: 启动nginx1nginx Done！ 在浏览器输入服务器公网ip，回车，即可看到 nginx 欢迎文字，nginx安装启动成功！ 三、其他命令查看ngix安装路径1whereis nginx 测试nginx1nginx -t 修改nginx.conf配置后，重载nginx1nginx -s reload 文章同时发表于公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘webpack loader]]></title>
    <url>%2F2020%2F01%2F28%2F%E6%8F%AD%E7%A7%98webpack-loader%2F</url>
    <content type="text"><![CDATA[Loader(加载器) 是 webpack 的核心之一。它用于将不同类型的文件转换为 webpack 可识别的模块。本文将尝试深入探索 webpack 中的 loader，揭秘它的工作原理，以及如何开发一个 loader。 一、Loader 工作原理webpack 只能直接处理 javascript 格式的代码。任何非 js 文件都必须被预先处理转换为 js 代码，才可以参与打包。loader（加载器）就是这样一个代码转换器。它由 webpack 的 loader runner 执行调用，接收原始资源数据作为参数（当多个加载器联合使用时，上一个loader的结果会传入下一个loader），最终输出 javascript 代码（和可选的 source map）给 webpack 做进一步编译。 二、 Loader 执行顺序1. 分类 pre： 前置loader normal： 普通loader inline： 内联loader post： 后置loader 2. 执行优先级 4类 loader 的执行优级为：pre &gt; normal &gt; inline &gt; post 。 相同优先级的 loader 执行顺序为：从右到左，从下到上。 3. 前缀的作用内联 loader 可以通过添加不同前缀，跳过其他类型 loader。 ! 跳过 normal loader。 -! 跳过 pre 和 normal loader。 !! 跳过 pre、 normal 和 post loader。 这些前缀在很多场景下非常有用。 三、如何开发一个loaderloader 是一个导出一个函数的 node 模块。 1. 最简单的 loader当只有一个 loader 应用于资源文件时，它接收源码作为参数，输出转换后的 js 代码。123456// loaders/simple-loader.jsmodule.exports = function loader (source) &#123; console.log('simple-loader is working'); return source;&#125; 这就是一个最简单的 loader 了，这个 loader 啥也没干，就是接收源码，然后原样返回，为了证明这个loader被调用了，我在里面打印了一句话‘simple-loader is working’。 测试这个 loader：需要先配置 loader 路径若是使用 npm 安装的第三方 loader，直接写 loader 的名字就可以了。但是现在用的是自己开发的本地 loader，需要我们手动配置路径，告诉 webpack 这些 loader 在哪里。12345678910111213141516// webpack.config.jsconst path = require('path');module.exports = &#123; entry: &#123;...&#125;, output: &#123;...&#125;, module: &#123; rules: [ &#123; test: /\.js$/, // 直接指明 loader 的绝对路径 use: path.resolve(__dirname, 'loaders/simple-loader') &#125; ] &#125;&#125; 如果觉得这样配置本地 loader 并不优雅，可以在 webpack配置本地loader的四种方法 中挑一个你喜欢的。 执行webpack编译可以看到，控制台输出 ‘simple-loader is working’。说明 loader 成功被调用。 2. 带 pitch 的 loaderpitch 是 loader 上的一个方法，它的作用是阻断 loader 链。 123456789101112// loaders/simple-loader-with-pitch.jsmodule.exports = function (source) &#123; console.log('normal excution'); return source;&#125;// loader上的pitch方法，非必须module.exports.pitch = function() &#123; console.log('pitching graph'); // todo&#125; pitch 方法不是必须的。如果有 pitch，loader 的执行则会分为两个阶段：pitch 阶段 和 normal execution 阶段。webpack 会先从左到右执行 loader 链中的每个 loader 上的 pitch 方法（如果有），然后再从右到左执行 loader 链中的每个 loader 上的普通 loader 方法。 假如配置了如下 loader 链：1use: ['loader1', 'loader2', 'loader3'] 真实的 loader 执行过程是： 在这个过程中如果任何 pitch 有返回值，则 loader 链被阻断。webpack 会跳过后面所有的的 pitch 和 loader，直接进入上一个 loader 的 normal execution。 假设在 loader2 的 pitch 中返回了一个字符串，此时 loader 链发生阻断： 3. 写一个简版的 style-loaderstyle-loader 通常不会独自使用，而是跟 css-loader 连用。css-loader 的返回值是一个 js 模块，大致长这样：123456789// 打印 css-loader 的返回值// Importsvar ___CSS_LOADER_API_IMPORT___ = require("../node_modules/css-loader/dist/runtime/api.js");exports = ___CSS_LOADER_API_IMPORT___(false);// Moduleexports.push([module.id, "\nbody &#123;\n background: yellow;\n&#125;\n", ""]);// Exportsmodule.exports = exports; 这个模块在运行时上下文中执行后返回 css 代码 &quot;\nbody {\n background: yellow;\n}\n&quot;。 style-loader 的作用就是将这段 css 代码转成 style 标签插入到 html 的 head 中。 设计思路 style-loader 最终需返回一个 js 脚本：在脚本中创建一个 style 标签，将 css 代码赋给 style 标签，再将这个 style 标签插入 html 的 head 中。 难点是获取 css 代码，因为 css-loader 的返回值只能在运行时的上下文中执行，而执行 loader 是在编译阶段。换句话说，css-loader 的返回值在 style-loader 里派不上用场。 曲线救国方案：使用获取 css 代码的表达式，在运行时再获取 css (类似 require(&#39;css-loader!index.css&#39;)）。 在处理 css 的 loader 中又去调用 inline loader require css 文件，会产生循环执行 loader 的问题，所以我们需要利用 pitch 方法，让 style-loader 在 pitch 阶段返回脚本，跳过剩下的 loader，同时还需要内联前缀 !! 的加持。 注：pitch 方法有3个参数： remainingRequest：loader链中排在自己后面的 loader 以及资源文件的绝对路径以!作为连接符组成的字符串。 precedingRequest：loader链中排在自己前面的 loader 的绝对路径以!作为连接符组成的字符串。 data：每个 loader 中存放在上下文中的固定字段，可用于 pitch 给 loader 传递数据。 可以利用 remainingRequest 参数获取 loader 链的剩余部分。 实现12345678910111213141516171819202122232425262728// loaders/simple-style-loader.jsconst loaderUtils = require('loader-utils');module.exports = function(source) &#123; // do nothing&#125;module.exports.pitch = function(remainingRequest) &#123; console.log('simple-style-loader is working'); // 在 pitch 阶段返回脚本 return ( ` // 创建 style 标签 let style = document.createElement('style'); /** * 利用 remainingRequest 参数获取 loader 链的剩余部分 * 利用 ‘!!’ 前缀跳过其他 loader * 利用 loaderUtils 的 stringifyRequest 方法将模块的绝对路径转为相对路径 * 将获取 css 的 require 表达式赋给 style 标签 */ style.innerHTML = require($&#123;loaderUtils.stringifyRequest(this, '!!' + remainingRequest)&#125;); // 将 style 标签插入 head document.head.appendChild(style); ` )&#125; 一个简易的 style-loader 就完成了。 试用webpack 配置 123456789101112131415161718192021222324252627// webpack.config.jsconst path = require('path');const HtmlWebpackPlugin = require('html-webpack-plugin');module.exports = &#123; entry: &#123;...&#125;, output: &#123;...&#125;, // 手动配置 loader 路径 resolveLoader: &#123; modules: [path.resolve(__dirname, 'loaders'), 'node_modules'] &#125;, module: &#123; rules: [ &#123; // 配置处理 css 的 loader test: /\.css$/, use: ['simple-style-loader', 'css-loader'] &#125; ] &#125;, plugins: [ // 渲染首页 new HtmlWebpackPlugin(&#123; template: './src/index.html' &#125;) ]&#125; 在 index.js 中引入一个 css 样式文件 1234// src/index.jsrequire('./index.css');console.log('Brovo!'); 样式文件中将 body 的背景色设置为黄色 12345/* src/index.css */body &#123; background-color: yellow;&#125; 执行webpack 1npm run build 可以看到命令行控制台打印了 ‘simple-style-loader is working’，说明 webpack 成功调用了我们编写的 loader。 在浏览器打开 dist 下的 index.html 页面，可以看到样式生效，而且成功插入到了页面头部！ 说明我们编写的 loader 发挥作用了。 成功！ 三、一些 tips推荐2个工具包开发 loader 必备： 1. loader-utils这个模块中常用的几个方法： getOptions 获取 loader 的配置项。 interpolateName 处理生成文件的名字。 stringifyRequest 把绝对路径处理成相对根目录的相对路径。 2. schema-utils这个模块可以帮你验证 loader option 配置的合法性。用法：1234567891011121314151617181920// loaders/simple-loader-with-validate.jsconst loaderUtils = require('loader-utils');const validate = require('schema-utils');module.exports = function(source) &#123; // 获取 loader 配置项 let options = loaderUtils.getOptions(this) || &#123;&#125;; // 定义配置项结构和类型 let schema = &#123; type: 'object', properties: &#123; name: &#123; type: 'string' &#125; &#125; &#125; // 验证配置项是否符合要求 validate(schema, options); return source;&#125; 当配置项不符合要求，编译就会中断并在控制台打印错误信息： 开发异步 loader异步 loader 的开发（例如里面有一些需要读取文件的操作的时候），需要通过 this.async() 获取异步回调，然后手动调用它。用法：1234567891011// loaders/simple-async-loader.jsmodule.exports = function(source) &#123; console.log('async loader'); let cb = this.async(); setTimeout(() =&gt; &#123; console.log('ok'); // 在异步回调中手动调用 cb 返回处理结果 cb(null, source); &#125;, 3000);&#125; 注： 异步回调 cb() 的第一个参数是 error，要返回的结果放在第二个参数。 raw loader如果是处理图片、字体等资源的 loader，需要将 loader 上的 raw 属性设置为 true，让 loader 支持二进制格式资源（webpack默认是以 utf-8 的格式读取文件内容给 loader）。用法：12345678910111213// loaders/simple-raw-loader.jsmodule.exports = function(source) &#123; // 将输出 buffer 类型的二进制数据 console.log(source); // todo handle source let result = 'results of processing source' return ` module.exports = '$&#123;result&#125;' `;&#125;// 告诉 wepack 这个 loader 需要接收的是二进制格式的数据module.exports.raw = true; 注：通常 raw 属性会在有文件输出需求的 loader 中使用。 输出文件在开发一些处理资源文件（比如图片、字体等）的 loader 中，需要拷贝或者生成新的文件，可以使用内部的 this.emitFile() 方法.用法：123456789101112131415// loaders/simple-file-loader.jsconst loaderUtils = require('loader-utils');module.exports = function(source) &#123; // 获取 loader 的配置项 let options = loaderUtils.getOptions(this) || &#123;&#125;; // 获取用户设置的文件名或者制作新的文件名 // 注意第三个参数，是计算 contenthash 的依据 let url = loaderUtils.interpolateName(this, options.filename || '[contenthash].[ext]', &#123;content: source&#125;); // 输出文件 this.emitFile(url, source); // 返回导出文件地址的模块脚本 return `module.exports = '$&#123;JSON.stringify(url)&#125;'`;&#125;module.exports.raw = true; 在这个例子中，loader 读取图片内容（buffer），将其重命名，然后调用 this.emitFile() 输出到指定目录，最后返回一个模块，这个模块导出重命名后的图片地址。于是当 require 图片的时候，就相当于 require 了一个模块，从而得到最终的图片路径。（这就是 file-loader 的基本原理） 开发约定为了让我们的 loader 具有更高的质量和复用性，记得保持简单。也就是尽量保持让一个 loader 专注一件事情，如果发现你写的 loader 比较庞大，可以试着将其拆成几个 loader 。 在 webpack 社区，有一份 loader 开发准则，我们可以去参考它来指导我们的 loader 设计： 保持简单。 利用多个loader链。 模块化输出。 确保loader是无状态的。 使用 loader-utils 包。 标记加载程序依赖项。 解析模块依赖关系。 提取公共代码。 避免绝对路径。 使用 peerDependency 对等依赖项。 四、总结 loader 的本质是一个 node 模块，这个模块导出一个函数，这个函数上可能还有一个 pitch 方法。 了解了 loader 的本质和 loader 链的执行机制，其实就已经具备了 loader 开发基础了。 开发 loader 不难上手，但是要开发一款高质量的 loader，仍需不断实践。 尝试自己开发维护一个小 loader 吧～ 没准以后可以通过自己编写 loader 来解决项目中的一些实际问题。 文章源码获取：https://github.com/yc111/webpack-loader 欢迎交流～ Happy New Year！ – 参考https://webpack.js.org/concepts/#loadershttps://webpack.js.org/api/loaders/https://webpack.js.org/contribute/writing-a-loader/https://github.com/webpack/webpack/blob/v4.41.5/lib/NormalModuleFactory.jshttps://github.com/webpack-contrib/style-loader/blob/master/src/index.jshttps://www.npmjs.com/package/loader-utilshttps://www.npmjs.com/package/schema-utils]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《新型冠状病毒肺炎预防手册》电子书]]></title>
    <url>%2F2020%2F01%2F27%2F%E3%80%8A%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%E8%82%BA%E7%82%8E%E9%A2%84%E9%98%B2%E6%89%8B%E5%86%8C%E3%80%8B%E7%94%B5%E5%AD%90%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[没想到这次爆发的肺炎疫情这么严重。 这个是从湘雅医学院老师那获取的 新型冠状病毒肺炎预防手册 普及扩散之。 电子书预览： 若无法预览可以直接到github下载pdf：https://github.com/yc111/ebooks/tree/master/medical-science 另附小贴士：出门回家后，身上可能沾染病毒？应该如何消毒更安全更合理？123456789101112131415161718192021222324252627282930311.头发感染率低，防护策略：日常清洁。2.皮肤感染率低（新冠病毒不能透过皮肤侵入人体），但是手沾病毒概率极大，防护策略：正确洗手勤洗手，不摸脸，不揉眼。3.眼膜感染率高，防护策略：手部消毒前不揉眼，必要时带上护目镜。4.手机是高频接触物品，防护策略：关闭电源，等手机冷却，沾取75%酒精擦拭。5.口罩重要防护，防护策略：不建议重复使用，摘取口罩不要触碰外表面，此处已污染。6.衣服感染率低，防护措施：没去过特定场所不需要对衣服进行专门消毒，注意：喷洒酒精在衣物上，遇到明火、高温或静电可能起火。7.购物袋防护措施：必要时，用75%酒精喷洒表面。8.鞋底感染率低，防护措施： 保持清洁，门口换鞋。9.出租车防护措施：关闭车内空调，开窗通风，全程佩戴口罩，减少交流。10.其他流水洗菜，不吃生食，菜品烧熟、煮透，水果削皮。 为什么外面没有人也要戴口罩 耳戴式口罩佩戴方法 医院标准七步洗手法: 内、外、夹、弓、大、指、腕 友情链接：实时疫情地图-丁香园最新疫情地图及动态2019新型冠状病毒-百度百科新型冠状病毒肺炎-百科医典]]></content>
      <categories>
        <category>电子书</category>
      </categories>
      <tags>
        <tag>ebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘webpack plugin]]></title>
    <url>%2F2020%2F01%2F12%2F%E6%8F%AD%E7%A7%98webpack-plugin%2F</url>
    <content type="text"><![CDATA[Plugin(插件) 是 webpack 生态的的一个关键部分。它为社区提供了一种强大的方法来扩展 webpack 和开发 webpack 的编译过程。本文将尝试探索 webpack plugin，揭秘它的工作原理，以及如何开发一个 plugin。 一、Plugin 的作用关于 Plugin 的作用，引用一下 webpack 官方的介绍： Plugins expose the full potential of the webpack engine to third-party developers. Using staged build callbacks, developers can introduce their own behaviors into the webpack build process. 我把它通俗翻译了下：我们可以通过插件，扩展 webpack，加入自定义的构建行为，使 webpack 可以执行更广泛的任务，拥有更强的构建能力。 二、Plugin 工作原理 webpack 就像一条生产线，要经过一系列处理流程后才能将源文件转换成输出结果。 这条生产线上的每个处理流程的职责都是单一的，多个流程之间有存在依赖关系，只有完成当前处理后才能交给下一个流程去处理。 插件就像是一个插入到生产线中的一个功能，在特定的时机对生产线上的资源做处理。webpack 通过 Tapable 来组织这条复杂的生产线。 webpack 在运行过程中会广播事件，插件只需要监听它所关心的事件，就能加入到这条生产线中，去改变生产线的运作。 webpack 的事件流机制保证了插件的有序性，使得整个系统扩展性很好。——「深入浅出 Webpack」 站在代码逻辑的角度就是：webpack 在编译过代码程中，会触发一系列 Tapable 钩子事件，插件所做的，就是找到相应的钩子，往上面挂上自己的任务，也就是注册事件，这样，当 webpack 构建的时候，插件注册的事件就会随着钩子的触发而执行了。 三、webpack 的一些底层逻辑开发一个 plugin 比开发一个 loader 更高级一些（关于 loader 的开发，可以看我的另一篇文章「揭秘webpack loader」），因为我们会用到一些 webpack 比较底层的内部组件。因此我们需要了解一些 webpack 的底层逻辑。 webpack 内部执行流程一次完整的 webpack 打包大致是这样的过程： 将命令行参数与 webpack 配置文件 合并、解析得到参数对象。 参数对象传给 webpack 执行得到 Compiler 对象。 执行 Compiler 的 run方法开始编译。每次执行 run 编译都会生成一个 Compilation 对象。 触发 Compiler 的 make方法分析入口文件，调用 compilation 的 buildModule 方法创建主模块对象。 生成入口文件 AST(抽象语法树)，通过 AST 分析和递归加载依赖模块。 所有模块分析完成后，执行 compilation 的 seal 方法对每个 chunk 进行整理、优化、封装。 最后执行 Compiler 的 emitAssets 方法把生成的文件输出到 output 的目录中。 webpack 底层基本流程图 webpack 内部的一些钩子什么是钩子钩子的本质就是：事件。为了方便我们直接介入和控制编译过程，webpack 把编译过程中触发的各类关键事件封装成事件接口暴露了出来，这些接口被很形象地称做：hooks（钩子）。开发插件，离不开这些钩子。 TapableTapable 为 webpack 提供了统一的插件接口（钩子）类型定义，它是 webpack 的核心功能库。webpack 中目前有十种 hooks，在 Tapable 源码中可以看到，他们是： 123456789101112// https://github.com/webpack/tapable/blob/master/lib/index.jsexports.SyncHook = require("./SyncHook");exports.SyncBailHook = require("./SyncBailHook");exports.SyncWaterfallHook = require("./SyncWaterfallHook");exports.SyncLoopHook = require("./SyncLoopHook");exports.AsyncParallelHook = require("./AsyncParallelHook");exports.AsyncParallelBailHook = require("./AsyncParallelBailHook");exports.AsyncSeriesHook = require("./AsyncSeriesHook");exports.AsyncSeriesBailHook = require("./AsyncSeriesBailHook");exports.AsyncSeriesLoopHook = require("./AsyncSeriesLoopHook");exports.AsyncSeriesWaterfallHook = require("./AsyncSeriesWaterfallHook"); Tapable 还统一暴露了三个方法给插件，用于注入不同类型的自定义构建行为： tap：可以注册同步钩子和异步钩子。 tapAsync：回调方式注册异步钩子。 tapPromise：Promise方式注册异步钩子。 webpack 里的几个非常重要的对象，Compiler, Compilation 和 JavascriptParser 都继承了 Tapable 类，它们身上挂着丰富的钩子。 Compiler HooksCompiler 编译器模块是创建编译实例的主引擎。大多数面向用户的插件都首先在 Compiler 上注册。 compiler上暴露的一些常用的钩子： 钩子 类型 什么时候调用 run AsyncSeriesHook 在编译器开始读取记录前执行 compile SyncHook 在一个新的compilation创建之前执行 compilation SyncHook 在一次compilation创建后执行插件 make AsyncParallelHook 完成一次编译之前执行 emit AsyncSeriesHook 在生成文件到output目录之前执行，回调参数： compilation afterEmit AsyncSeriesHook 在生成文件到output目录之后执行 assetEmitted AsyncSeriesHook 生成文件的时候执行，提供访问产出文件信息的入口，回调参数：file，info done AsyncSeriesHook 一次编译完成后执行，回调参数：stats Compilation HooksCompilation 是 Compiler 用来创建一次新的编译过程的模块。一个 Compilation 实例可以访问所有模块和它们的依赖。在一次编译阶段，模块被加载、封装、优化、分块、散列和还原。Compilation 也继承了 Tapable 并提供了很多生命周期钩子。 Compilation 上暴露的一些常用的钩子： 钩子 类型 什么时候调用 buildModule SyncHook 在模块开始编译之前触发，可以用于修改模块 succeedModule SyncHook 当一个模块被成功编译，会执行这个钩子 finishModules AsyncSeriesHook 当所有模块都编译成功后被调用 seal SyncHook 当一次compilation停止接收新模块时触发 optimizeDependencies SyncBailHook 在依赖优化的开始执行 optimize SyncHook 在优化阶段的开始执行 optimizeModules SyncBailHook 在模块优化阶段开始时执行，插件可以在这个钩子里执行对模块的优化，回调参数：modules optimizeChunks SyncBailHook 在代码块优化阶段开始时执行，插件可以在这个钩子里执行对代码块的优化，回调参数：chunks optimizeChunkAssets AsyncSeriesHook 优化任何代码块资源，这些资源存放在 compilation.assets 上。一个 chunk 有一个 files 属性，它指向由一个chunk创建的所有文件。任何额外的 chunk 资源都存放在 compilation.additionalChunkAssets 上。回调参数：chunks optimizeAssets AsyncSeriesHook 优化所有存放在 compilation.assets 的所有资源。回调参数：assets JavascriptParser HooksParser 解析器实例在 Compiler 编译器中产生，用于解析 webpack 正在处理的每个模块。我们可以用它提供的 Tapable 钩子自定义解析过程。 JavascriptParser 上暴露的一些常用的钩子： 钩子 类型 什么时候调用 evaluate SyncBailHook 在计算表达式的时候调用。 statement SyncBailHook 为代码片段中每个已解析的语句调用的通用钩子 import SyncBailHook 为代码片段中每个import语句调用，回调参数：statement,source export SyncBailHook 为代码片段中每个export语句调用，回调参数：statement call SyncBailHook 解析一个call方法的时候调用，回调参数：expression program SyncBailHook 解析一个表达式的时候调用，回调参数：expression 对webpack底层逻辑和tapable钩子有了这些了解后，我们就可以进一步尝试开发一个插件了。 四、如何开发一个webpack pluginplugin 的基本结构一个 webpack plugin 由如下部分组成： 一个命名的 Javascript 方法或者 JavaScript 类。 它的原型上需要定义一个叫做 apply 的方法。 注册一个事件钩子。 操作webpack内部实例特定数据。 功能完成后，调用webpack提供的回调。 一个基本的 plugin 代码结构大致长这个样子： 1234567891011// plugins/MyPlugin.jsclass MyPlugin &#123; apply(compiler) &#123; compiler.hooks.done.tap('My Plugin', (stats) =&gt; &#123; console.log('Bravo!'); &#125;); &#125;&#125;module.exports = MyPlugin; 这就是一个最简单的 webpack 插件了，它注册了 Compiler 上的异步串行钩子 done，在钩子中注入了一条控制台打印的语句。根据上文钩子的介绍我们可以知道，done 会在一次编译完成后执行。所以这个插件会在每次打包结束，向控制台首先输出这句 Bravo!。 开发一个文件清单插件我希望每次webpack打包后，自动产生一个打包文件清单，上面要记录文件名、文件数量等信息。 思路： 显然这个操作需要在文件生成到dist目录之前进行，所以我们要注册的是Compiler上的emit钩子。 emit 是一个异步串行钩子，我们用 tapAsync 来注册。 在 emit 的回调函数里我们可以拿到 compilation 对象，所有待生成的文件都在它的 assets 属性上。 通过 compilation.assets 获取我们需要的文件信息，并将其整理为新的文件内容准备输出。 然后往 compilation.assets 添加这个新的文件。 插件完成后，最后将写好的插件放到 webpack 配置中，这个包含文件清单的文件就会在每次打包的时候自动生成了。 实现：123456789101112131415161718192021222324252627282930313233343536373839404142// plugins/FileListPlugin.jsclass FileListPlugin &#123; constructor (options) &#123; // 获取插件配置项 this.filename = options &amp;&amp; options.filename ? options.filename : 'FILELIST.md'; &#125; apply(compiler) &#123; // 注册 compiler 上的 emit 钩子 compiler.hooks.emit.tapAsync('FileListPlugin', (compilation, cb) =&gt; &#123; // 通过 compilation.assets 获取文件数量 let len = Object.keys(compilation.assets).length; // 添加统计信息 let content = `# $&#123;len&#125; file$&#123;len&gt;1?'s':''&#125; emitted by webpack\n\n`; // 通过 compilation.assets 获取文件名列表 for(let filename in compilation.assets) &#123; content += `- $&#123;filename&#125;\n`; &#125; // 往 compilation.assets 中添加清单文件 compilation.assets[this.filename] = &#123; // 写入新文件的内容 source: function() &#123; return content; &#125;, // 新文件大小（给 webapck 输出展示用） size: function() &#123; return content.length; &#125; &#125; // 执行回调，让 webpack 继续执行 cb(); &#125;) &#125;&#125;module.exports = FileListPlugin; 测试：在 webpack.config.js 中配置我们自己写的plugin：123456plugins: [ new MyPlugin(), new FileListPlugin(&#123; filename: '_filelist.md' &#125;)] npm run build 执行，可以看到生成了 _filelist.md 文件： 打开 dist 目录，可以看到_filelist.md 文件中列出了 webpack 打包后的文件： 成功！ 总结本文总结了 webpack plugin 的工作原理、wepack底层执行的基本流程以及介绍了 tapable 和常用的 hooks，最后通过两个小例子演示了如何自己开发一个webpack插件。 开发插件并非难如登天的事情，当遇到通过配置无法解决的问题，又一时找不到好的插件时，不如试试自己编写一个插件来解决，相信我，你会越来越强的！ 本文的源码均可在这里获取：https://github.com/yc111/webpack-plugin 欢迎交流～ Happy New Year！ – 参考https://webpack.js.org/api/compiler-hooks/https://webpack.js.org/api/compilation-hooks/https://webpack.js.org/api/parser/https://github.com/yc111/webpack/tree/master/libhttps://webpack.js.org/contribute/writing-a-plugin/https://github.com/webpack/tapable#tapablehttps://webpack.js.org/concepts/#pluginshttps://webpack.js.org/api/plugins/]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack配置本地loader的四种方法]]></title>
    <url>%2F2020%2F01%2F04%2Fwebpack%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0loader%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[通常我们配置 loader 只需直接使用 loader 的名字，不用关心 loader 的路径。那是因为通过 npm 或者 yarn 安装的 loader 都会安装在 node_modules 目录下，而 webpack 默认所有第三方模块都会去 node_modules 里找。 当我们要使用本地 loader (例如测试自己开发的loader)，而这些模块不在 node_modules 里的时候，就需要告诉 webpack 存放 loader 的位置。 在 webpack4.0 里，一共有四种方法配置本地loader： 1. 在配置 rules 的时候直接指定 loader 的绝对路径123456789101112module.exports = &#123; // xxx module: &#123; rules: [ &#123; test: /\.js$/, // 在这里配置绝对路径 use: path.resolve(__dirname, 'loaders/myLoader.js') &#125; ] &#125;&#125; 2. 或者在 resolveLoader 里配置 alias 别名1234567891011121314151617module.exports = &#123; // xxx resolveLoader: &#123; // 配置 resolveLoader.alias alias: &#123; myLoader: path.resolve(__dirname, 'loaders/myLoader.js') &#125; &#125;, module: &#123; rules: [ &#123; test: /\.js$/, use: 'myLoader' &#125; ] &#125;&#125; 3. 还可以在 resolveLoader 里配置 modules 属性将放置 loader 的目录告诉 webpack。当 webpack 在默认目录下找不到指定 loader 时，会自动去这个目录查找。resolveLoader.modules 是个数组，可以配置多个路径。12345678910111213141516module.exports = &#123; // xxx resolveLoader: &#123; // 配置 resolveLoader.modules modules: ['node_modules', path.resolve(__dirname, 'loaders'] &#125;, module: &#123; rules: [ &#123; test: /\.js$/, use: 'myLoader' &#125; ] &#125;&#125; 4. 还可以使用 npm link 把 loader 从当前项目抽离出来，构建独立工程。 在 loader 工程目录下执行 npm link; 回到原项目目录，执行 npm link xxx (xxx为loader的名称)。 最后，在原项目使用时，直接使用名称即可 (跟 npm install 的 loader 一样使用)。 如果对 npm link 原理感兴趣，可以看一看这篇文章 npm link详解。 –GOOD LUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[封装axios]]></title>
    <url>%2F2019%2F12%2F23%2F%E5%B0%81%E8%A3%85axios%2F</url>
    <content type="text"><![CDATA[axios 是一个轻量的 HTTP客户端，它基于 XMLHttpRequest 服务来执行 HTTP 请求，支持丰富的配置，支持 Promise，支持浏览器端和 Node.js 端。自Vue2.0起，尤大大（Vue作者尤雨溪）宣布取消对 vue-resource 的官方推荐，转而推荐 axios。现在 axios 已经成为大部分 Vue 开发者的首选。（ 如果你还不熟悉 axios，可以在这里查看它的API。） axios 的API很友好，你完全可以很轻松地在项目中直接使用。不过随着项目规模增大，如果每发起一次HTTP请求，就要把这些比如设置超时时间、设置请求头、根据项目环境判断使用哪个请求地址、错误处理等等操作，都就地写一遍，得疯！这种重复劳动不仅浪费时间，而且让代码变得冗余不堪，难以维护。 为了提高我们的代码质量，我们应该在项目中二次封装一下 axios 再使用。 那么，怎么封装 axios 呢？ 原来的样子封装前，先来看下，不封装的情况下，一个实际项目中axios请求的样子。大概是长这样：1234567891011121314151617181920212223242526axios(&apos;http://localhost:3000/data&apos;, &#123; method: &apos;GET&apos;, timeout: 1000, withCredentials: true, headers: &#123; &apos;Content-Type&apos;: &apos;application/json&apos;, Authorization: &apos;xxx&apos;, &#125;, transformRequest: [function (data, headers) &#123; return data; &#125;], // 其他请求配置...&#125;).then((data) =&gt; &#123; // todo: 真正业务逻辑代码 console.log(data);&#125;, (err) =&gt; &#123; if (err.response.status === 401) &#123; // handle authorization error &#125; if (err.response.status === 403) &#123; // handle server forbidden error &#125; // 其他错误处理..... console.log(err);&#125;); 可以看到在这段代码中，页面代码逻辑只在第15行处，上方的一大块请求配置代码和下方一大块响应错误处理代码，几乎跟页面功能没有关系，而且每个请求中这些内容都差不多，甚至有的部分完全一样。想象一下，每发一次请求都来这么一下，十几个请求一写，会是什么盛况？ 封装步骤封装的本质就是在待封装的内容外面添加各种东西，然后把它们作为一个新的整体呈现给使用者，以达到扩展和易用的目的。 封装axios要做的事情，就是把所有HTTP请求共用的配置，事先都在axios上配置好，预留好必要的参数和接口，然后把它作为新的axios返回。 接下来我们借助一个demo实现一个具有良好扩展性的axios封装。 demo目录结构如下(由Vue-cli 3.0 生成)：123456789101112131415|--public/|--mock/| |--db.json # 我新建的接口模拟数据|--src/| |--assets/| |--components/| |--router/| |--store/| |--views/| |--Home.Vue| |--App.vue| |--main.js| |--theme.styl|--package.json|... 封装目标我希望在 Home 页，发起 axios 请求时就像调用一个只有少量参数的方法一样简单，这样我就可以专注业务代码了。 1. 将 axios 封装到一个独立的文件 在src下创建 utils/http.js 文件 123cd srcmkdir utilstouch http.js 引入 axios 123// src/utils/http.jsimport axios from &apos;axios&apos;; 创建一个类你也可以用函数来封装，我只是觉得类更语义化而已。 123456//src/utils/http.js//...class NewAxios &#123;&#125; 给不同环境配置不同请求地址根据 process.env.NODE_ENV 配置不同的 baseURL，使项目只需执行相应打包命令，就可以在不同环境中自动切换请求主机地址。 1234567891011121314151617181920// src/utils/http.js//...const getBaseUrl = (env) =&gt; &#123; let base = &#123; production: &apos;/&apos;, development: &apos;http://localhost:3000&apos;, test: &apos;http://localhost:3001&apos;, &#125;[env]; if (!base) &#123; base = &apos;/&apos;; &#125; return base;&#125;;class NewAxios &#123; constructor() &#123; this.baseURL = getBaseUrl(process.env.NODE_ENV); &#125;&#125; 配置超时时间timeout属性，我一般设置10秒。 123456789// src/utils/http.js//...class NewAxios &#123; constructor() &#123; //... this.timeout = 10000; &#125;&#125; 配置允许携带凭证widthCredentials属性设为true。 123456789// src/utils/http.js//...class NewAxios &#123; constructor() &#123; //... this.withCredentials = true; &#125;&#125; 给这个类创建实例上的方法request在 request 方法里，创建新的axios实例，接收请求配置参数，处理参数，添加配置，返回axios实例的请求结果（一个promise对象）。你也可以不创建，直接使用默认导出的axios实例，然后把所有配置都放到它上面，不过这样一来整个项目就会共用一个axios实例。虽然大部分项目下这样够用没问题，但是有的项目中不同服务地址的请求和响应结构可能完全不同，这个时候共用一个实例就没办法支持了。所以为了封装可以更通用，更具灵活性，我会使用axios的create方法，使每次发请求都是新的axios实例。 12345678910111213141516171819// src/utils/http.js//...class NewAxios &#123; //... request(options) &#123; // 每次请求都会创建新的axios实例。 const instance = axios.create(); const config = &#123; // 将用户传过来的参数与公共配置合并。 ...options, baseURL: this.baseURL, timeout: this.timeout, withCredentials: this.withCredentials, &#125;; // 配置拦截器，支持根据不同url配置不同的拦截器。 this.setInterceptors(instance, options.url); return instance(config); // 返回axios实例的执行结果 &#125;&#125; 因为拦截器配置内容比较多，所以封装成一个内部函数了。 配置请求拦截器在发送请求前对请求参数做的所有修改都在这里统一配置。比如统一添加token凭证、统一设置语言、统一设置内容类型、指定数据格式等等。做完后记得返回这个配置，否则整个请求不会进行。我这里就配置一个token。 123456789101112131415// src/utils/http.js//...class NewAxios &#123; //... // 这里的url可供你针对需要特殊处理的接口路径设置不同拦截器。 setInterceptors = (instance, url) =&gt; &#123; instance.interceptors.request.use((config) =&gt; &#123; // 请求拦截器 // 配置token config.headers.AuthorizationToken = localStorage.getItem(&apos;AuthorizationToken&apos;) || &apos;&apos;; return config; &#125;, err =&gt; Promise.reject(err)); &#125; //...&#125; 配置响应拦截器在请求的then或catch处理前对响应数据进行一轮预先处理。比如过滤响应数据，更多的，是在这里对各种响应错误码进行统一错误处理，还有断网处理等等。我这里就判断一下403、请求超时和断网。 123456789101112131415161718192021222324252627282930313233343536373839404142// src/utils/http.js//...class NewAxios &#123; //... setInterceptors = (instance, url) =&gt; &#123; //... instance.interceptors.response.use((response) =&gt; &#123; // 响应拦截器 // todo: 想根据业务需要，对响应结果预先处理的，都放在这里 console.log(); return response; &#125;, (err) =&gt; &#123; if (err.response) &#123; // 响应错误码处理 switch (err.response.status) &#123; case &apos;403&apos;: // todo: handler server forbidden error break; // todo: handler other status code default: break; &#125; console.log(&apos;err.response: &apos;, err); return Promise.reject(err.response); &#125; if (err.request) &#123; // 请求超时处理 if (err.request.readyState === 4 &amp;&amp; err.request.status === 0) &#123; // 当一个请求在上面的timeout属性中设置的10秒内还没结束，则触发超时错误 // todo handler request timeout error &#125; console.log(&apos;err.request: &apos;, err); return Promise.reject(err.request); &#125; if (!window.navigator.online) &#123; // 断网处理 // todo: jump to offline page return -1; &#125; console.log(&apos;err: &apos;, err); return Promise.reject(err); &#125;); &#125; //...&#125; 另外，在拦截器里，还适合放置loading等缓冲效果：在请求拦截器里显示loading，在响应拦截器里移除loading。这样所有请求就都有了一个统一的loading效果。 默认导出新的实例1234// src/utils/http.js//...export default new NewAxios(); 最后完整的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// src/utils/http.jsimport axios from &apos;axios&apos;;const getBaseUrl = (env) =&gt; &#123; let base = &#123; production: &apos;/&apos;, development: &apos;http://localhost:3000&apos;, test: &apos;http://localhost:3001&apos;, &#125;[env]; if (!base) &#123; base = &apos;/&apos;; &#125; return base;&#125;;class NewAxios &#123; constructor() &#123; this.baseURL = getBaseUrl(process.env.NODE_ENV); this.timeout = 10000; this.withCredentials = true; &#125; setInterceptors = (instance, url) =&gt; &#123; instance.interceptors.request.use((config) =&gt; &#123; // 在这里添加loading // 配置token config.headers.AuthorizationToken = localStorage.getItem(&apos;AuthorizationToken&apos;) || &apos;&apos;; return config; &#125;, err =&gt; Promise.reject(err)); instance.interceptors.response.use((response) =&gt; &#123; // 在这里移除loading // todo: 想根据业务需要，对响应结果预先处理的，都放在这里 return response; &#125;, (err) =&gt; &#123; if (err.response) &#123; // 响应错误码处理 switch (err.response.status) &#123; case &apos;403&apos;: // todo: handler server forbidden error break; // todo: handler other status code default: break; &#125; return Promise.reject(err.response); &#125; if (!window.navigator.online) &#123; // 断网处理 // todo: jump to offline page return -1; &#125; return Promise.reject(err); &#125;); &#125; request(options) &#123; // 每次请求都会创建新的axios实例。 const instance = axios.create(); const config = &#123; // 将用户传过来的参数与公共配置合并。 ...options, baseURL: this.baseURL, timeout: this.timeout, withCredentials: this.withCredentials, &#125;; // 配置拦截器，支持根据不同url配置不同的拦截器。 this.setInterceptors(instance, options.url); return instance(config); // 返回axios实例的执行结果 &#125;&#125;export default new NewAxios(); 现在 axios 封装算是完成了80%。我们还需要再进一步把axios和接口结合再封装一层，才能达到我在一开始定的封装目标。 2. 使用新的 axios 封装API 在 src 目录下新建 api 文件夹。把所有涉及HTTP请求的接口统一集中到这个目录来管理。 新建 home.js。我们需要把接口根据一定规则分好类，一类接口对应一个js文件。这个分类可以是按页面来划分，或者按模块等等。为了演示更直观，我这里就按页面来划分了。实际根据自己的需求来定。 使用新的 axios 封装API（固定url的值，合并用户传过来的参数），然后命名导出这些函数。 12345678// src/api/home.js import axios from &apos;@/utils/http&apos;;export const fetchData = options =&gt; axios.request(&#123; ...options, url: &apos;/data&apos;,&#125;);export default &#123;&#125;; 在 api 目录下新建 index.js，把其他文件的接口都在这个文件里汇总导出。 123// src/api/index.jsexport * from &apos;./home&apos;; 这层封装将我们的新的axios封装到了更简洁更语义化的接口方法中。 现在我们的目录结构长这样：1234567891011121314151617181920|--public/|--mock/| |--db.json # 接口模拟数据|--src/| |--api/ # 所有的接口都集中在这个目录下| |--home.js # Home页面里涉及到的接口封装在这里| |--index.js # 项目中所有接口调用的入口| |--assets/| |--components/| |--router/| |--store/| |--utils/| |--http.js # axios封装在这里| |--views/| |--Home.Vue| |--App.vue| |--main.js| |--theme.styl|--package.json|... 使用封装后的axios现在我们要发HTTP请求时，只需引入 api 下的 index.js 文件就可以调用任何接口了，并且用的是封装后的 axios。12345678910111213141516171819202122232425// src/views/Home.vue&lt;template&gt; &lt;div class=&quot;home&quot;&gt; &lt;h1&gt;This is home page&lt;/h1&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;// @ is an alias to /srcimport &#123; fetchData &#125; from &apos;@/api/index&apos;;export default &#123; name: &apos;home&apos;, mounted() &#123; fetchData() // axios请求在这里 .then((data) =&gt; &#123; console.log(data); &#125;) .catch((err) =&gt; &#123; console.log(err); &#125;); &#125;,&#125;;&lt;/script&gt; axios请求被封装在fetchData函数里，页面请求压根不需要出现任何axios API，悄无声息地发起请求获取响应，就像在调用一个简单的 Promise 函数一样轻松。并且在页面中只需专注处理业务功能，不用被其他事物干扰。 运行运行 npm run serve 启动项目，执行 npm run mock 启动服务mock接口。 现在打开 localhost:8080 可以看到home页面。打开浏览器控制台，可以看到打印的请求响应结果： 简洁，优雅。 总结 封装思想是前端技术中很有用的思想，简单的axios及接口封装，就可以让我们可以领略到它的魅力。 封装 axios 没有一个绝对的标准，只要你的封装可以满足你的项目需求，并且用起来方便，那就是一个好的封装方案。 BTW：以上封装给大家提供了一个封装好的axios和api框架，经过以上过程封装好的 axios，可以不局限于 Vue，React 项目同样可以拿去使用，它适用任何前端项目。 本文的代码可以在这里获取：https://github.com/yc111/wrap-axios 欢迎交流～]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>axios</tag>
        <tag>full stack</tag>
        <tag>vue</tag>
        <tag>http</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ajax vs Axios vs Fetch]]></title>
    <url>%2F2019%2F12%2F20%2FAjax-vs-Axios-vs-Fetch%2F</url>
    <content type="text"><![CDATA[发HTTP请求是JS前端应用最常见的任务之一。实现HTTP请求有非常多解决方案，目前主流的几个解决方案有 ajax、axios 和 fetch。哪个好？如何选？下面对这几个方案进行一个简单的对比分析。 ajax： jQuery库中的异步HTTP请求API。基本语法： 1$.ajax(url[, settings]) axios： 轻量的HTTP客户端，支持浏览器端和 Node.js 端。基本语法: 1axios(url[, options]).then().catch() fetch： Web原生的HTTP请求API。基本语法: 1fetch(url[, options]).then().catch() 可以看到 axios 和 fetch 的基本用法非常一致，不过在面对稍复杂一些的需求时使用还是有差别的。 性能 ajax 和 axios 属于第三方库，它们底层都是基于 XMLHttpRequest，而 fetch 是web原生的 JS API，是 web标准 的一部分。从性能上讲，原生API fetch 有天然的性能优势：1fetch &gt; axios = ajax 简洁性在处理异步的方式上，ajax 基于回调，axios 和 fetch 都是基于 Promise，因此代码会比 ajax 更简洁，更优雅。1axios = fetch &gt; ajax jQuery3.0之后，$.ajax()也支持了$.ajax().done().fail().always()的链式调用方式（内部基于Defferred对象实现）。 易用性在功能上，axios 支持了很多实用的功能封装，比如请求和响应拦截器等等。fetch 则是纯粹的HTTP请求API，不支持额外的功能，你需要自己重写 fetch方法 来实现请求拦截。ajax 也不支持额外的功能。从易用和实用上讲，axios 无疑是占优势的：1axios &gt; fetch &gt; ajax 兼容性兼容性方面，jQuery 是比较早期的库，所以 ajax 对低版本的浏览器支持较好。axios 由于使用了 Promise (ECMAScript2015特性)，在一些低版本浏览器中支持的不好，比如IE8和更低的IE浏览器。fetch 只在比较新的现代浏览器中支持，并且所有IE都不支持。从浏览器兼容上讲：1ajax &gt; axios &gt; fetch 不过现在旧版本浏览器以及IE浏览器已经在慢慢淘汰，浏览器兼容的顾虑会越来越少，兼容性越来越不重要。所以就放心大胆地使用新的技术吧。 一些不成熟的建议和看法 ajax 依然有它的市场，现在依然有很多的依赖 jQuery 库的项目，在 $.ajax 就够用了的情况下，没必要非要引入 axios。 在尤大大的推荐下，Vue 项目一般都搭配 axios 使用，但是不要陷入 “Vue 只能使用 axios”，或者 “axios 只能在 Vue 中使用” 的误区。 以后的大趋势依然是原生web。使用原生的好处之一就是，不依赖外部，不必再加载额外模块，效率高。所以当原生web标准支持越来越多草案后，第三方的库也就没有存在的必要了，以后 fetch 的使用率会越来越高。 不过从历史规律看来，第三方永远比标准发展的快… 最后我想说，没有最好，只有最合适。而只有了解这些技术的特点，才可以让技术选型不再随意或者跟风。 –FIGHTING！ 参考：jQuery ajax APIAxios 官网Fetch API MDN]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>ajax</tag>
        <tag>axios</tag>
        <tag>fetch</tag>
        <tag>full stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack中的publicPath]]></title>
    <url>%2F2019%2F12%2F05%2Fwebpack%E4%B8%AD%E7%9A%84publicPath%2F</url>
    <content type="text"><![CDATA[webpack的常用基本配置我们可能已经耳熟能详，比如 input,output,module,plugins,devServer的配置等等。而在这些基本配置中，其实还有一些细节参数，它可以帮助我们更好的定制化打包的目录结构，但它可能并不是那么好理解，比如publicPath。 webpack官网这么解释：publicPath配置项在很多场景下都非常有用，它允许你给你的应用中的所有静态资源指定一个基本路径。 The publicPath configuration option can be quite useful in a variety of scenarios. It allows you to specify the base path for all the assets within your application. 有些抽象，我总结了下，它大概做的事情就是：可以帮我们处理资源引用的url路径问题：为生成的资源自动添加特定路径前缀。 什么时候需要使用publicPath?1. 打包出来的文件有特定目录结构划分时webpack打包出来的文件，默认都统一放在output配置的path路径下，项目稍大一点，这个目录中的文件就比较杂乱了，我们可能会希望给这些文件进行归类。当然我们可以粗暴一点通过filename来指定一个子目录。但是，如果在这这个子目录中，文件还有层级，就需要配置相应 plugin 或者 loader 的 publicPath 了。 例如file-loader，我们可以配置它的outputPath 自定义生成文件存放在output.path的哪个子目录，并且配置它的 publicPath 指定资源路径前缀：在file-loader中publicPath的值可以是string和function123456789101112module: &#123; rules: [ &#123; test: /\.(png|jpe?g|gif)$/i, loader: &apos;file-loader&apos;, options: &#123; outputPath: &apos;media&apos;, // string publicPath: &apos;media&apos;, // string &#125; &#125; ]&#125; 这样，编译打包后的图片资源就会放在dist/media目录下（假设你设置的output path为dist），并且所有引用到图片的资源路径都会自动加上前缀 media/。 如果想对不同的图片添加不同的路径前缀，可以使用函数来定义publicPath:123456789101112131415161718192021222324252627module: &#123; rules: [ &#123; test: /\.(png|jpe?g|gif)$/i, loader: &apos;file-loader&apos;, options: &#123; publicPath: (url, resourcePath, context) =&gt; &#123; // `resourcePath` 是这个资源的本地绝对路径 // `context` 是存放这个资源的目录，或者是`context`配置项的值 // 想获取相对路径可以这样： // const relativePath = path.relative(context, resourcePath); // 将符合下面条件的png图片url添加前缀 `other_public_path` if (/my-custom-image\.png/.test(resourcePath)) &#123; return `other_public_path/$&#123;url&#125;`; &#125; // 将符合下面条件的图片url添加前缀 `image_output_path` if (/images/.test(context)) &#123; return `image_output_path/$&#123;url&#125;`; &#125; // 其他图片url添加前缀 `public_path` return `public_path/$&#123;url&#125;`; &#125; &#125; &#125; ]&#125; 这样编译打包出来的图片url，就会根据你的设置，分别加上 other_public_path、image_output_path和public_path前缀了（当然这几个目录的名称你自己来定），是不是很不错？ 2. 生产模式要求index首页不在根目录下例如在某些生产模式下，要求产出的文件目录类似这样：12345|--assets/| |--index.js| |--vendor.js|--page/ |--index.html 那么可以这么配置webpack：123456789101112// webpack.prod.js fileoutput: &#123; filename: &apos;assets/[name].js&apos;, path: resolve(__dirname, &apos;../&apos;, &apos;dist&apos;), publicPath: &apos;../&apos; // 相对HTML页面的路径&#125;,plugins: [ new HtmlWebpackPlugin(&#123; template: &apos;../public/index.html&apos;, filename: &apos;pages/index.html&apos; &#125;)], 编译后，在index.html中index.js的引用就会变成这样：1&lt;script src=../assets/index.js&gt;&lt;/script&gt; 在output中publicPath的值可以是以下几种：123456789101112module.exports = &#123; //... output: &#123; // 以下几种之一 publicPath: &apos;https://cdn.example.com/assets/&apos;, // CDN (一定是HTTPS) publicPath: &apos;//cdn.example.com/assets/&apos;, // CDN (HTTPS协议) publicPath: &apos;/assets/&apos;, // 相对服务端跟目录 publicPath: &apos;assets/&apos;, // 相对 HTML 页面文件 publicPath: &apos;../assets/&apos;, // 相对 HTML 页面文件 publicPath: &apos;&apos;, // 相对 HTML 页面文件 (与HTML同一目录) &#125;&#125;; 3. 生产模式下的静态资源在CDN上托管时例如在某些生产模式下，静态文件都由www.xx.com/assets来托管那么可以在 webpack 中这么配置 publicPath：123456// webpack.prod.js fileoutput: &#123; filename: &apos;assets/[name].js&apos;, path: resolve(__dirname, &apos;../&apos;, &apos;dist&apos;), publicPath: &apos;https://www.xx.com/assets&apos; // CDN URL&#125;, 编译后，在 index.html 中 index.js 的引用就会变成这样：1&lt;script src=https://www.xx.com/assets/index.js&gt;&lt;/script&gt; 其他在devServer中也有publicPath配置，默认它是获取output的publicPath的值。要提一下，webpack-dev-server生成的文件是不会放在硬盘的，而是在内存中，所以看不到。只有在请求资源的时候，可以证明文件的存在。。。123devServer &#123; publicPath: &apos;/assets/&apos;&#125; 一定要在string的前后都放上/。 需要注意的是，devServer中还有一个叫做contentBase的参数，这个参数如果配置的不好，跟publicPath一搭配，很可能会导致请求不到页面（我也是被这个坑了很久）。这个地方如果出问题，基本上原因在于contentBase设置的路径范围太小了，去掉contentBase配置，或者给它配置多个路径，把输出目录包含进来，就可以解决问题。 1234devServer &#123; contentBase: [path.resolve(__dirname, &apos;../assets&apos;), path.resolve(__dirname, &apos;../dist&apos;)], // contentBase可以放多个路径 publicPath: &apos;/assets/&apos;&#125; –GOOD LUCK! 参考：https://webpack.js.org/guides/public-path/https://www.npmjs.com/package/file-loader]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack优化之happypack]]></title>
    <url>%2F2019%2F11%2F29%2Fwebpack%E4%BC%98%E5%8C%96%E4%B9%8Bhappypack%2F</url>
    <content type="text"><![CDATA[上篇文章webpack优化之玩转代码分割和公共代码提取从代码维度出发，为生产环节进行了优化（通过提取公用代码减小打包结果体积，提升线上体验）。而在开发大型前端项目时，经过一段时间的开发维护和不断迭代，随着业务功能增多，就算提取了公共代码，项目体积仍会越来越大（如果不从产品层面优化，这是无法避免的），这意味着编译打包时间会越来越久、从修改代码到看到效果的等待时间越来越长。为了更好的开发体验，这次我们来为开发环节做一些事情。 How？我们可以试试使用happypack。虽然这个包有点老了，作者也不怎么维护了（汗。。（因为他不怎么使用javascript了，他推荐了thread-loader，有空研究下） HappypackHappypack 是一个webpack插件，它可以帮助我们实现多线程打包，提升webpack打包性能，减少开发者等待打包的时间，从而提升开发体验，提高开发效率。 使用Happypack的使用非常简单，只需3步： 安装happypack 1npm i -D happypack 修改rules配置 1234&#123; rest: /\.js$/, use: &apos;Happypack/loader?id=js&apos; //id用于在接下来的插件中引用，便于识别对谁进行多线程打包&#125; 在webpack插件中 new happypack把原来在rules中配置的use参数放到happypack插件参数中。 123456new Happypack(&#123; id: &apos;js&apos;, use :[&#123; loader: &apos;babel-loader&apos; &#125;]&#125;) 最后大致长这样：12345678910111213141516171819202122const Happypack = require(&apos;happypack&apos;);module.exports = &#123; mode: &apos;development&apos;, entry: xxx, output: xxx, module: &#123; rules: [ &#123; rest: /\.js$/, use: &apos;Happypack/loader?id=js&apos; &#125; ] &#125;, plugins: [ new Happypack(&#123; id: &apos;js&apos;, use :[&#123; loader: &apos;babel-loader&apos; &#125;] &#125;) ]&#125; 如果还要对其他类型的文件进行多线程打包，可以继续替换和new就行（注意id的对应）。 happypack适用于比较大的项目，如果项目比较小，使用happypack可能会花更长时间，因为开线程需要消耗一些性能。 –GOOD LUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack优化之玩转代码分割和公共代码提取]]></title>
    <url>%2F2019%2F11%2F15%2Fwebpack%E4%BC%98%E5%8C%96%E4%B9%8B%E7%8E%A9%E8%BD%AC%E4%BB%A3%E7%A0%81%E5%88%86%E5%89%B2%E5%92%8C%E5%85%AC%E5%85%B1%E4%BB%A3%E7%A0%81%E6%8F%90%E5%8F%96%2F</url>
    <content type="text"><![CDATA[开发多页应用的时候，如果不对webpack打包进行优化，当某个模块被多个入口模块引用时，它就会被打包多次（在最终打包出来的某几个文件里，它们都会有一份相同的代码）。当项目业务越来越复杂，打包出来的代码会非常冗余，文件体积会非常庞大。大体积文件会增加编译时间，影响开发效率；如果直接上线，还会拉长请求和加载时长，影响网站体验。作为一个追求极致体验的攻城狮，是不能忍的。所以在多页应用中优化打包尤为必要。那么如何优化webpack打包呢？ 一、概念在一切开始前，有必要先理清一下这三个概念： module: 模块，在webpack眼里，任何可以被导入导出的文件都是一个模块。 chunk: chunk是webpack拆分出来的： 每个入口文件都是一个chunk 通过 import、require 引入的代码也是 通过 splitChunks 拆分出来的代码也是 bundle: webpack打包出来的文件，也可以理解为就是对chunk编译压缩打包等处理后的产出。 二、问题分析首先，简单分析下，我们刚才提到的打包问题： 核心问题就是：多页应用打包后代码冗余，文件体积大。 究其原因就是：相同模块在不同入口之间没有得到复用，bundle之间比较独立。 弄明白了问题的原因，那么大致的解决思路也就出来了： 我们在打包的时候，应该把不同入口之间，共同引用的模块，抽离出来，放到一个公共模块中。这样不管这个模块被多少个入口引用，都只会在最终打包结果中出现一次。————解决代码冗余。 另外，当我们把这些共同引用的模块都堆在一个模块中，这个文件可能异常巨大，也是不利于网络请求和页面加载的。所以我们需要把这个公共模块再按照一定规则进一步拆分成几个模块文件。————减小文件体积。 至于如何拆分，方式因人而异，因项目而异。我个人的拆分原则是： 业务代码和第三方库分离打包，实现代码分割； 业务代码中的公共业务模块提取打包到一个模块； 第三方库最好也不要全部打包到一个文件中，因为第三方库加起来通常会很大，我会把一些特别大的库分别独立打包，剩下的加起来如果还很大，就把它按照一定大小切割成若干模块。 optimization.splitChunkswebpack提供了一个非常好的内置插件帮我们实现这一需求：CommonsChunkPlugin。不过在 webpack4 中CommonsChunkPlugin被删除，取而代之的是optimization.splitChunks, 所幸的是optimization.splitChunks更强大！ 三、 实现通过一个多页应用的小demo，我们一步一步来实现上述思路的配置。 demo目录结构：12345678910|--public/| |--a.html| |--index.html|--src/| |--a.js| |--b.js| |--c.js| |--index.js|--package.json|--webpack.config.js 代码逻辑很简单，index模块中引用了 a 和 b 2个模块，a 模块中引用了 c 模块和 jquery库，b 模块中也引用了 c 模块和 jquery 库，c 是一个独立的模块没有其他依赖。 index.js代码如下：1234567//index.jsimport a from &apos;./a.js&apos;;import b from &apos;./b.js&apos;;function fn() &#123; console.log(&apos;index-------&apos;);&#125;fn(); a.js代码如下：1234567//a.jsrequire(&apos;./c.js&apos;);const $ = require(&apos;jquery&apos;)function fn() &#123; console.log(&apos;a-------&apos;);&#125;module.exports = fn(); b.js代码如下：1234567//b.jsrequire(&apos;./c.js&apos;);const $ = require(&apos;jquery&apos;)function fn() &#123; console.log(&apos;b-------&apos;);&#125;module.exports = fn(); c.js代码如下：12345//c.jsfunction fn() &#123; console.log(&apos;c-------&apos;);&#125;module.exports = fn(); 1. 基本配置webpack先不做优化，只做基本配置看看效果。项目配置了2个入口，搭配html-webpack-plugin实现多页打包：1234567891011121314151617181920212223const path = require(&apos;path&apos;);const HtmlWebpackPlugin = require(&apos;html-webpack-plugin&apos;);module.exports = &#123; entry: &#123; index: &apos;./src/index.js&apos;, a: &apos;./src/a.js&apos; &#125;, output: &#123; path: path.resolve(__dirname, &apos;dist&apos;), filename: &apos;[name].js&apos; &#125;, plugins: [ new HtmlWebpackPlugin(&#123; template: &apos;./public/index.html&apos;, filename: &apos;index.html&apos; &#125;), new HtmlWebpackPlugin(&#123; template: &apos;./public/a.html&apos;, filename: &apos;a.html&apos; &#125;) ]&#125; 在开发模式下运行webpack： 可以看到，打包出两个html和两个体积很大的（300多K）的文件a.js,index.js。 进入dist目录检查js文件： a.js里包含c模块代码和jquery代码 index.js里包含a模块、b模块、c模块和jquery代码 看，同样的代码c和jquery被打包了2遍。 2. 初步添加splitChunks优化配置首先解决相同代码打包2次的问题，我们需要让webpack把c和jquery提取出来打包为公共模块。 在webpack配置文件添加splitChunks：123456789101112//webpack.config.jsoptimization: &#123; splitChunks: &#123; cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos; &#125; &#125; &#125;&#125; - cacheGroups cacheGroups是splitChunks配置的核心，对代码的拆分规则全在cacheGroups缓存组里配置。 缓存组的每一个属性都是一个配置规则，我这里给他的default属性进行了配置，属性名可以不叫default可以自己定。属性的值是一个对象，里面放的我们对一个代码拆分规则的描述。 - name name：提取出来的公共模块将会以这个来命名，可以不配置，如果不配置，就会生成默认的文件名，大致格式是index～a.js这样的。 - chunks chunks：指定哪些类型的chunk参与拆分，值可以是string可以是函数。如果是string，可以是这个三个值之一：all,async,initial，all代表所有模块，async代表只管异步加载的, initial代表初始化时就能获取的模块。如果是函数，则可以根据chunk参数的name等属性进行更细致的筛选。 再次打包： 可以看到a.js,index.js从300多K减少到6点几K。同时增加了一个common.js文件，并且两个打包入口都自动添加了common.js这个公共模块： 进入dist目录，依次查看这3个js文件： a.js里不包含任何模块的代码了，只有webpack生成的默认代码。 index.js里同样不包含任何模块的代码了，只有webpack生成的默认代码。 common.js里有a,b,c,index,jquery代码。 发现，提是提取了，但是似乎跟我们预料的不太一样，所有的模块都跑到common.js里去了。 这是因为我们没有告诉webpack（splitChunks）什么样的代码为公共代码，splitChunks默认任何模块都会被提取。 - minChunkssplitChunks是自带默认配置的，而缓存组默认会继承这些配置，其中有个minChunks属性： 它控制的是每个模块什么时候被抽离出去：当模块被不同entry引用的次数大于等于这个配置值时，才会被抽离出去。 它的默认值是1。也就是任何模块都会被抽离出去（入口模块其实也会被webpack引入一次）。 我们上面没有配置minChunks，只配置了name和chunk两个属性，所以minChunks的默认值 1 生效。也难怪所有的模块都被抽离到common.js中了。 优化一下，在缓存组里配置minChunks覆盖默认值：12345678910111213//webpack.config.jsoptimization: &#123; splitChunks: &#123; cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos;, minChunks: 2 //模块被引用2次以上的才抽离 &#125; &#125; &#125;&#125; 然后运行webpack 可以看到有2个文件的大小发生了变化：common.js由314K减小到311K，index.js由6.22K增大到7.56K。 进入dist目录查看： a.js里依然不包含任何模块的代码（正常，因为a作为模块被index引入了一次，又作为入口被webpack引入了一次，所以a是有2次引用的）。 index.js里出现了b和index模块的代码了。 common.js里只剩a,c,和jquery模块的代码。 现在我们把共同引用的模块a, c, jquery，从a和index这两个入口模块里抽取到common.js里了。有点符合我们的预期了。 3. 配置多个拆分规则3.1 实现代码分离，拆分第三方库接下来，我希望公共模块common.js中，业务代码和第三方模块jquery能够剥离开来。 我们需要再添加一个拆分规则。123456789101112131415161718192021//webpack.config.jsoptimization: &#123; splitChunks: &#123; minSize: 30, //提取出的chunk的最小大小 cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos;, minChunks: 2, //模块被引用2次以上的才抽离 priority: -20 &#125;, vendors: &#123; //拆分第三方库（通过npm|yarn安装的库） test: /[\\/]node_modules[\\/]/, name: &apos;vendor&apos;, chunks: &apos;initial&apos;, priority: -10 &#125; &#125; &#125;&#125; 我给cacheGroups添加了一个vendors属性（属性名可以自己取，只要不跟缓存组下其他定义过的属性同名就行，否则后面的拆分规则会把前面的配置覆盖掉）。 - minSizeminSize设置的是生成文件的最小大小，单位是字节。如果一个模块符合之前所说的拆分规则，但是如果提取出来最后生成文件大小比minSize要小，那它仍然不会被提取出来。这个属性可以在每个缓存组属性中设置，也可以在splitChunks属性中设置，这样在每个缓存组都会继承这个配置。这里由于我的demo中文件非常小，为了演示效果，我把minSize设置为30字节，好让公共模块可以被提取出来，正常项目中不用设这么小。 - prioritypriority属性的值为数字，可以为负数。作用是当缓存组中设置有多个拆分规则，而某个模块同时符合好几个规则的时候，则需要通过优先级属性priority来决定使用哪个拆分规则。优先级高者执行。我这里给业务代码组设置的优先级为-20，给第三方库组设置的优先级为-10，这样当一个第三方库被引用超过2次的时候，就不会打包到业务模块里了。 - testtest属性用于进一步控制缓存组选择的模块，与chunks属性的作用有一点像，但是维度不一样。test的值可以是一个正则表达式，也可以是一个函数。它可以匹配模块的绝对资源路径或chunk名称，匹配chunk名称时，将选择chunk中的所有模块。我这里用了一个正则/[\\/]node_modules[\\/]/来匹配第三方模块的绝对路径，因为通过npm或者yarn安装的模块，都会存放在node_modules目录下。 运行一下webpack： 可以看到新产生了一个叫vendor.js的文件（name属性的值），同时common.js文件体积由原来的311k减少到了861bytes！ 进入dist目录，检查js文件： a.js里不包含任何模块代码。 common.js只包含a和c模块的代码。 index.js只包含b和index模块的代码。 vendor.js只包含jquery模块的代码。 现在，我们在上一步的基础上，成功从common.js里把第三方库jquery抽离出来放到了vendor.js里。 3.2 拆分指定文件如果我们还想把项目中的某一些文件单独拎出来打包（比如工程本地开发的组件库），可以继续添加拆分规则。比如我的src下有个locallib.js文件要单独打包，假设a.js中引入了它。12345678//a.jsrequire(&apos;./c.js&apos;);require(&apos;./locallib.js&apos;); //引入自己本地的库const $ = require(&apos;jquery&apos;)function fn() &#123; console.log(&apos;a-------&apos;);&#125;module.exports = fn(); 可以这么配置：123456789101112131415161718192021222324252627//webpack.config.jsoptimization: &#123; splitChunks: &#123; minSize: 30, //提取出的chunk的最小大小 cacheGroups: &#123; default: &#123; name: &apos;common&apos;, chunks: &apos;initial&apos;, minChunks: 2, //模块被引用2次以上的才抽离 priority: -20 &#125;, vendors: &#123; //拆分第三方库（通过npm|yarn安装的库） test: /[\\/]node_modules[\\/]/, name: &apos;vendor&apos;, chunks: &apos;initial&apos;, priority: -10 &#125;, locallib: &#123; //拆分指定文件 test: /(src\/locallib\.js)$/, name: &apos;locallib&apos;, chunks: &apos;initial&apos;, priority: -9 &#125; &#125; &#125;&#125; 我在缓存组下又新增了一个拆分规则，通过test正则指定我就要单独打包src/locallib.js文件，并且把优先级设置为-9，这样当它被多次引用时，不会进入其他拆分规则组，因为另外两个规则的优先级都比它要低。 运行webpack打包后： 可以看到新产生了一个locallib.js文件。进入dist目录查看： a.js里不包含任何模块代码。 common.js只包含a和c模块的代码。 index.js只包含b和index模块的代码。 vendor.js只包含jquery模块的代码。 locallib.js里只包含locallib模块的代码。 现在我们又在上一步的基础上独立打包了一个指定的模块locallib.js。 至此，我们就成功实现了抽离公共模块、业务代码和第三方代码剥离、独立打包指定模块。 对比一下，优化前，打包出来js一共有633KB： 优化后，打包出来js一共不到330KB： 优化打包后的文件分类清晰，体积比优化前缩小了几乎50%，有点小完美是不是！击掌！这还只是我举的一个简单例子，在实际多页应用中，优化力度说不定还不止这么多。 总结webpack很强大，以上只是冰山一角，但是只要掌握了上述optimization.splitChunks的核心配置，我们就可以几乎随心所欲地按照自己的想法来拆分优化代码控制打包文件了，是不是很酷？ 用webpack玩转代码拆分，你也可以！ 本文的完整webpack配置和demo源码可以在这里获取：https://github.com/yc111/webpack-optimize-demo 欢迎一起探讨～ 如果觉得这些依然不能满足你的需求，还想更精(bian)细(tai)地定制打包规则，可以到webpack官网查看optimization.splitChunks的更多配置。 –GOODLUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>splitChunks</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack如何不打包第三方模块]]></title>
    <url>%2F2019%2F11%2F13%2Fwebpack%E5%A6%82%E4%BD%95%E4%B8%8D%E6%89%93%E5%8C%85%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[在一些前端工程中，不是所有的模块都需要打包到最终的生产中，例如开发UI库，我们不需要把依赖的基础框架和库打进去（比如vue，react，jquery等），因为它们在业务工程中会肯定会被引入，没必要在UI库中打包，而且打包进来不仅让UI库体积庞大，还可能在业务工程中引发版本依赖冲突。那么如何让工程在打包中避开某些不希望被打包的第三方模块呢？ webpack的externals可以帮到你，它的配置非常简单。 external的配置在webpack的配置文件中添加externals属性，把你不希望打包在最终结果中的包写进去就行了，你的其他代码不需要任何更改，头部的 import、require 什么的都不用变。12345678// webpack.config.jsmodule.exports = &#123; externals: &#123; jquery: &apos;jquery&apos;, react: &apos;react&apos;, &apos;react-dom&apos;: &apos;react-dom&apos; &#125;&#125; 然后再build打包的时候，你会发现打包出来的文件体积小了很多很多，打开编译后的文件看就会发现指定的第三方库都从代码中剔除了。 –GOODLUCK！]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cookie、session]]></title>
    <url>%2F2019%2F11%2F09%2Fcookie%E3%80%81session%2F</url>
    <content type="text"><![CDATA[Cookie是什么？它的工作原理是什么？Session是什么？它跟Cookie有什么区别？ Web应用是基于Http协议的，Http协议是无状态协议，因此没办法把同一个用户的两次请求关联起来，用户必须每操作一次就要登录一次。为了支持客户端与服务器之间的交互，我们需要一种技术为交互存储状态，Cookie和Session就应运而生。 一、概念 Cookie：Cookie由W3C组织提出。Cookie属于http协议标准，它是一段小信息，由服务器创建，以文本形式存储在客户端（浏览器）。用于存储一些服务器需要的用户信息数据，最大4KB。 Session：Session不属于任何协议，只是一个域对象，由服务器创建，保存在服务器上（默认是服务器内存，也可以存存redies或其他数据库如mogo等）。用于存储一些客户端会话数据，没有大小限制。 会话：用户打开浏览器访问某个网站，在这个网站上浏览任意页面，访问完成后将浏览器关闭的过程称为一次会话。Cookie和Session都属于常见的会话技术。会话技术是用于解决在会话过程中数据的保存问题。 二、Cookie的工作原理服务器收到客户端请求，如果服务器需要记录该用户状态： 则可以创建一个Cookie，放上用户信息，然后把Cookie信息附在Response Header（响应头）里，传给客户端（浏览器）。 浏览器收到响应后，会自动把这个Cookie保存到本地。 当客户端再次向该网站发出http请求时，浏览器会自动往Request Header（请求头）里添加这个Cookie。 服务器收到后，就可以根据请求里的Cookie字段，辨认用户状态等，也可以根据需要修改Cookie的内容。 另外： JavaScript能够任意读写Cookie，所以浏览器也可以改Cookie的内容，因此Cookie被视为不安全的。 Cookie中的信息一般都需要先经过加密。 Cookie不能跨域，但可以通过设置Cookie的domain参数来支持跨子域名（注意domain必须以.开头）。 很多浏览器都限制一个站点最多保存20个Cookie。 在浏览器想获取Cookie，可以通过document.cookie，获取该网站的所有Cookie。 Cookie生命周期只要设置了正常的有效期，浏览器会把Cookie保存到硬盘，关闭再打开浏览器，Cookie依然有效，直到超过设定的失效时间。Cookie有两种方式设置有效期，也可以称为生命周期。 maxAge 单位秒，设置的是从现在起，往后多久失效。 如果为正数，则该Cookie在maxAge秒后失效。 如果为负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。这种称为会话Cookie。 如果为0，表示删除该Cookie。 默认为-1，即默认在浏览器关闭后，Cookie就失效。 expires 可以设置一个绝对时间点，到达时间点即失效。 可以设置为整天数，表示expires天后失效。 如果设置的是一个过去的时间，那么这个Cookie会被立即删掉，立即失效。 三、Session的工作原理服务器收到客户端请求，如果服务器需要记录该用户状态： 则服务器可以产生一个Session，同时会生成一个唯一的sessionId， 服务器将这个sesionId通过set-cookie的放到Cookie中，借用Cookie的方式传给客户端， 客户端接收到响应后，浏览器会把Cookie保存，也就同时保存了sessionId。 当用户再次向该网站发出http请求时，浏览器的自动附加Cookie机制，让服务器收到带sessionId的Cookie，然后服务器通过sessionId来匹配用户状态，比如是否登录等。 另外： 因为Session存在服务端，所以它不能被客户端获取和修改，因此比Cookie安全些。 因为在服务端，Session没有跨域问题。 如果客户端禁用了Cookie的话，服务器还可以通过重写URL的方式把Session传给客户端。 由浏览器窗口内的链接、脚本等打开的新窗口，这类子窗口会共享父窗口的Cookie，因此也会共享一个Session。 Session生命周期 Session在用户第一次访问服务器的时候创建。 Session生成后，只要用户继续访问，服务器就会认为该用户的Session活跃（active）了一次，然后更新Session的最后访问时间，维护该Session。 如果正常关闭服务器，Session会序列化到硬盘。当服务器重新启动时，会执行反序列化。 一般包含Session信息的Cookie会设置失效时间为0，即浏览器进程有效时间，这种情况当浏览器关闭，Cookie失效，服务器在收到下一次请求后，就会销毁Session。 为了获取更高的存取速度，服务器一般把Session存在内存里。每个用户都有一个独立的Seesion，为了防止内存溢出，服务器会把长时间没有活跃的Session从内存中删除。这个时间就是Session的超时时间。另外，如果服务器宕机，Session也就销毁了 当Session被存在了数据库，则它的生命周期由Cookie的失效时间决定：如果此时服务器宕机，只要开机后数据库没有发生不可逆的破坏，Cookie时间没过期，那么Session继续保持；当Cookie过期，服务器将Session从数据库移除。 –参考：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Cookieshttps://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Set-Cookiehttps://blog.csdn.net/fangaoxin/article/details/6952954https://www.cnblogs.com/zhuanzhuanfe/p/8010854.htmlhttp://www.itheima.com/news/20180831/150322.htmlhttps://blog.csdn.net/pingfan592/article/details/88388045]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>cookie</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过webpack定义全局模块]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87webpack%E5%AE%9A%E4%B9%89%E5%85%A8%E5%B1%80%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[不知道大家在开发中有没有遇到这种情况，就是在很多模块里都要用到某一个库，于是在这些模块里都要不厌其烦地import一遍。页面少也还好，当项目庞大到一定程度，就有些讨厌了。有没有办法不要每次使用前都import，而是有个全局的引入，在其他任何地方直接使用就行了呢？有，webpack可以帮我们，它的内置插件ProvidePlugin就是为这个而生的。 1. 用法在webpack配置文件中配置 webpack.ProvidePlugin 插件。语法：123new webpack.ProvidePlugin(&#123; identifier: &apos;modulename&apos;&#125;) 如果像上面一样，直接指定模块名，确保你的模块就在当前目录下，或者是通过npm、yarn安装的。因为这么写，默认模块路径为当前目录./**和node_modules，webpack只会从这两个目录去加载模块（先找当前目录，找不到找node_modules目录）。 另外如果是导入ES6modules，需要指定模块的默认导出属性：123new webpack.ProvidePlugin(&#123; identifier: [&apos;modulename&apos;,&apos;propertyname&apos;]&#125;) 你也可以自己指定模块的完整绝对路径。这样你的模块可以放在工程的任何目录：123new webpack.ProvidePlugin(&#123; identifier: path.resolve(__dirname, somepath ,&apos;modulename&apos;)&#125;) 例如我在项目中要用到jQuery, Vue, mili(项目中的自己开发的工具模块)，这几个模块在很多地方都要使用，我就可以把他们申明在 ProvidePlugin 中：12345678plugins: [ new webpack.ProvidePlugin(&#123; $: &apos;jquery&apos;, &apos;window.$&apos;: &apos;jquery&apos;, Vue: [&apos;vue/dist/vue.esm.js&apos;, &apos;default&apos;], mili: path.resolve(__dirname, &apos;src&apos;, &apos;mili&apos;) &#125;)] 2. 原理ProvidePlugin是webpack内置的插件，在里面申明过的模块变量名，都可以在工程中任何模块中直接独立使用。因为webpack编译后，在代码中遇到独立出现的这些全局变量名时，会去自动加载它对应的模块，并把这个模块导出的内容（或者导出的某个指定的属性）赋给这个模块变量名。 3. 应用当我在ProvidePlugin中申明过全局模块变量后，在其他模块，我可以直接使用它们，而不用在头部import了。例如就上面例子中我申明了$, window.$, Vue, mili 四个全局模块变量，我就可以直接这么使用了：1234567// any module file// free to use $, window.$, Vue, mili，without importing them.let &#123;Message&#125; = mili;let $toot = $(&apos;#root&apos;);let $ele = window.$(&apos;#container&apos;);Vue.prototype.$bus = new Vue; 番外除了webpack.ProvidePlugin，还有其他方法实现全局模块变量，当作番外简单介绍一下吧。 1. html引用我们还可以通过在index.html模版中通过script标签引入全局模块。这个模块的路径可以是CDN地址，也可以是本地路径。然后在每个模块中就都能使用这个模块了。 引用CDN1234//index.html file&lt;head&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.js&quot;&gt;&lt;/script&gt;&lt;/head&gt; 引用本地前提是这个文件在项目发布的时候服务器上要有，所以记得在webpack上配置 copy-webpack-plugin 插件。1234//index.html file&lt;head&gt; &lt;script src=&quot;/vendor/jquery_3.4.1.js&quot;&gt;&lt;/script&gt;&lt;/head&gt; 这样在其他模块都可以直接使用window.$和$了。12console.log(window.$);console.log($); 2. expose-loaderexpose-loader 虽然是一个比较老的包，但是依然可用。它的作用是给全局对象window添加模块。 先安装：npm i -S expose-loader 可以内联使用在入口文件导入全局模块：1require(&apos;expose-loader?$!jquery&apos;); 或则1import $ from &apos;expose-loader?$!jquery&apos;; 也可以在webpack中配置1234567891011module: &#123; rulers: [ &#123; test: require.resolve(&apos;jquery&apos;), use: &#123; loader: &apos;expose-loader&apos;, options: &apos;$&apos; &#125; &#125; ]&#125; 不论使用哪种方式，最后在任何模块都可以通过window.$来使用jquery了：1console.log(window.$); –GOODLUCK!]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何利用webpack定义全局常量]]></title>
    <url>%2F2019%2F11%2F06%2F%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8webpack%E5%AE%9A%E4%B9%89%E5%85%A8%E5%B1%80%E5%B8%B8%E9%87%8F%2F</url>
    <content type="text"><![CDATA[在前端开发过程中，我们在不同的工程阶段，对代码会有不同的要求。比如在开发阶段，我们希望代码能更快地实时编译，自动刷新，可以调试定位源码；在接口测试阶段，我们希望可以不修改源码，只通过修改某个配置，就可以无缝切换接口地址或者上下文，以及决定请求是否携带token；在发布代码时，我们希望输出的代码体积尽可能小，代码可以各种压缩，各种分离打包等等。为了让一套代码适应不同工程阶段的需求，我们通常会刻意制造开发、测试、生产几种编译模式。然后我们通过webpack做一些配置，使得webpack在编译阶段可以识别出当前是什么模式，从而产生不同的编译行为，达到不同的编译效果。而这个配置，就是webpack.DefinePlugin。它是webpack的内置插件，用于提供自定义全局常量功能。 1. 配置方法1234567// webpack.config.js fileplugins: [ new webpack.DifinePlugin(&#123; DEVELOPMENT: &apos;&quot;dev&quot;&apos;, // JSON.stringify(&apos;dev&apos;) &apos;process.env.NODE_ENV&apos;: JSON.stringify(process.env.NODE_ENV) &#125;)] tip1: 定义全局常量时，常量的值会需要被字符串化，需要注意的是，如果写成字符串格式，必须在单引号内再套一对双引号（或者反过来在双引号内套单引号），才能彻底字符串化，或者直接使用JSON.stringify。 tip2: 如果要为process的某个属性定义值，尽量使用&#39;process.env.NODE_ENV&#39;: JSON.stringify(process.env.NODE_ENV)而不要使用process: { env: { NODE_ENV: JSON.stringify(&#39;production&#39;) } }，因为后面的做法会覆盖process对象，会影响其他模块的兼容性（因为其他模块也可能会对它赋值）。 2. 原理webpack.DefinePlugin中定义的常量，它会在编译时，内联地加入代码中，相当于原地替换，所以在项目的源码任何js模块中都可以直接使用这些常量。 3. 全局常量使用场景通过webpack.DefinePlugin配置常量的意义在于，我们可以保存一些在编译时产生的变量的值，然后在编译完的运行态中，获取和使用这个常量，来做一些事情。 ‘process.env.NODE_ENV’是比较常用的常量，它是我们区分不同编译模式的关键，在编译以外的代码中，我们很多时候也需要拿这个值来实现一些切换，主要目的是为了让开发、测试更方便和高效。 场景举例：定义’process.env.NODE_ENV’常量，在前端发请求的时候，根据’process.env.NODE_ENV’这个常量设置不同的请求路径格式。1234567891011switch(process.env.NODE_ENV) &#123; case &apos;dev&apos;: baseUrl = &apos;localhost:8000&apos;; return; case &apos;test&apos;: baseUrl = &apos;10.22.22.21:3000&apos;; return; case &apos;prod&apos;: baseUrl = &apos;10.69.32.101&apos;; return;&#125; –GOODLUCK!]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack解决跨域的几种方法]]></title>
    <url>%2F2019%2F11%2F05%2Fwebpack%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[作为前端攻城狮，经常要面临的问题就是跨域，不论是调自己mock服务的数据，还是真实前后台联调。因为接口服务与前端工程通常都是独立的工程，而前端有很多协议需要遵循同源策略（后端则不需要）。解决跨域的方法有很多，可以在服务端配置，也可以在前端解决。作为前端开发者，我更偏向在前端把跨域解决掉，别问我为什么，我就是喜欢这种不依赖后端的感觉[傲娇脸]。 PS：我使用webpack构建工程，我的方法都是基于webpack的大前提下。如果你是用的其他构建工具，或者是没有使用构建工具的工程环境，我的方法可能不能适用。 不能操控服务端代码的情况当你不能操控服务端代码时（比如前后端联调），你可以通过webpack配置代理。 1. 通过 http-proxy 代理在webpack配置文件 webpack.config.js 中添加 devServer 配置。然后配置它的 proxy 属性，webpack-dev-server 在起服务后，会把匹配的本地请求转到 proxy 里配置的服务器上去请求，通过服务端的转发，实现跨域。 有点抽象，举个栗子： 我的前端工程服务端口8000。我要联调的服务端口3000，域名‘champyin.com’。 我在前端这么发请求：xhr.open(‘GET, ‘/api/students’, true);那么我其实发的请求完整url为 http://localhost:8000/api/students,直接发肯定是报错的，因为我的本地是没有这个接口的。 现在我在webpack这么配置代理，给/api配置一个映射 12345devServer: &#123; proxy: &#123; &apos;/api&apos;: &apos;http://champyin.com:3000&apos; &#125;&#125; npm run dev 重启下前端工程，webpack-dev-server 在遇到’/api/students’这种以/api开头的请求的时候，它不再往本地发了，而是向对应的http://champyin.com:3000发请求。这是一种后端的请求转发，而后端没有跨域问题。这个时候，虽然在浏览器查看网络请求的时候，会看到前端发的请求地址是http://localhost:8000/api/students，但其实它的背后真正获取响应的请求是http://champyin.com:3000/api/students。 灵活的proxy配置很多时候，后端的接口不一定都有一个统一的前缀，这个时候，如果还按照上面的方法，那就要对每个不同的接口名配置一个映射，而且后台一旦增加接口，这里也要跟着加，每个映射的值还都是一样的，又麻烦又冗余。其实，webpack已经考虑了这一点，每一个映射规则的value可以是一个对象，并提供 pathRewrite 参数来重置请求的上下文。 复用一下上面的例子，只不过服务端稍有不同，服务端提供的接口没有统一的/api前缀，而是直接的接口名：/students、/classes、/grades 这个时候，proxy 可以这么配置： 12345678910devServer: &#123; proxy: &#123; &apos;/api&apos;: &#123; target: &apos;http://champyin.com:3000&apos;, pathRewrite: &#123; &apos;/api&apos;: &apos;&apos; &#125; &#125; &#125;&#125; 这样我们的前端请求依然保留/api前缀不用变，而在转发之前，这个前缀会自动被重置去掉。 现在我在前端依然这么发请求：xhr.open(‘GET, ‘/api/students’, true);即我发的请求完整url为 http://localhost:8000/api/students,而经过代理后的最终url为 http://champyin.com:3000/students 这样，就不用因为后台接口不规范，而影响我们的前端代码的质量了。 当然，这个只是在联调模式可以这么做，真正生产环境的时候，还是要后台统一规范，或者部署一个中间层做这种代理转发。 可以操控服务端代码的情况当你可以控制服务端代码时（比如自己mock数据），你还可以通过以下的方法避免跨域（变相地解决跨域） 2. 在dev-server内mock数据webpack-dev-server内部其实是自己起了一个express来做服务。webpack的devServer配置提供了一个before方法，在启动服务之前，这个方法会被执行，我们可以把我们mock数据的逻辑写在这里面。1234567devServer: &#123; before(app) &#123; app.get(&apos;/api/sdutents&apos;, (req, res) =&gt; &#123; res.json(&#123;name: &apos;champyin&apos;, score: 100&#125;) &#125;) &#125;&#125; 这个before方法会传一个参数供我们使用，这个参数就是webpack-dev-server内部起的express对象。 重启前端工程时，我们的mock服务也就启动了。这时，我们的mock接口跟前端其实在同一服务也就是webpack-dev-server的express服务下，也就不存在跨域了。 2. 在服务端启动webpack假设后端我们的express mock接口代码长这样：12345678const express = require(&apos;express&apos;);let app = express();app.get(&apos;/api/students&apos;, (req, res) =&gt; &#123; res.json(&#123;name: &apos;champyin&apos;, score: 100&#125;)&#125;)app.listen(3000, () =&gt; &#123; console.log(&apos;server is on 3000&apos;);&#125;); 现在我们要把webpack构建放到后端来起。在后端起webpack需要用到叫做webpack-dev-middleware的中间件，整体逻辑大致是：获取webpack模块 -&gt; 获取webpack配置文件 -&gt; 将配置文件传给webpack执行，获得compiler实例 -&gt; 把compiler实例传给webpack-dev-middleware中间件，然后整个交给express作为express中间件执行 -&gt; done!1234567891011121314// bin/www.js fileconst express = require(&apos;express&apos;);const webpack = require(&apos;webpack&apos;);const webpackDevMiddleware = require(&apos;webpack-dev-middleware&apos;);let webpackConf = require(&apos;../webpack.config.js&apos;);let compiler = webpack(webpackConf);let app = express();app.use(webpackDevMiddleWare(compiler));app.listen(3000, () =&gt; &#123; console.log(&apos;server is on 3000&apos;);&#125;); 现在启动前端工程就不是npm run dev了，而是node bin/www.js。 这时，我们的前端就跟后端复用了同一个服务，自然也就不存在跨域了。 其实这相当于在改后端了，不过这个后端是前端可以控制的，所以也算是前端的扩展了。另外，如果可以改后端的话，还可以直接在express里面通过设置请求头来实现跨域，不过这个就跟webpack没有关系了，就不在这里细讲了。 总结第一种方法是我们提倡的跨域配置，配置代理。首选推荐。第二和第三种方法其实是在你能控制后端工程的情况下，把前后端工程合并成一个工程了，区别是第二种方法相当于把后端接口移到前端工程来起，第三种方法是把前端工程构建移到后端工程来起。避免了跨域，也算是变相地解决跨域的方案吧，在某些轻量的工程里可以快速搭建调试环境。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>webpack</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es6-promise]]></title>
    <url>%2F2019%2F11%2F05%2Fes6-promise%2F</url>
    <content type="text"><![CDATA[自从2015年 ES6（ECMAScript 6）正式发布以来，许多JS新特性让我们的前端开发更加语意化，更加高效。在享受新特性给我们带来的便利的同时，在各类前端框架和业务代码满天飞的同时，我觉得仍有必要不间断地去了解和总结原生JS的底层机制、原理及其优缺点。就从Promise开始。 Promise总结基本语法123456789101112131415161718192021let p = new Promise((resolve, reject) =&gt; &#123; console.log(1) setTimeout(() =&gt; &#123; resolve(2); &#125;, 1000);&#125;)p.then(data =&gt; &#123; console.log(data); &#125;, err =&gt; &#123; console.log(err);&#125;)console.log(3);//输出：132其中 1 和 3 是立即输出，2 是1秒后输出。 Promise的本质它是一个类。它是异步编程的一种解决方案。它的链式调用方式，在一定程度上可以解决JS中的多层异步回调嵌套问题（也叫回调地狱）。 Promise的特征1 . 一个Promise对象有三个状态：pending，fulfilled，rejected。 只能当状态是pending时，这个状态才能改变，并且状态一旦发生改变，就不能再改变。 2 . Promise实例化时接受一个函数作为参数，这个函数会立即执行。 这个函数暴露两个参数，分别是resolve，reject，这两个参数同样也是函数。 3 . 每个Promise对象都有一个then方法。 4 . resolve和reject都接收一个参数，这个参数将被在内部进行一些必要处理，其返回结果会传到下一个then中。 5 . 必须在这个Promise实例中调用resolve或则reject或者throw new Error，才会往下走，即then中的方法才会被执行。 6 . 一个Promise对象可以多次then，也可以连续then（链式调用），每次then都会返回一个新的Promise对象。 7 . then也接收两个参数，是两个回调函数，分别对应处理成功和失败的业务。 8 . then的回调函数中，使用return进入下一个then的成功、使用throw new Error 等报错，进入下一个then的失败。不显示写return，则默认return undefined，也是进入下一个then的成功。 9 . then是微任务，所以then中的方法会在同步代码执行后再执行。 10 . 如果Promise实例中resolve了一个Promise，Promise内部会取这个Promise的then的结果，如果还是一个Promise，继续取，直到获得一个非Promise的值，然后把这个值返回。 11 . Promise的then可以穿透，即如果中间的then没有写成功或者失败的处理，则结果会一直往下传，直到有then处理。 Promise实例上的方法和静态方法Promise实例上的方法： then处理回调的函数。then的链式调用，是异步有序的，写在前面的会先执行。 catch本质是 .then(null, rejectCallback) 的别名，用于处理错误。 finallyES2018 中的新特性。不管Promise成功还是失败，都会执行的操作。 Promise静态方法： resolve将现有对象转为Promise对象的快捷方法。 reject产生一个状态为 rejected 的Promise实例。 all将多个Promise实例装包成一个Promise实例，同步获取多个异步操作的结果，只有所有Promise实例的状态都为 fulfilled，这个Promise才会成功，并且返回一个数组，里面按序存放异步操作的结果。只要一个Promise被reject，整个Promise都reject。 race将多个Promise实例包装成一个Promise实例，谁先改变状态，整个Promise就采用谁的状态和返回值。 any目前是一个stage3提案。接受一组Promise实例，如果谁先变成 fulfilled，整个Promise fulfilled，如果都 rejected，整个都失败。 Promise的缺点Promise不能彻底解决回调地狱，因为它也是基于回调来实现的。 解决方案：结合async+await，彻底解决异步回调地狱问题。 自己实现一版Promise现在的大部分IDE和浏览器都已经内置原生Promise，不过你也可以不使用原生Promise，选择自己写一个Promise。 但如果你的Promise想跟原生Promise混用，或者想让别人使用，最好先通过 promiseA+规范 的测试。 如何测试自己的Promise是否符合PromiseA+规范 step1. 在代码中添加测试代码在自己的 Promise.js 里，给Promise添加一个deferred静态方法，在里面new一个自己的Promise 实例，把自己的Promise实例和实例上的resolve、reject挂上去： 12345678Promise.deferred = () =&gt; &#123; let dfd = &#123;&#125;; dfd.promise = new Promise((resolve, reject) =&gt; &#123; dfd.resolve = resolve; dfd.reject = reject; &#125;) return dfd;&#125; step2. 安装 promsises-aplus-tests 插件 1npm i -D primises-aplus-tests step3. 运行脚本 123 npx promises-aplus-test ./ Promise.js &gt; npx 是 npm 8.5 以上具有的功能。 如果一切顺利，会在一片绿勾之后，得到872 passing (16s)这样的信息，这说明，你的Promise已经符合PromiseA+规范，即符合基本要求，可以放心使用了。 不间断补充更新中。 –GoodLuck!]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>promise</tag>
        <tag>es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git进阶之合并多次commit]]></title>
    <url>%2F2019%2F10%2F28%2Fgit%E8%BF%9B%E9%98%B6%E4%B9%8B%E5%90%88%E5%B9%B6%E5%A4%9A%E6%AC%A1commit%2F</url>
    <content type="text"><![CDATA[当我们开发一个功能，不是一时半会可以完成的时候，为了保护代码不丢失，通常会把这次的修改先 commit，等到这个功能完全做好，再 push。不过这样一来，就会有很多零碎的 commit 记录，这会使远程的提交历史显得杂乱。 必要的时候，我们需要将这些相近的 commit 合并为一个 commit 再 push。当然了，如果你想合并远程的 commit 也是可以的，但请一定要提前跟团队里的其他人说一声，免得有人也在跟你做同样的事情，导致没必要的代码冲突（所以合并 commit 尽量在 push 前）。 操作步骤： 1. git log 查看commit节点id1git log --oneline 参数--oneline可以让你的commit log在一行输出，比较紧凑，coimmit id也以简短的位数展示，比较便于查看。找到你要保留的那条commit的上一条commit（这样可以保证你要保留的那一条commit出现在pick清单的顶部），复制这条commit的id。 2. git rebase 变基1git rebase -i [commit_id] [commit_id]就放你在第1步复制的那个值。然后就会进入rebase界面，类似这样： 注意：观察头部的commit清单，确保你要保留的那条commit出现在内。一切顺利的话，它会出现在顶部第一条。 3. 修改 pick 为 squashvi指令i进入编辑模式，修改你不想保留的commit记录前的 pick 为 squash(或者s)。git 会把前面为 squash的commit记录与它的上一条记录合并为一条。 注意要确保第一条为 pick，因为squash的作用是把commit合并到上一个提交，所以必须保证至少第一个提交被pick。 如果你不小心把所有的pick都改为了s，然后保存退出，会收到一个错误提示：cannot &#39;squash&#39; without a previous commit。不要怕，根据它的下一个提示操作就可以了：12You can fix this with &apos;git rebase --edit-todo&apos; and then run &apos;git rebase --continue&apos;.Or you can abort the rebase with &apos;git rebase --abort&apos;. 尽管它提示了2种方法来处理，我还是推荐你使用git rebase --abort，然后重来一次rebase，这样最稳妥。 4. 处理合并后的commit message如果第3步顺利的话，esc之后，:进入指令模式，输入vi指令wq，保存并退出vi界面，然后会进入另一个vi界面，在这里它会把你合并的这些commit的日志列出来，便于你编辑。同样使用vi指令i进入编辑模式，编辑完后，esc+:+wq回车退出。然后会出现Successfully rebased and updated refs/heads/xxx.说明commit合并成功了。 5. 如果修改的是远程的commit，则强制push一把1git push -f 如果你还没push，只是处理本地的commit，则不需要这一步。否则，就需要把这次的rebase强制覆盖远程分支。 done！现在可以git log --oneline看下，是不是commit数量已经减少了，并且你指定的那些commit都合并为了一条，message就是你在第4步处理的内容。 GoodLuck！]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>rebase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Webpack error 之 TypeError: Cannot read property 'properties' of undefined]]></title>
    <url>%2F2019%2F10%2F17%2FWebpack-error-%E4%B9%8B-TypeError-Cannot-read-property-properties-of-undefined%2F</url>
    <content type="text"><![CDATA[老项目重新 npm install 的坑，问题原因比较隐蔽，记录一下。 操作背景 去年建的项目，webpack4.4.1，webpack-cli2.0.12。 今天在另一台电脑，把项目clone下来，然后npm install, 执行build打包的时候，立即报错。 两台电脑node环境相同。完整报错如下：123456789101112131415/node_modules/webpack-cli/bin/config-yargs.js:89 describe: optionsSchema.definitions.output.properties.path.description, ^TypeError: Cannot read property &apos;properties&apos; of undefined at module.exports (/Users/yinchuan/Documents/学习/学习笔记/test/code-lib/webpack-library-example/node_modules/webpack-cli/bin/config-yargs.js:89:48) at /Users/yinchuan/Documents/学习/学习笔记/test/code-lib/webpack-library-example/node_modules/webpack-cli/bin/webpack.js:60:27 at Object.&lt;anonymous&gt; (/Users/yinchuan/Documents/学习/学习笔记/test/code-lib/webpack-library-example/node_modules/webpack-cli/bin/webpack.js:515:3) at Module._compile (module.js:652:30) at Object.Module._extensions..js (module.js:663:10) at Module.load (module.js:565:32) at tryModuleLoad (module.js:505:12) at Function.Module._load (module.js:497:3) at Module.require (module.js:596:17) at require (internal/module.js:11:18) 问题分析 看提示，是webpack-cli报错，于是进webpack-cli相应目录查看 不知为啥没有获得 webapack 配置参数的 output 属性。 简单百度了一下，有人说是webpack和webpack-cli版本不对应导致，安装一下最新的webpack-cli即可解决。也没太注意，就直接重新安装了webpack-cli，为了webpack也跟它匹配，连webpack一起重装了： 1npm i --save-dev webpack webpack-cli 安装完就直接build了，但是还是报同样的错。 于是开始各种尝试，直接npx webpack用默认配置打包、用配置文件webpack.config.js打包、把工程简化到就一句console.log、把webpack配置精简到就entry和output… 排除了文件路径，代码逻辑问题，webpack和webpack-cli也都是最新的，还是没用。 最后再次百度，发现有人提到他把 webpack-cli 从2.x升级到3.x就好了，原因是 webpack 在 4.20.0 之后，需要 webpack-cli3.1.1 搭配使用。。。 https://github.com/webpack/webpack/releases/tag/v4.20.0 我突然想到 npm package 的版本前面的那个符号有限制版本的作用，可能我以为我的webpack-cli是最新的，但其实并没有呢？ 赶紧去检查了下我的本地webpack和webpack-cli版本，OHG！果然！12&quot;webpack&quot;: &quot;^4.41.2&quot;,&quot;webpack-cli&quot;: &quot;^2.1.5&quot; 刚才的重新安装后，webpack-cli并没有更新到3.x。 问题原因所以问题原因终于找到：webpack4.20.0之后，需要 webpack-cli3.1.1 搭配使用，而现在是webpack4.41.2 + webpack-cli2.1.5，所以开始报开头贴出来的错。 而我以为我装了最新的实际却没有给我装最新的cli，原因是：坑爹的 ^ ，这个符号会限制你在不指定package版本的install时，安装的是不超过当前大版本的最新版本。所以&quot;webpack-cli&quot;: &quot;^2.0.12&quot;这句，限制了我直接install的webpack-cli版本不会超过3.0.0 。 更多npm包版本的语意可以到官网 https://docs.npmjs.com/misc/semver 查阅。 解决强制安装：npm i -D webpack-cli@latest或者在 package.json 删除&quot;webpack-cli&quot;: &quot;^2.0.12&quot;这句后，再使用普通安装：npm i -D webpack-cli。 再运行npm run build 打包，OK了～ 总结 不要以为重新安装一下就一定是安装最新的包。 不要忽视 npm package 的版本号前缀，它的语意很重要。 一定要关注webpack这些打包工具的release动态和特性变化，这对你的项目中如果改变了webpack的版本导致的问题很有帮助。 webpack 4.20.0 以上，需要 webpack-cli3.1.1 搭配使用。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>webpack-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node.js操作数据库之MongoDB+mongoose篇]]></title>
    <url>%2F2019%2F10%2F10%2Fnode.js%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8BMongoDB%2Bmongoose%E7%AF%87%2F</url>
    <content type="text"><![CDATA[node.js 的出现，使得用前端语法(javascript)开发后台服务成为可能，越来越多的前端因此因此接触后端，甚至转向全栈发展。后端开发少不了数据库的操作。MongoDB 是一个基于分布式文件存储的开源数据库系统。本文为大家详细介绍了如何用 node.js + mongoose 玩转 MongoDB 。希望能帮到有需要的人。 由于我用Mac开发，以下所有操作都是在Mac下进行。 一、 环境搭建安装Node.js 有 node 环境的可以跳过。 nodejs官网提供了 macOS 安装包，直接下载安装即可。现在 nodejs 稳定版已经到了 12.11.1 。 安装MongoDBMongoDB 是为现代应用程序开发人员和云时代构建的基于文档的通用分布式数据库。 上个月（9月） macOS 包管理器 Homebrew 宣布移除 MongoDB 。原因是去年10月 MongoDB 宣布将其开源许可证从 GNU AGPLv3 切换到 SSPL（Server Side Public License），以此回应 AWS 等云厂商将 MongoDB 以服务的形式提供给用户而没有回馈社区的行为，MongoDB 希望从软件即服务上获取收入。Homebrew 认为 MongoDB 已经不再属于开源范畴… 言归正传，由于上述原因，我们不能直接使用 brew install mongodb 来安装 MongoDB 了。好在 MongoDB 自己维护了一个定制化的 Homebrew tap。并在 Install MongoDB Community Edition 更新了安装步骤。 Mac下 MongoDB 的最新安装步骤如下： 1. 首先安装 HomebrewHomebrew 是 macOS 的包管理器。因为 OSX 默认不包含 Homebrew brew 包，所以要先安装，已经安装过的可以跳过。1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装过程会有点长，终端输出信息超过一屏，这里我只截取了头尾两部分。 2. 然后获取下 MongoDB Homebrew Tap1brew tap mongodb/brew 3. 最后安装 MongoDB CE（社区版）1brew install mongodb-community@4.2 现在你的 Mac 上就已经安装好 MongoDB 环境了。 安装mongoose node.js 是可以直接操作 MongoDB 的，但是通过 MongoDB 命令语法直接编写 MongoDB 验证、数据类型转换和业务逻辑模版比较繁琐。所以我们使用了 mongoose。 mongoose 是 MongoDB 的一个对象模型工具，它对 MongoDB 的常用方法进行了封装，让 node.js 操作 MongoDB 更加优雅简洁。 刚才的 node.js 和 MongoDB 都是安装在全局环境，mongoose 则是安装在你的项目下：12cd your-projectnpm i -S mongoose 现在，你的开发环境就已经全部安装好了。 二、启动MongoDB服务要操作 MongoDB ，首先要启动它。有两种方式启动 MongoDB 服务： 1. 在前台运行1mongod --config /usr/local/etc/mongod.conf 前台运行的好处就是，可以查看一些反馈和日志，便于调试。另外如果要关闭服务，只需要在终端按 control + c 键即可。 2. 也可以作为 macOS 服务，在后台运行1brew services start mongodb-community@4.2 后台运行的好处是开机就自动启动，随时可以使用。 这种启动方式，如果要关闭服务，可以通过 stop 命令： 1brew services stop mongodb-community@4.2 现在，你的 MongoDB 数据库已经开启了。 三、操作MongoDB操作之前先解释一下MongoDB和mongoose里的一些核心概念。MongoDB MongoDB 中的数据记录是一种 BSON 格式的文件（BSON是一种用二进制描述的JSON文件格式）。 MongoDB 将文件存储在集合中，将集合存储在数据库中。 MongoDB 的数据库、集合都不用手动创建。 集合collection: 相当于关系型数据库中的表table。 文件document: MongoDB 的数据记录单位，相当于关系型数据库中的记录row。 mongoose schema: 在 mongoose 中，所有的东西都来源于一个 schema，每个schema 映射了一个 MongoDB 的集合，它定义了这个集合中的文档的骨架。 model: 一个文件的构造器，通过编译schema得到，一个model的实例就是一个文件，model负责从 MongoDB 数据库中创建和读取文档。 更多mongoose概念可以在mongoose guide中查阅。 数据库操作： 1. 使用 mongoose 连接 MongoDB在项目中创建 connection.js 文件1234567891011121314151617181920// connection.js fileconst mongoose = require(&apos;mongoose&apos;);const conn = mongoose.createConnection( // 连接地址，MongoDB 的服务端口为27017 // dbtest是我要使用的数据库名，当往其中写数据时，MongoDB 会自动创建一个名为dbtest的数据库，不用事先手动创建。 &apos;mongodb://127.0.0.1:27017/dbtest&apos;, // 一些兼容配置，必须加，你不写运行的时候会提示你加。 &#123; useNewUrlParser: true, useUnifiedTopology: true &#125;)conn.on(&apos;open&apos;, () =&gt; &#123; console.log(&apos;打开 mongodb 连接&apos;);&#125;)conn.on(&apos;err&apos;, (err) =&gt; &#123; console.log(&apos;err:&apos; + err);&#125;) 运行：1node conection.js 可以看到打印出“打开 mongodb 连接”，并且运行一直在等待。 这说明现在已经成功连接上 MongoDB 了，接下来可以开始操作数据库了。 为了方便扩展起见，我们先对 connection.js 改造一下，让它作为模块导出，这样就可以在其他地方导入复用了。1234567891011121314151617// connection.js fileconst mongoose = require(&apos;mongoose&apos;);const conn = mongoose.createConnection( &apos;mongodb://127.0.0.1:27017/dbtest&apos;, &#123; useNewUrlParser: true, useUnifiedTopology: true &#125;)conn.on(&apos;open&apos;, () =&gt; &#123; console.log(&apos;打开 mongodb 连接&apos;);&#125;)conn.on(&apos;err&apos;, (err) =&gt; &#123; console.log(&apos;err:&apos; + err);&#125;)module.exports = conn; //commonJs 语法，导出conn模块。 2. 添加操作 save | create 方法新建insert.js文件 1234567891011121314151617181920212223242526// insert.js filelet mongoose = require(&apos;mongoose&apos;);// 导入连接模块let connection = require(&apos;./connection&apos;);// 创建schemalet StudentSchema = new mongoose.Schema(&#123; name: String, age: Number&#125;)// 通过connection和schema创建modellet StudentModel = connection.model(&apos;Student&apos;, StudentSchema);// 通过实例化model创建文档let studentDoc = new StudentModel(&#123; name: &apos;zhangsan&apos;, age: 20&#125;)// 将文档插入到数据库，save方法返回一个Promise对象。studentDoc.save().then((doc) =&gt; &#123; console.log(doc)&#125;) 运行：1node insert.js 为了更直观看到操作数据库的结果，推荐大家安装一个数据库可视化工具：Robo3T，下载mac版安装即可。 点击 Robo3T 左上角连接我们的数据库后，可以看到 MongoDB 自动帮我们生成了数据库和集合，并且已经插入了一条记录： 或者还可以直接通过Model的create方法直接插入数据，返回的也是一个Promise：123456StudentModel.create(&#123; name: &apos;lisi&apos;, age: 19&#125;).then((doc) =&gt; &#123; console.log(doc)&#125;) 3. 读取操作 find 方法为更加合理复用代码，我们先把 StudentSchema 和 StudentModel 抽离出来： 新建StudentSchema.js文件123456789// StudentSchema.js fileconst mongoose = require(&apos;mongoose&apos;);let StudentSchema = mongoose.Schema(&#123; name: String, age: Number&#125;)module.exports = StudentSchema; 新建StudentModel.js文件1234567// StudentModel.js fileconst connection = require(&apos;./connection&apos;);const StudentSchema = require(&apos;./StudentSchema&apos;);let StudentModel = connection.model(&apos;Student&apos;, StudentSchema);module.exports = StudentModel; 然后新建query.js文件1234567// query.js fileconst StudentModel = require(&apos;./StudentModel&apos;);// 富查询条件，对象格式，键值对，下面为查询 name 为 lisi 的记录StudentModel.find(&#123;name: &apos;lisi&apos;&#125;).then(doc =&gt; &#123; console.log(doc);&#125;) 运行1node query.js 可以看到name为“lisi”的记录被打印了出来。 如果想查询整个集合：1234// 不放查询条件即查询所有的记录StudentModel.find(&#123;&#125;).then(doc =&gt; &#123; console.log(doc);&#125;) 可以看到集合中的所有记录被打印了出来。 4. 更新操作 update|updateOne|updateMany 方法 新建update.js文件12345678// update.js fileconst StudentModel = require(&apos;./StudentModel&apos;);// update 方法接收2个参数，第一个是查询条件，第二个是修改的值// 下面把name为lisi的记录，将他的age修改为80StudentModel.update(&#123;name: &apos;lisi&apos;&#125;, &#123;age: 80&#125;).then(result =&gt; &#123; console.log(result)&#125;) 进入 Robo3T，可以看到数据被更改（切换到表格模式更加直观）： 不过在终端，提示DeprecationWarning: collection.update is deprecated. Use updateOne, updateMany, or bulkWrite instead. 意思是建议我们使用 updateOne、updateMany或者bulkWrite update 更新查询到的所有结果，方法已经不提倡使用，已被updateMany替代。updateOne 如果查询到多条结果，只更新第一条记录。upateMany 更新查询到的所有结果。bulkWrite 提供可控执行顺序的批量写操作。 为了代码的健壮性，我们应该根据建议将update方法换成updateMany方法。 另外，终端的输出{ n: 1, nModified: 1, ok: 1 }的意思是： “n: 1”：查询到1条记录。 “nModified: 1”：需要修改1条记录。（如果修改值和原始值相同，则需要修改的就是0条） “ok: 1”：修改成功1条。 5. 删除操作 remove|removeOne|removeMany|bulkWrite 方法 新建remote.js文件12345678// remove.js fileconst StudentModel = require(&apos;./StudentModel&apos;);// delete 方法接收1个参数，就是查询条件// 下面把name为lisi的记录删除StudentModel.remove(&#123;name:&apos;lisi&apos;&#125;).then((result) =&gt; &#123; console.log(result);&#125;); 进入 Robo3T，可以看到集合里已经没有name为lisi的记录了： 在看终端的输出，跟update类似，也提示建议使用新的方法代替。 意思是建议我们使用 removeOne、removeMany或者bulkWrite remove 删除查询到所有结果，方法已经不提倡使用，已被removeMany替代。removeOne 如果查询到多条结果，只删除第一条记录。removeMany 删除查询到所有结果。bulkWrite 提供可控执行顺序的批量写操作。 另外，终端的输出{ n: 1, ok: 1, deletedCount: 1 }的意思跟update的类似，就不累述了。 现在我们已经成功地对 MongoDB 数据库进行了 CRUD（添加、读取、更新、删除）操作。欢呼～ 更多高级操作，可以到mongoose API 文档中查阅。 四、总结梳理一下，主要讲了这些内容： node.js+MongoDB+mongoose 在Mac下的环境搭建，注意使用最新的 MongoDB 的安装方式。 在Mac下如何启动和关闭 MongoDB 服务。 介绍了 MongoDB 和 mongoose 的基本核心概念。 使用 mongoose 连接以及增删改查 MongoDB 操作。可以使用 Robo3T 来更直观地观察数据库。 前端也能玩转数据库开发。欢迎交流～ 文章源码地址：https://github.com/yc111/mongodb-demo 相关网站：Homebrew官网MongoDB官网monggose官网Robo3T官网macOS 包管理器 Homebrew 移除 MongoDB]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>node</tag>
        <tag>MongoDB</tag>
        <tag>mongoose</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github项目徽标]]></title>
    <url>%2F2019%2F10%2F05%2Fgithub%E9%A1%B9%E7%9B%AE%E5%BE%BD%E6%A0%87%2F</url>
    <content type="text"><![CDATA[GitHub徽标，GitHub Badge，你也可以叫它徽章。就是在项目README中经常看到的那些表明构建状态或者版本等信息的小图标。就像这样：这些好看的小图标不仅简洁美观，而且包含了清晰易读的信息，在README中使用小徽标能够为自己的项目说明增色不少！如何给自己的项目加上小徽标呢？ 一、关于徽标 徽标图片分左右两部分，左边是标题，右边是内容，就像是键值对。 GitHub徽标官网是 https://shields.io/ 图标规范 二、如何添加动态徽标动态徽标是指如果项目状态发生变化，会自动更新状态的徽标，它能保证用户看到的信息就是项目当前的真实状态。 常用的动态徽标有： 持续集成状态 项目版本信息 代码测试覆盖率 项目下载量 贡献者统计等等 这里以Travis CI 的持续集成状态为例。没有接触过 Travis CI的可以看我的上一篇文章 利用Travis CI+GitHub实现持续集成和自动部署 登录 Travis CI，进入配置过构建的项目，在项目名称的右边有个 build passing 或者 build failing 徽标。 点击它，在弹出框中，就可以看到 Travis CI 为你提供的各种格式的徽章地址了。 你可以根据需要选择格式，imageUrl格式大概是这个样子： 1https://www.travis-ci.org/&#123;your-name&#125;/&#123;your-repo-name&#125;.svg?branch=master markdown格式大概是这个样子： 1[![Build Status](https://www.travis-ci.org/&#123;your-name&#125;/&#123;your-repo-name&#125;.svg?branch=master)](https://www.travis-ci.org/&#123;your-name&#125;/&#123;your-repo-name&#125;) 简单起见，我选择 markdown 格式。将内容复制后，打开项目的README文档，在顶部位置粘贴。 经过前4步，小徽章就搞定了。将README文档push到远程，刷新GitHub页面，过一会，就会看到README上面已经有了持续集成状态图标了。之所以要过一会才加载出来，是因为它要动态从 Travis CI 平台获取状态。 三、如何自定义徽标shields.io 提供了自定义徽标的功能。 徽标图标格式1https://img.shields.io/badge/&#123;徽标标题&#125;-&#123;徽标内容&#125;-&#123;徽标颜色&#125;.svg 带链接的徽标1[![](https://img.shields.io/badge/&#123;徽标标题&#125;-&#123;徽标内容&#125;-&#123;徽标颜色&#125;.svg)](&#123;linkUrl&#125;) 变量说明 徽标标题：徽标左边的文字 徽标内容：徽标右边的文字 徽标颜色：徽标右边的背景颜色，可以是颜色的16进制值，也可以是颜色英文。支持的颜色英文如下： 变量之间用 - 连接。将这3个变量替换为你需要的内容即可生成一个自定义的徽标。 举个栗子例如下面这个是我的博客的徽标：1[![](https://img.shields.io/badge/blog-@champyin-red.svg)](https://champyin.com) 效果：点击该徽标会打开对应的url地址，即直接跳到我的博客。 进阶除了上面所说的3个参数，shields.io 还提供了一些 query string 来控制徽标样式。使用方式跟浏览器 URL 的 query string 一致：徽标图标地址?{参数名}={参数值}，多个参数用 &amp; 连接：1https://img.shields.io/badge/&#123;徽标标题&#125;-&#123;徽标内容&#125;-&#123;徽标颜色&#125;.svg?&#123;参数名1&#125;=&#123;参数值1&#125;&amp;&#123;参数名2&#125;=&#123;参数值2&#125; 常用的 query string 参数有： style：控制徽标主题样式，style的值可以是： plastic | flat | flat-square | social 。 label：用来强制覆盖原有徽标的标题文字。 colorA：控制左半部分背景颜色，只能用16进制颜色值作为参数，不能使用颜色英文。 colorB：控制右半部分背景颜色。 以style参数为例1![](https://img.shields.io/badge/blog-@champyin-orange.svg?style=plastic) plastic 立体效果： 1![](https://img.shields.io/badge/blog-@champyin-yellow.svg?style=flat) flat 扁平化效果，也是默认效果： 1![](https://img.shields.io/badge/blog-@champyin-success.svg?style=flat-square) flat-square 扁平 + 去圆角效果： 1![](https://img.shields.io/badge/blog-@champyin-blue.svg?style=social) social 社交样式效果： 还有很多参数，用法类似。更多信息可以到shields.io查阅。 总结徽标简洁又不失内容，使用简单又不失灵活。如果你的项目还没有使用过徽标，那么不妨试试给你的项目中试试添加一个，你会爱上它。 建议：徽标的使用也是门艺术，徽标不是越多越好。应该根据项目性质合理添加，放的太多会失去徽标的简洁本意。 –GOOD LUCK！ 欢迎转载，转载请注明出处：https://champyin.com/2019/10/05/github%E9%A1%B9%E7%9B%AE%E5%BE%BD%E6%A0%87/]]></content>
      <categories>
        <category>工具</category>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>badge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Travis CI+GitHub实现持续集成和自动部署]]></title>
    <url>%2F2019%2F09%2F27%2F%E5%88%A9%E7%94%A8Travis-CI-GitHub%E5%AE%9E%E7%8E%B0%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E5%92%8C%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[这次的主题是如何利用Travis CI+GitHub实现持续集成和自动部署，通过我的一些研究和实战经验，希望可以帮到有需要的朋友。 如果你手动部署过项目，一定会深感持续集成的必要性，因为手动部署实在又繁琐又耗时又没技术含量，九段部署流程基本固定，依然容易出错。 如果你很熟悉持续集成，一定会同意这样的观点：“使用它已经成为一种标配”。 什么是持续集成Continuous Integration(CI) is a development practice that requires developers to integrate code into a shared repository several times a day. Each check-in is then verified by an automated build, allowing teams to detect problems early.———ThoughtWorks翻译过来就是：持续集成是一个开发行为，它要求开发者每天多次将代码集成到一个共享的仓库，每次提交都会被自动构建所检查，团队可因此提前检测出问题。 持续集成的工具非常多，例如用java语言开发的Jenkins，由于其可以在多台机器上进行分布式地构建和负载测试的特性，很多大公司都在使用它。 但是Jenkins的不加修饰的界面界面让我有些嫌弃… 随着GitHub的发展，出现了越来越多支持GitHub的CI/CD产品。在GitHub市场上，可以看到，已经支持的持续集成服务提供商已超过300多家。详情。选择Travis CI，是因为身边很多朋友的推荐。 什么是Travis CITravis CI是用Ruby语言开发的一个开源的分布式持续集成服务，用于自动构建和测试在GitHub托管的项目。支持包括Javascript、Node.js、Ruby等20多种程序语言。对于开源项目免费提供CI服务。你也可以买他的收费版，享受更多的服务。 Travis CI目前有两个官网，分别是 https://travis-ci.org 和 https://travis-ci.com 。https://travis-ci.org 是旧平台，已经逐渐往新平台 https://travis-ci.com 上迁移了。对于私有仓库的免费自动构建，Travis CI在新平台上给予了支持。 GitHub-&gt;Marketplace-&gt;Apps-&gt;Travis CI 一、获取GitHub Access TokenTravis CI在自动部署的时候，需要push内容到仓库的某个分支，而访问GitHub仓库需要用户授权，授权方式就是用户提供 Access Token 给Travis CI。获取token的位置：GitHub-&gt;Settings-&gt;Developer Settings-&gt;Personal access tokens。勾选repo下的所有项，以及user下的user:email后，生成一个token，复制token值。 注意：这个token只有现在可以看到，再次进入就看不到了，而且是再也看不到了，忘记了就只能重新生成了，所以要记住保管好。 二、使用GitHub账号登录Travis进入Travis官网，用GitHub账号登录。（我目前使用的是它的旧平台） 登录后，会在Travis里看到自己GitHub账号下所有的public open source repo。 三、开启对项目的监控选择目标项目，打开右侧开关。 四、配置travis 点击开关右侧Settings，进入该项目的travis配置页 勾选触发条件 设置全局变量 第一步获取的access token，必须设置设置好的变量可以在配置文件中以 ${变量名}来引用。 五、在项目根目录添加.travis.yml配置文件 注意文件名以.开头。 Travis CI的一次构建分两个步骤： install安装，安装任何所需的依赖 script脚本，运行构建脚本 Travis CI提供了一些构建生命周期的“钩子” 完整的 Travis CI 构建生命周期： OPTIONAL Install apt addons OPTIONAL Install cache components before_install install before_script script OPTIONAL before_cache(for cleaning up cache) after_success or after_failure OPTIONAL before_deploy OPTIONAL deploy OPTIONAL after_deploy after_script 在 before_install、before_script之前，或者after_script之后，都可以运行自定义命令，详细资料可参考官方文档：Job Lifecycle 我在footprint项目中的.travis.yml完整配置：1234567891011121314151617181920212223242526272829303132333435language: node_js #设置语言node_js: &quot;10.16.3&quot; #设置语言版本cache: directories: - node_modules #缓存依赖# S: Build Lifecycleinstall: - npm iscript: - npm run buildafter_script前5句是把部署分支的.git文件夹保护起来，用于保留历史部署的commit日志，否则部署分支永远只有一条commit记录。#命令里面的变量都是在Travis CI里配置过的。after_script: - git clone https://$&#123;GH_REF&#125; .temp - cd .temp - git checkout gh-pages - cd ../ - mv .temp/.git dist - cd dist - git config user.name &quot;$&#123;U_NAME&#125;&quot; - git config user.email &quot;$&#123;U_EMAIL&#125;&quot; - git add . - git commit -m &quot;:construction_worker:- Build &amp; Deploy by Travis CI&quot; - git push --force --quiet &quot;https://$&#123;Travis_Token&#125;@$&#123;GH_REF&#125;&quot; gh-pages:$&#123;D_BRANCH&#125;# E: Build LifeCycle# 只有指定的分支提交时才会运行脚本branches: only: - master Done！将 .travis.yml push 到远程，可以看到 travis 开始构建编译了。并且之后每次push代码，travis 都会自动执行.travis.yml里配置的脚本任务了。 自动编译： 构建完，travis 会根据我的配置，自动部署到 GitHub： And One More Thing构建成功后，我们就可以在自己的GitHub项目里添加build徽章了。方法：在Travis里，点击项目右侧的徽章，即可获取小徽章地址，将地址放在README.md文档中即可。效果： –GOOD LUCK！ 欢迎转载，转载请注明出处：https://champyin.com/2019/09/27/%E5%88%A9%E7%94%A8Travis-CI-GitHub%E5%AE%9E%E7%8E%B0%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E5%92%8C%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/#more]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>travis</tag>
        <tag>CI/CD</tag>
        <tag>yml</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用echarts展示旅行足迹]]></title>
    <url>%2F2019%2F09%2F27%2F%E5%88%A9%E7%94%A8echarts%E5%B1%95%E7%A4%BA%E6%97%85%E8%A1%8C%E8%B6%B3%E8%BF%B9%2F</url>
    <content type="text"><![CDATA[一直有个环游世界的梦，周游列国，体验不同国家的人类文明，寻山访水，体验造物主大自然的伟大造化。毕竟人生不止眼前的苟且，还有诗和远方。这么多年以来，陆续走过了一些地方，每到一个地方，都让我离梦想又近了一些。虽然我知道这比起环游世界来说，还差不知道多少个山头，但是我一直在往这个梦努力，靠近。希望终有一天，我可以笑着对自己说，你做到了！ 6年前，因为工作的原因，我接触过地图应用的开发，从那时起，我对地图的热爱就埋在了心底。今年年中我带爸妈旅了旅游，去了一些我没去过的地方，我好想有个地图可以让我点亮一下，记录一下我到过的新的“领土”。搜了下市面上已经存在的地图应用，都不是我想要的，唯一比较符合我的需求的是百度旅游里面的一个小功能，叫做足迹地图，但是似乎早就停止了维护，数据停留在2016年。。。 找不到趁手的工具，那就自己打造一把。是啊，为什么不自己开发一个呢？说干就干。 工程搭建首先用 cyt-cli 快速搭建项目框架。cyt-cli地址 cyt-cli 是一款可以快速创建前端工程的脚手架，具有比较完善的webpack4配置，目前支持纯js、vue、react等语言版本。如果没有安装 cyt-cli ，先全局安装一下：npm i -g cyt-cli。 123456cyt-cli create footprint✔ fetching template ...? please choose a template to create roject (Use arrow keys)❯ swan-template swan-vue-template swan-react-template 因为想快速做出雏形来，所以使用最简单的模版就行，选择第一个 swan-template。等待一会，工程就搭建好了。生成的工程目录：123456789101112131415161718192021|--build/ # webpack配置文件| |-- webpack.base.js| |-- webpack.dev.js| |-- webpack.prod.js|--public/ # 首页模版| |-- index.html|--src/| |-- assets/ # 静态资源，比如中国地图数据| |-- components/ # 项目组件| | |-- foo.js| | |-- bar.js| |-- icon/ # 字体图标| |-- images/ # 图片资源| |-- theme/ # 样式文件| |-- index.js # 项目入口|--.babel.js # babel配置|--.browserslistrc.json # 浏览器支持规则|--.gitignore |--package.json|--postcss.config.js # postcss插件配置|--README.md 安装一下依赖包。12cd footprintnpm i 地图选型地图展示我选择了 echarts。 echarts官网1npm i --save echarts 应用开发我的核心需求很简单，就是可以把我去过的国家、省、市在地图上展示出来即可。先实现国内的省，开发逻辑很简单： 1.引入echarts按需引用1234567import echarts from &apos;echarts/lib/echarts&apos;;import &apos;echarts/lib/chart/map&apos;;import &apos;echarts/lib/component/tooltip&apos;;import &apos;echarts/lib/component/title&apos;;import &apos;echarts/lib/component/visualMap&apos;;import &apos;echarts/lib/component/legend&apos;;import &apos;echarts/lib/component/toolbox&apos;; 2.处理用户数据给series的data用。123456789101112131415161718192021222324252627282930313233let handleData = function(rawdata) &#123; rowData.forEach(item =&gt; &#123; item.value = FREQUENCY[item.value] if (item.value !== NEVER) &#123; item.label = &#123; show: true, color: LEBEL_COLOR &#125; &#125; if (item.value === NEVER) &#123; never.push(item); &#125; else if (item.value === ONECE) &#123; onece.push(item); &#125; else if (item.value === AFEWTIMES) &#123; afewtimes.push(item); &#125; else &#123; usually.push(item); &#125; &#125;); series = [usually, afewtimes, onece, never].map((item, index) =&gt; &#123; let temp = &#123; type: &apos;map&apos;, map: mapType, roam: true, itemStyle: &#123; emphasis: &#123; label: &#123; show: true &#125; &#125;, areaColor: &apos;#fff&apos; &#125; &#125;; temp.name = legendData[index]; temp.data = item; return temp; &#125;)&#125;handleData(userData); 3.注册mapecharts有个registerMap方法，echarts.registerMap(mapName, geoJson, specialAreas).123- mapName：地图名称，一定要与option-&gt;series-&gt;map对应的值相同。- geoJson：GeoJson格式的数据，具体格式见 http://geojson.org/。- specialAreas：可选。将地图中的部分区域缩放到合适的位置，可以使得整个地图的显示更加好看。 geoJson是地理信息数据，一般都很大，当然通过异步获取。123456util.get(&apos;assets/china.json&apos;).then(data =&gt; &#123; let chinaJson = data; myChart.hideLoading(); // 注册地图 echarts.registerMap(mapName, chinaJson, &#123;&#125;)&#125;) ECharts3提供的矢量地图数据，在4版本后已经不提供下载服务了。官网的解释是“由于部分数据不符合国家《测绘法》规定”。不过，只要不商用，这些矢量数据还是可以使用的。有需要可以到我这里获取https://github.com/yc111/echarts3-geojson 4.配置option显示地图注册地图后进行其他配置123456789101112// 指定图表的配置项和数据let option = &#123; color: _color, title: _title, tooltip: _tooltip, legend: _legend, visualMap: _visualMap, toolbox: _toolbox, series: series&#125;;// 使用刚指定的配置项和数据显示图表myChart.setOption(option); 添加Travis CI持续集成花了大概一天时间，雏形做好（感觉很大一部分时间在调地图颜色…）。我把项目部署在了github page上，但是每次build之后，都要手动部署，太麻烦。 于是我用 Travis CI 给项目做了持续集成，现在只要代码一提交，就会自动部署了。 具体关于Travis的详细配置，可以参考我的另一篇文章：利用Travis CI+GitHub实现持续集成和自动部署 效果预览项目预览地址：http://champyin.com/footprint/暂时还比较简陋，并且只支持省。以后我会把世界地图，和城市地图都加进来（毕竟也是出过境的人，哈哈），实现地图下钻，并且优化用户数据设置，不断完善下去。 项目源码地址：https://github.com/yc111/footprint欢迎star。如果你喜欢，可以fork本项目，然后打造属于你自己的足迹应用。 –欢迎转载，转载请注明出处：https://champyin.com/2019/09/27/%E5%88%A9%E7%94%A8echarts%E5%B1%95%E7%A4%BA%E6%97%85%E8%A1%8C%E8%B6%B3%E8%BF%B9/ 本文同步发表于：利用echarts展示旅行足迹 | 掘金]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>echarts</tag>
        <tag>map</tag>
        <tag>footprint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode 常用快捷键]]></title>
    <url>%2F2019%2F09%2F21%2Fvscode-%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[基于当前项目路径打开外部终端(MAC中)1shift + command + c 查看vscode快捷键的方法： 在vscode中shift+command+p打开vscode命令行，输入keyboard搜索： 在结果中点击 Preferences: Open Keyboard Shortcuts： 可以搜索指定的关键字搜索，例如输入terminal搜索：]]></content>
      <categories>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode中如何使编辑器根据屏幕宽度自动换行]]></title>
    <url>%2F2019%2F09%2F20%2Fvscode%E4%B8%AD%E5%A6%82%E4%BD%95%E4%BD%BF%E7%BC%96%E8%BE%91%E5%99%A8%E6%A0%B9%E6%8D%AE%E5%B1%8F%E5%B9%95%E5%AE%BD%E5%BA%A6%E8%87%AA%E5%8A%A8%E6%8D%A2%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[vscode中默认是不会自动换行的，也就是说当你查看一个压缩后的代码后，只会显示一行。。。很难看出内容的多少也不利于查找定位内容。 在vscode中可以设置是否自动换行，进入：1Code -&gt; Preference -&gt; Settings 然后在配置界面，搜索 word-wrap，找到 Editor: Word Wrap 选项： 将off改成on即可。 –GoodLuck!]]></content>
      <categories>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何配置多个ssh key]]></title>
    <url>%2F2019%2F08%2F29%2F%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAssh-key%2F</url>
    <content type="text"><![CDATA[我们都知道在使用git管理代码时，要推送代码到远程仓库时，为了不想每次都输入账号密码，会配置一下ssh key。但是如果你有多个github账号，或者同时还有gitlab或者是gitee账号，我在推送到这三个账号的仓库都不想输入用户名密码，可不可以把github上使用的ssh key跟其他的账号共享呢？我没有这样试过，不过即便是可以，也不太安全吧。最好的做法就是为这些账号分别创建ssh key，分别配置。 配置单个SSH key，可以参考：配置git环境之设置SSH key。而配置多个SSH key未必都熟悉。其实方法也很简单： 1. 生成ssh key第一个，给github用1ssh-keygen -t rsa -C &apos;xxx@abc.com&apos; -f ~/.ssh/github_id_rsa 第二个，给gitee用1ssh-keygen -t rsa -C &apos;xxx@edf.com&apos; -f ~/.ssh/gitee_id_rsa 由于指定了文件名，可以一路回车，不用输入密码。然后～/.ssh目录下会出现4个文件：1234github_id_rsagithub_id_rsa.pubgitee_id_rsagitee_id_rsa.pub 2. 在～/.ssh 目录下创建config文件。打开～/.ssh目录1open ~/.ssh 编辑config文件，写入：1234567891011# githubHost github.com # host名字可以随意，自己能识别就好，我这里直接使用了网站域名HostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/github_id_rsa# giteeHost my.gitee.comHostName gitee.comPreferredAuthentications publickeyIdentityFile ~/.ssh/gitee_id_rsa 3. 将为不同账号生成的公钥，填入各自网站的ssh key配置中。可以通过cat查看公钥内容1cat ~/.ssh/github_id_rsa.pub 4. 检测配置成没成功检测方法：ssh -T git@Host, Host 就是你之前在config文件中配置的Host 的值。检测github的1ssh -T git@github.com 检测gitee的1ssh -T git@my.gitee.com 如果有提示问要不要把这个RSA host key 添加到 konwn_host 列表中，选择yes。最后如果看到类似如下的提示，说明配置成功：1Hi xxxx! You&apos;ve successfully authenticated,but...... access. 搞定！ 科普：SSH：Secure Shell，是建立在应用层基础上的安全协议。github要求推送代码的用户是合法的，所以每次推送都需要输入账号和密码，用于验证你是否为合法用户，为了省去每次都要输入密码的步骤，采用ssh公钥秘钥，也就是ssh key来验证，公钥放到github上，推送代码时，git会检测你本地的私钥是否跟github上的公钥配对。ssh key可以理解为你的身份标识，公钥放在github上表明你是这个项目的一个开发人员，公钥匙可以被截获的，但是私钥在本地别人就无法截获，ssh key可以保证每次传输都是安全的。 Have a nice day!]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm link详解]]></title>
    <url>%2F2019%2F08%2F27%2Fnpm-link%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[npm install 可以把发布在 npmjs 平台上的模块包下载到本地，npm install -g 可以把包下下来的同时，还帮我们配置好全局变量，让我们可以直接使用命令而不是通过 node 来执行或者配置 package.json 的 script 脚本来 run。 但这仅限于已经发布的包，那对于未发布的包，要怎么测试使用呢？难道要把一个未经测试的包发布上去然后 install 下来测试？当然不能这么做，也不用这么做。npm 官方早已考虑到了这一点，给我们提供了测试本地的包的工具指令：npm link。 npm link原理npm link 可以帮助我们模拟包安装后的状态，它会在系统中做一个快捷方式映射，让本地的包就好像install过一样，可以直接使用。 在mac中，我们在终端可以直接敲的命令，其实是在执行/usr/local/bin目录下的脚本，这个目录可以认为是我们的全局命令所在的地方。 而当我们在npm install -g的时候，其实是将相关文件安装在/usr/local/lib/node_modules目录下，同时在全局命令/usr/local/bin目录下会有一个映射脚本，将其指向/usr/local/lib下的真实文件。这么做的好处是，可以在保证只有一份可执行文件的前提下，给命令取别名。 同样的，npm link 做的事情也是一样，唯一的区别是，它在 /usr/local/lib 下的 node_modules 里不是存的真实的文件，而是存了一个快捷方式，指向你当前执行 npm link 的目录。如果开发的的是node包，则执行的命令名和真实执行的文件入口，会根据项目的 package.json 里 bin 的配置来获取。 如何使用12cd your-project-dirnpm link 然后会看到输出类似如下的链接信息，说明成功。12/usr/local/bin/yourpakagename -&gt; /usr/local/lib/node_modules/yourpackagename/xxx/usr/local/lib/node_modules/yourpackagename/xxx -&gt; /Users/username/Documents/xxx(your real project path) 全局link测试 node 环境下运行的包时，需要使用全局 link​。​并且做npm link之前，需要在 package.json 里配置 bin 字段。1234# package.json&quot;bin&quot; : &#123; &quot;your-command-name&quot;: &quot;./path-to/your-command-entry-file&quot;&#125; 然后再在当前目录下进行link12cd your-command-modulenpm link 成功后，就可以直接在终端执行全局命令 your-command-name 了。 link到项目如果是测试前端包，跑在浏览器环境的，比如 UI 组件库，有两种情况： 当项目和模块在同一个目录下，可以使用相对路径，只需要link一次 1npm link ../xx-module 当项目和模块不在同一个目录下，那需要做两次 link。先进入待测试组件库目录，将组件库 link 到全局： 12cd your-ui-libnpm link 之后，再进入要使用该组件库的工程，然后在工程中 link 这个组件库： 12cd your-projectnpm link your-ui-lib 现在你就可以在你的工程中使用这个 ui 组件库，就好像这个 ui 库被 install 到工程中一样。 解除link 解除模块全局link进入模块目录，然后执行unlink 12cd your-command-modulenpm unlink your-command-module 解除项目和模块link进入项目目录，然后执行unlink 12cd your-projectnpm unlink your-ui-lib GoodLuck！]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在mac中管理和随时切换node版本]]></title>
    <url>%2F2019%2F08%2F26%2F%E5%A6%82%E4%BD%95%E5%9C%A8mac%E4%B8%AD%E7%AE%A1%E7%90%86%E5%92%8C%E9%9A%8F%E6%97%B6%E5%88%87%E6%8D%A2node%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[之前用windows的电脑的时候，曾使用 nvm-windows 工具来管理开发环境中的node版本。快速在各个版本的node环境中切换的体验非常好。而在mac中，由于开发环境比较稳定，则没有使用这类工具来管理。近期由于项目的需要，有了在mac下频繁切换node版本的需求。才有了这篇文章。 工具选择我根据第一直觉，在npm上搜索 nvm，竟没有 nvm 的精确匹配，搜索结果第一位是一个叫 n 的包，点进去，也没个README说明（其实是当时我的网络不好README没有加载出来…）。(说实话，要不是发现它的作者是tj大神，我后来可能不会再次点开它，可能我就错过了一个非常好的工具。） 诧异过后，我转到github，搜索 nvm。 找是找到了，然而，它的安装方式，让我觉得不太友好：1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash 为什么nvm没有pacakge版？不如看看那个”连README都没有”的 n 是否能用。我点开了 n 的github页面。详细的使用说明映入眼帘，粗略读了一遍，感觉有戏。仔细操作一遍，这感觉，怎么说呢，这是捡到宝了呀！ 就它了！ n！ 如何使用 n 管理mac上的node版本 1. 安装1npm install -g n 2. 修改几个本地目录的拥有者因为node环境是全局的，需要安装到系统目录下，涉及目录有 /usr/local/bin、usr/local/lib、/usr/local/include、/usr/local/share，这几个目录的拥者是root，其他用户没有权限操作他们。如下命令可以将他们的拥有者从root改为当前用户：1sudo chown -R $(whoami) /usr/local/bin /usr/local/lib /usr/local/include /usr/local/share 另外，n 会在系统目录下创建一个目录，也需要修改下它的拥有者：1sudo chown -R $(whoami) /usr/local/n 关于 chown 命令，我的另一篇文章有详细说明： 如何修改mac中文件夹和文件的拥有者 3. 安装指定版本的node123n 10.16.3 //下载并安装node 10.16.3n latest //下载并安装node 最新版本n lts //下载并安装node 长期稳定维护版 4. 切换node版本1234567n //列出所有缓存的node版本 node/4.4.4 ο node/8.11.1 node/10.16.3Use up/down arrow keys to select a version, return key to install, q to quit-&gt; 上下键选择当前需要的版本，回车-&gt; done 用 node -v 查看版本是否生效。 5. 删除node版本123456//删除指定版本n rm xxx//删除当前版本外的所有版本n prune//卸载当前已安装的noden uninstall 6. 其他命令1n ls //查看已下载的node版本列表 补充 n 的获取node的源路径为node官网https://nodejs.org/dist/，在国内访问，非常慢，经常由于太慢而发生超时错误导致下载失败。解决方案：修改node镜像源。1export N_NODE_DOWNLOAD_MIRROR=https://npm.taobao.org/mirrors/node 将node镜像指向淘宝镜像。再来操作 n 命令，是不是速度嗖嗖的了。 GOOD LUCK！ 参考：n （npm）：https://www.npmjs.com/package/nn （github）：https://github.com/tj/nnvm ：https://github.com/nvm-sh/nvmnvm-window ：https://github.com/coreybutler/nvm-windows]]></content>
      <categories>
        <category>工具</category>
        <category>Intergration</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>node</tag>
        <tag>n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何修改mac中文件夹和文件的拥有者]]></title>
    <url>%2F2019%2F08%2F26%2F%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9mac%E4%B8%AD%E6%96%87%E4%BB%B6%E5%A4%B9%E5%92%8C%E6%96%87%E4%BB%B6%E7%9A%84%E6%8B%A5%E6%9C%89%E8%80%85%2F</url>
    <content type="text"><![CDATA[在mac上开发，涉及在系统目录（指操作系统自带的那些目录，比如／、 ／usr、 ／usr／local／bin 等）创建文件夹或者文件时，会出现由于权限不足导致创建失败的问题。这是由于，这些目录属于 root 用户， 而当前登录mac的一般都是非root用户，而非root用户没有权限修改root用户直接管辖的目录和文件。那么如何让用户拥有这些目录的修改权限呢？ 解决办法有两个： 方法一：改成使用root登录，这样就具有对操作系统的最大权限，可以为所欲为。但是，不推荐这么做，因为太危险。 方法二：将你要操作的目录的权限从root手里夺过来，也即修改目录的拥有者。推荐。 如何修改目录的拥有者使用linux命令 chown 。 命令格式：1chown [选项] 所有者[:组] 文件 chown 将指定文件的拥有者改为指定的用户或者用户组，用户可以是用户名或者用户ID，组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用 chown 命令，在将文件拷贝到另一个用户的目录下后，让用户拥有使用该文件的权限。 实例： 把 ／usr/local/bin 和 ／usr/local/lib 这两个目录以及其子目录的拥有者从root改成当前用户：1sudo chown -R $(whoami) /usr/local/bin ／usr/local/lib 说明： chown change owner 的缩写。 $(whoami) who am i ，获取当前的用户。 -R –recursive 的缩写，递归处理，将指定目录和所有子目录一并处理。 执行完命令，可以用 ls -l 来查看一下是否修改成功。 常用选项列表：必要参数 -c ：–changes 的缩写，当发生改变时输出调试信息，仅显示更改部分的信息 -f ：不显示错误信息，忽略错误信息 -h ：修复符号链接 -R ：–recursive 的缩写, 递归处理，将指定目录以及其子目录下的所有文件一并处理 -v ：–verbose 的缩写, 显示指令执行过程的详细的处理信息选择参数 --help ：显示帮助信息 --version ：显示版本信息]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iphone AirDrop 无法发现mac的解决办法]]></title>
    <url>%2F2019%2F08%2F13%2Fiphone-AirDrop-%E6%97%A0%E6%B3%95%E5%8F%91%E7%8E%B0mac%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前几天想把手机上的照片传到mac上，发现在AirDrop里看不到我的mac了。以为是电脑太久没重启抽了，因为以前是可以找到的。于是重启了mac，结果没用。后来求助网络，才终于搞定。在此记下方法，以备以后遇到同样的问题又忘记怎么处理。 第一步先确保手机（iPhone）上的蓝牙打开，AirDrop 开启，并对所有人可见。 第二步确保 mac 上 AirDrop 开启。具体操作：打开 Finder 中的 AirDrop ，并设置成 所有人可见。不过此时手机上的 AirDrop 仍然看不到 mac。 第三步确保 mac 上蓝牙开启。具体操作：打开 设置 -&gt; 蓝牙 -&gt; 打开蓝牙。 第四步 （关键） mac 和 iPhone 蓝牙配对。具体操作：在 mac 的蓝牙设置界面，应该可以看到你的 iPhone 了。点击这个 iPhone 旁边的 配对 按钮。然后手机会收到一个配对请求，点接受。等待一会，就会配对成功。 PS：如果第四部看到手机已经是配对状态，则移除后重新配对。 这时，在mac和iPhone的AirDrop中就可以互相看见彼此了，然后就可以愉快地互传文件了。 Have a nice day!]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>iphone</tag>
        <tag>mac</tag>
        <tag>airdrop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(五)：给文章添加字数统计、阅读时长]]></title>
    <url>%2F2019%2F02%2F25%2F%E8%BF%9B%E9%98%B6-%E4%BA%94-%EF%BC%9A%E7%BB%99%E6%96%87%E7%AB%A0%E6%B7%BB%E5%8A%A0%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E3%80%81%E9%98%85%E8%AF%BB%E6%97%B6%E9%95%BF%2F</url>
    <content type="text"><![CDATA[继续倒腾个站。今天看到别人的花里胡哨的博客，手又痒了。之前我可是对自己的极简风“守身如玉”，不愿意在个站添加一点点多余的信息。今天居然有一点点动摇了，那就神不知鬼不觉地添加一点统计信息吧，这都是为了用户体验好（天音：想加东西就加，这么多借口干啥？）我：[抠鼻] 只需三步： Step1: 安装插件需要安装 hexo-wordcount 插件。它可以统计文章字数，估算阅读时长，以及统计整个网站的总字数。在命令行进入blog根目录，然后：1npm i --save hexo-wordcount Step2: 修改主题配置进入 themes/next/ 目录，打开 _config.yml ，找到 post_wordcount 字段，将wordcont、min2read、totalcount 三个属性都设为 true ：123456post_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true Step3: 重启hexo给hexo项目安装新的插件，以及修改一些配置，需要重启hexo才能看到效果。我们重新 hexo s 启动一下hexo，再刷新本地预览界面，现在你可以看到： 在每个标题下面增加了文章字数（Words count in article） 和 阅读时长（Reading time） 两组统计项； 在网站页脚增加了所有文章字数统计数据（Site words total count）。 –NICE～]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[添加chrome扩展程序技巧]]></title>
    <url>%2F2019%2F01%2F29%2F%E6%B7%BB%E5%8A%A0chrome%E6%89%A9%E5%B1%95%E7%A8%8B%E5%BA%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[我们给chrome 浏览器添加扩展程序，有时会遭到 chrome 的限制，比如只能通过 chrome 商城添加，而 chrome 商城需要墙外的环境，大多数时候不一定当前电脑可以翻墙。那么就需要一些技巧来添加这些扩展程序。 方法一 在扩展程序界面，打开开发者模式。 然后将下载好的 .crx 扩展程序文件拖拽到插件管理界面。 该方法通常是可行的，不过也有的时候赶上某些 chrome 版本，不允许拖拽安装。那么可以尝试第方法2： 方法二 首先将下载好的 .crx 扩展程序文件修改后缀为 .rar，然后解压它，在解压的文件夹内，找到 _metadata 文件夹，将下划线去掉，改为 metadata。 然后在 chrome 插件管理界面，打开开发者模式，点击 ‘加载已解压的扩展程序’，选择刚才解压并修改后的文件夹，确定，即可。]]></content>
      <categories>
        <category>浏览器</category>
      </categories>
      <tags>
        <tag>chrome</tag>
        <tag>browser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何创建空白git分支]]></title>
    <url>%2F2019%2F01%2F29%2F%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E7%A9%BA%E7%99%BDgit%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[在管理前端代码工程时，有时需要创建一个干净的分支，比如用于放文档，或者全新的版本分支。但是普通的创建分支命令，会将历史日志带过去。那么对于有代码洁癖和强迫症的人（比如我）来说，是不能忍的。强大的git为我们这些人准备了创建空白git分支的方法。掌握后受用无穷。 步骤： 1. 创建无父节点的分支1git checkout --orphan orphanbranch 参数 orphan 的作用有两个： 1.拷贝当前所在分支的所有文件。 2.让这个新的分支没有父节点。这意味着这个分支不会有任何历史记录。 2. 删除该分支下所有文件orphan 会把之前分支中的文件都拷贝过来，这些文件我不想要，因为我要一个完全空白的干净分支。可以用git rm删除一下。1git rm -rf . 不用担心在log里留下delete日志，因为严格来讲，我们的分支还没完全创建好（还差一步），此时的操作并不会影响历史记录。 3. 创建一个初始文件，比如readme，并提交现在试着查看下当前分支： 会发现，并没有看到我们创建的 orphanbranch。因为还差一步，我们必须对这个分支进行一次初始提交，才可以看到它。123touch README.mdgit add .git commit -m &quot;add readme&quot; 4. 一个干净的空白分支诞生现在git branch -a可以看到这个分支了。用git log查看一下这条分支的日志，可以看到，只有一条添加readme的记录。此时，一个空白分支就创建成功了。12git branch -agit log --oneline Good luck！]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(四)：给博客添加站内搜索功能]]></title>
    <url>%2F2019%2F01%2F26%2F%E8%BF%9B%E9%98%B6-%E5%9B%9B-%EF%BC%9A%E7%BB%99%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[不知不觉坚持写博客已经快一年了，博客文章破50，虽然平均每个月4到5篇不算什么，但是对于平时一心扑到工作简直没有时间生活的我来说，已经很不容易了。虽然文章可能没有高大上的标题，也没有涉及太多前沿的技术，但是起码我记录下了我的一些小经验，累积了自己的一个小知识库。其实我还有很多内容没来及的记录，希望以后能通过博客沉淀更多的知识，同时帮助到更多的人。 言归正传，文章一多，有时自己想翻查一个内容，要找好久，要是有站内查找功能就好了。于是仔细查阅了工程yml配置，果然发现在theme下的_config.yml有个local_search配置项，满心欢心把它设为true。结果搜索图标是出来了，但是点击后除了在页面加了一个全局loading就什么都没有了。看来还需要额外的操作。百度了一番，原来hexo提供了的search插件，需要手动安装才可以使用站内搜索。 3步搞定： 1.安装两个插件1npm i --save hexo-generator-search hexo-generator-searchdb 2.配置hexo主配置文件（位于工程根目录下）_config.yml在最后面追加这段，注意2个空格的缩进，这个是yml缩进语法，不能随意。123456# local_searchsearch: path: search.xml field: post format: html limit: 10000 3.配置hexo主题下的配置文件（位于theme-&gt;next下）_config.yml 将enable设为true。这一步我在一开始就已经做过了～ 1234567local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 重新hexo g, hexo s，刷新页面，点击搜索图标，就可以看到搜索弹出框了，输入关键字，可以看到匹配到文章。 GOOD LUCK! 参考资料：https://www.jianshu.com/p/519b45730824https://github.com/wzpan/hexo-generator-searchhttps://www.npmjs.com/package/hexo-generator-searchdb]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm install 高级]]></title>
    <url>%2F2019%2F01%2F09%2Fnpm-install-%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[npm install npm install –production npm install –only=prod npm install –only=dev]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git clone 高级]]></title>
    <url>%2F2019%2F01%2F09%2Fgit-clone-%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[自定义克隆下来的目录名克隆仓库的命令格式是 git clone [url]这个命令会将远程仓库的名字作为你的本地仓库（即项目根目录）的名字。如果你想自己命名本地仓库的名字可以使用这个命令：git clone [url] yourprojectname 克隆指定分支如果远程仓库不做设置，默认 git clone 克隆下来的是项目的 master 分支。如果想要获取非 master 分支，可以使用命令指定分支： git clone -b branchname [url]比如我要克隆 zrender 项目的 dev 分支：1git clone -b dev https://github.com/ecomfe/zrender]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github和gitlab上的md文档支持相对路径的链接了]]></title>
    <url>%2F2019%2F01%2F09%2Fgithub%E5%92%8Cgitlab%E4%B8%8A%E7%9A%84md%E6%96%87%E6%A1%A3%E6%94%AF%E6%8C%81%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E9%93%BE%E6%8E%A5%E4%BA%86%2F</url>
    <content type="text"><![CDATA[markdown 格式语法中，链接的格式是：1[链接文字](链接地址) 之前写链接，用 http 协议 url 居多，最近遇到在项目的 README 中要添加另一个文档的链接，由于当前在 dev 分支，如果写分支的仓库 url 路径，那到时候 dev 分支合并到其他分支后，dev 分支被删除后，这个地址岂不是有问题了。如果能用相对路径就好了。 查了下，居然在 gitlab 上是支持的，在 github 上最近也支持了，真是喜讯。说到喜讯，昨天 github 官网宣布开放免费的 private repository ，也是2019喜讯一桩。 相对路径使用举例如果你的项目结构如下： 12345678project/ text.md subpro/ subtext.md subsubpro/ subsubtext.md subsubpro2/ subsubtext2.md 那么在 text.md 中链接到 subtext.md 的相对链接这么写：1[this subtext](subpro/subtext.md) 在 text.md 中链接到 subsubtext.me 的相对链接这么写：1[this subsubtext](subpro/subsubpro/subsubprotext.md) 在 subsubtext.md 中链接到 text.md 的相对链接这么写：1[this text](../../text.md)]]></content>
      <categories>
        <category>工具</category>
        <category>Intergration</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows批处理常用命令]]></title>
    <url>%2F2018%2F12%2F20%2Fwindows%E6%89%B9%E5%A4%84%E7%90%86%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前阵子在倒腾服务器的时候，需要些一些 windows 批处理来执行任务。就稍微研究了一下。 一、 基本信息 批处理文件扩展名为 .bat 或者 .cmd。区别：cmd 文件只能在 windows2000 以上的系统才能运行，bat 文件则没有这个限制。 这个文件的每一行都是一条 DOS 命令。 可以使用任何文本编辑器创建和修改。 批处理是一种简单的程序，可以用 if 和 go 来控制流程，也可以使用 for 循环。 批处理的编程能力远不如 C语言等编程语言，也十分不规范。 每个编写好的批处理文件都相当于一个 DOS 的外部命令，把它锁在的目录放到 DOS 搜索路径（path）中，即可在任意位置运行。 C:\AUTOEXEC.BAT 是每次系统启动时都会自动运行的，可以将每次启动时都要运行的命令放入该文件中。 大小写不敏感 在命令提示下键入批处理文件的名称，或者双击该批处理文件，系统会调用cmd.exe来运行该文件。 二、 参数 系统参数 1234567891011121314%SystemRoot% === C:\WINDOWS (%windir% 同样)%ProgramFiles% === C:\Program Files%USERPROFILE% === C:\Documents and Settings\Administrator (子目录有“桌面”,“开始菜单”,“收藏夹”等)%APPDATA% === C:\Documents and Settings\Administrator\Application Data%TEMP% === C:\DOCUME~1\ADMINI~1\LOCALS~1\Temp (%TEM% 同样)%APPDATA% === C:\Documents and Settings\Administrator\Application Data%OS% === Windows_NT (系统)%Path% === %SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem (原本的设置)%HOMEDRIVE% === C: (系统盘)%HOMEPATH% === \Documents and Settings\Administrator:: 枚举当前的环境变量setlocal enabledelayedexpansionFOR /F &quot;usebackq delims==&quot; %%i IN (`set`) DO @echo %%i !%%i! 给批处理文件传递参数 12345678910%[1-9]表示参数，参数是指在运行批处理文件时在文件名后加的以空格(或者Tab)分隔的字符串。变量可以从%0到%9，%0表示批处理命令本身，其它参数字符串用 %1 到 %9 顺序表示。Sample：call test2.bat &quot;hello&quot; &quot;haha&quot; (执行同目录下的“test2.bat”文件，并输入两个参数)在“test2.bat”文件里写:echo %1 (打印: &quot;hello&quot;)echo %2 (打印: &quot;haha&quot;)echo %0 (打印: test2.bat)echo %19 (打印: &quot;hello&quot;9) 三、 基本命令setmdechoshutdowmpause符号：&gt; 传递并覆盖&gt;&gt; 传递并追加:: 注释 找到一个比较清晰比较全的一个文档，在这里 四、 例子重启的批处理1shutdown -r -f -t 0 r: 关闭并重启计算机。f: 强制关闭正在运行的应用程序，不在前台警告用户。t xxx: 设置关闭的超时事件为 xxx 秒。有效范围时0-315360000（10年），默认值为30. 在重启前，将重启时间写入日志(以下已在英文版windows操作系统上检测过)restart.bat12345678@echo offset nowdate=%date:~4, 10%set nowtime=%time:~0,8%set content=%nowdate:/=-% %nowtime%set distpath=&quot;c:\restartlog&quot;::write logecho restart time: %content% &gt;&gt; %distpath%\log.txtshutdown -r -f -t 0 再在windows的计划任务中，将这个脚本配置进去。则当脚本执行，将会在系统的c盘下新建一个目录restartlog，然后在这个目录中创建一个文件log.txt，并在文件中追加写入： “restart time： 当时的时间”，最后重启系统。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>windows</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git如何撤销commit并保留修改]]></title>
    <url>%2F2018%2F11%2F27%2Fgit%E5%A6%82%E4%BD%95%E6%92%A4%E9%94%80commit%E5%B9%B6%E4%BF%9D%E7%95%99%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[有时 commit 代码的时候，手误或者眼花误将不应该这次提交的文件 commit 了，此时还没有 push 到远程仓库，这个时候可以通过 git 命令，撤销该次 commit，并且本地修改还在，即回到 commit 之前的状态，可以重新选择文件进行提交。 1git reset --soft [commit_id] 这个 commit_id 可以是历史记录中任一一个，这个命令会让你的代码回到该条 commit 之后的状态，所有的修改都会在，log 中的该条之后的 commit 记录就都删除了。所以也要谨慎使用，一般用于撤销上一次的 commit。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何更改git clone默认检出的分支]]></title>
    <url>%2F2018%2F11%2F26%2F%E5%A6%82%E4%BD%95%E6%9B%B4%E6%94%B9git-clone%E9%BB%98%E8%AE%A4%E6%A3%80%E5%87%BA%E7%9A%84%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[一般我们 clone 一个项目都是检出默认的 master 分支。这个其实是可以修改的。 修改办法：在 git 服务器上，进入该项目的 .git （仓库）文件夹，编辑 HEAD 文件。 例如想默认为 dev 分支：将 refs/heads/master 改成 refs／heads/dev 该操作需要 git 管理员来完成，修改本地仓库没有用。 在 gitlab 或者 github 的仓库配置中，可以找到，有个默认分支下拉选项，就是做这个设置的。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js如何识别图片加载失败]]></title>
    <url>%2F2018%2F11%2F26%2Fjs%E5%A6%82%E4%BD%95%E8%AF%86%E5%88%AB%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[在做项目过程中遇到图片请求失败的时候，图片区域会出现一个原生的碎片图标，非常影响用户体验。这时需要用一个 broken 的图片去代替它，来提升户体验。要做到这一点，首先要在代码中识别图片加载失败这个事情。那么怎么判断一个图片加载失败了呢？ 在 js 中使用 onerror 事件javascript 给我们提供了一个 onerror 事件，img 标签支持该事件，当装载文档或者图像的过程中发生了错误，就会触发 onerror 事件。我们可以在这个事件中，定义要替换加载不出来的原图的 broken 图片。 核心代码： 1234567// html&lt;img src=&quot;img.png&quot; onerror=&quot;myfunction()&quot;&gt;// javascriptmyfunction() &#123; this.src=&quot;default.png&quot;&#125; 注意：如果 onerror 指定的图片也不存在的话，会出现无限死循环 404. 解决办法是在 js 中添加：12345// javascriptmyfunction() &#123; this.src=&quot;./default.png&quot;; this.onerror = null; // 添加这个防止默认图片也不存在而陷入死循环&#125; 在 Vue 中怎么使用 onerror12345678910111213// vue&lt;template&gt; &lt;img :src=&quot;item.imgUrl&quot; :onerror=&quot;defaultImg&quot;&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data () &#123; return &#123; defaultImg: &apos;this.src=&quot;./static/images/default.png&quot;&apos; &#125; &#125; &#125;&lt;/script&gt; 番外有时因为网络比较卡的原因需要多加载几次再判定为是否加载失败。但是有时是因为网络连接断开而加载失败，需要在网络恢复连接时自动加载图片。这是就需要知道，js中怎么识别网络断开和连接的，有两个事件：online 和 offline。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152var isOnLine = true;var eventList = &#123;&#125;;window.addEventListener(&apos;offline&apos;, function() &#123; isOnLine = false;&#125;)window.addEventListener(&apos;online&apos;, function() &#123; if(!isOnline) &#123; isOnLine = true; reLine(); // 执行重连后要做的事情 &#125;&#125;)function reLine() &#123; for(var key in eventList) &#123; if(!eventList[key]) continue; var arg = eventList[key].arg; var thisOnFn = eventList[key].that; eventList[key].fun.apply(thisOnFn, arg); eventList[key] = null; &#125;&#125;function offLined(fun, arg, that) &#123; if(!isOnLine) &#123; var name = fun.name || &apos;__new&apos;; eventList[name] = &#123;&#125;; eventList[name].fun = fun; eventList[name].arg = [].slice.call(arg); eventList[name].that = that; return true; &#125; return false;&#125;---// 重新定义myfunctionmyfunction(imgObj, imgSrc, maxErrorNum) &#123; if(offLined(restImgUrl, arguments, this)) return; if(maxErrorNum &gt; 0) &#123; imgObj.onerror = function () &#123; myFunction(imgObj, imgSrc, maxErrorNum - 1) &#125; setTimeout(function() &#123; imgObj.src = imgSrc; &#125;, 500) &#125; else &#123; imgObj.src = &apos;./default.png&apos;; this.onerror = null; &#125; &#125;// 调用&lt;img src=&quot;img.png&quot; onerror=&quot;myfunction(this, this.src, 3)&quot;&gt;]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js如何获取网页元素的绝对位置]]></title>
    <url>%2F2018%2F11%2F25%2Fjs%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E5%85%83%E7%B4%A0%E7%9A%84%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[什么是网页元素的绝对位置和相对位置网页元素的绝对位置，是指该元素的左上角相对于整张网页的左上角的坐标。网页元素的相对位置，是指该元素的左上角相对于视口的左上角的坐标。 如何获取绝对位置 由于每个元素都有 offsetTop 和 offsetLeft 属性， 表示该元素左上角与父容器（offsetParent对象）左上角的距离。所以可以遍历一下元素的祖先容器，把所有的 offsetTop 加起来得到。1234567var element = document.getElementById(&apos;article_container&apos;)var actualTop = element.offsetTop; // 绝对位置var current = element.offsetParent;while (current !== null)&#123; actualTop += current.offsetTop; current = current.offsetParent;&#125; 如何获取相对位置有了绝对位置，获得相对位置就容易了，可以通过绝对坐标减去页面滚动条滚动的距离来得到。滚动条滚动的垂直距离，是 document 对象的 scrollTop 属性，滚动的水平距离，是 document 对象的 scrollLeft 属性。scrollTop 和 scrollLeft 是可以赋值的，并且会立即自动滚动网页到相应位置。可以利用它们改变元素的相对位置。另外，elment.scrollIntoView() 方法也有类似作用，可以使网页元素出现在浏览器窗口的左上角（不过需要在支持 html5 的浏览器才能生效）。12var elementScrollTop = document.documentElement.scrollTop; var relativeTop = actualTop-elementScrollTop; // 相对位置 快速获取元素的绝对位置和相对位置使用 js 的 getBoundingClientRect() 方法。她会返回一个对象，包含 left， right， top， bottom 四个属性，分别对应该元素的左上角和右下角相对于浏览器窗口（viewport）左上角的距离。12345678var dom = document.getElementById(&apos;article_container&apos;);// 相对位置var rLeft = dom.getBoundingClientRect().left;var rTop = dom.getBoundingClientRect().top;// 绝对位置（相对位置+滚动距离）var aLeft = rLeft + document.documentElement.scrollLeft;var aTop = rTop + document.documentElement.scrollTop;]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacBook 常用快捷键]]></title>
    <url>%2F2018%2F11%2F25%2FMacBook-%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[1. 新建一个 Tab 样式的终端窗口1Command + T 2. 自带的截图快捷键1234Command + Shift + 3 截取整个屏幕，保存图片在桌面Command + Shift + 4 选取部分屏幕区域，保存图片在桌面先Command + Shift + 4 再空格， 可以对指定的窗口或者菜单截屏以上快捷键，加上 Control， 可以把截图保存在剪切板 3. 锁屏1Command + Control + q 4. 呼出 Emoji 键盘1Command + Control + 空格 其他1234567option + command + f 进入全屏模式command + delete 删除至行首option + delete 删除一个单词command + o 打开文件 command + ↑ 上级目录command + 空格: 打开Spotlight（本地搜索引擎）option + command + esc 打开强制关闭控制面板（很有用）fn + F11 显示桌面]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>MacBook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git log高级使用]]></title>
    <url>%2F2018%2F11%2F24%2Fgit-log%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[git log 是我们经常使用的git命令之一，它可以展示分支上的历史提交信息。但是除了 git log 这一个命令，其实它还为我们提供了很多辅助的参数来从不同维度展示我们需要的日志信息，包括展示格式、只看某个分支的日志，只看某个用户提交的日志，只看某个文件上的提交等等，有的时候，这些方法可以帮助我们快速地定位问题。 git log 选项 选项 说明 举例 -n 查看最近n次的提交信息 git log -2 #查看最近2次提交记录 -p 查看具体的修改diff git log -p src/index.js #显示某个文件每次提交的diff；git log -p commit-id #显示某次提交的diff –stat 查看提交的修改文件列表 git log -2 –stat #查看最近两次提交的修改文件列表表 –shortstat 只显示 –stat 中最后的行数和修改添加移除的统计 –filename 查看指定文件的提交信息，文件名要放到参数的最后位置，通常在前面加上 -- 并用空格隔开表示是文件。 git log – file1 file2 branchname 查看某个分支上的提交记录 git log dev tagName 查询指定标签的提交记录 git log v1.0.. #查询从v1.0以后的提交历史记录(不包含v1.0) –grep 仅显示含指定关键字的提交 –S 仅展示添加或者移除了某个关键字的提交 –author 查询指定作者的提交记录 git log –author=sam –commiter 查询指定提交者的提交记录 git log –commiter=sam –grep 通过关键字过滤提交日志 git log –grep=mod #列出所有包含 mod 字样提交信息的记录 –graph 显示ASCLL码图形表示的分支河滨管理师 git log –graph git log 过滤分支git log test..master 查询master分支中的提交记录但不包含test分支记录git log master..test 查询test分支中的提交记录但不办含master分支记录git log master…test 查询master或test分支中的提交记录。git log test –not master 屏蔽master分支 根据 commit id 或者 HEAD 查询日志commit id 可以是提交哈希的简写模式，也可以使用HEAD替代。HEAD指向当前分支，HEAD^为最后一个提交，等同于HEAD~1,HEAD~2代表倒数第二次提交123git log f52c471git show f52c471 filename #只看某个条中某个文件的变化git show -s --pretty=raw f52c471 #查看某个提交 git 其他查看某个文件修改历史的命令 选项 说明 举例 show 查看某次提交的修改(查看diff) git show –stat #–stat 可以不加 blame 显示文件的每一行是在哪个版本最后修改的 git blame filename whatchanged 显示某个文件的每个版本提交信息：提交日期、提交人员、版本号、提交备注 git whatchanged filename –pretty 按指定格式显示日志信息可选项有： oneline, short, medium, full, fuller, email, raw, format默认为medium，可以通过修改配置文件来指定默认的方式：1git log (--pretty=)oneline 常见的 format 选项：123456789101112131415161718选项 说明%H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 -date= 选项定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期，按多久以前的方式显示 例如：1 day ago%ci 提交日期，按ISO 8601 格式显示 例如：2021-02-04 23:00:45 +0800%s subject 提交说明%d body 事例：123git log --pretty=format:&quot;$h %cn %cr %s&quot;// 或者git log --format=&quot;$h %cn %cr %s&quot; 自定义 git log –format 后输出内容的颜色git log --format 后，输出的内容是没有颜色区分的，我们其实是可以给输出的内容自定义颜色，便于让内容更有辨识度。方法为在 format 的内容选项前，加上 %C() 选项。其中: 括号内放代表颜色的字符串，颜色字符串支持24位的RGB值（要带#号） 也可以是以下的颜色名称： normal black red green yellow blue magenta cyan white 这些颜色名称还可以跟这些修饰属性绑定使用，可叠加多个使用。注意，这些修饰只能修饰前景色： bold // 加粗 dim // 颜色减淡 ul // 下划线 blink // 闪烁效果 reverse // 前景色背景色交换 也可以放两个颜色字符串，第一个将被识别为前景色，第二个将被识别为背景色 在 git v1.7 版本后，对于 red、green、blue 三个颜色来说，括号是可选的。（但是这样就只能使用一个颜色，即前景色） 颜色和颜色修饰，是会传播到之后的输出内容样式，除非在内容前或者该内容后，重置颜色和修饰：%Creset。或则剔除修饰：noxxx（xxx 代表修饰名，例如nodim）。所以每设置完一个内容的颜色，最好是在该内容后紧跟一个%Creset，以防影响后面内容的样式。 重置颜色和剔除修饰也是会传播的。 事例命令：1git log --format=&quot;%C(magenta)%h %C(red)%d %C(yellow)(%cr) %C(green)%s&quot; 效果：命令：1git log --format=&quot;%C(white ul bold magenta)%h%Creset %C(yellow)(%cr)%Creset %C(green)%s%Creset %C(dim)%cd&quot; 效果：命令：1git log --format=&quot;%C(reverse ul black)%h%Creset %C(yellow)(%cr)%Creset %C(green)%s%Creset %C(dim)%cd&quot; 效果： 自定义规则快捷键——别名每次都要输入这一长串的命令非常繁琐且容易出错，我们可以将调整好的这一串命令保存在git配置文件里，并给它起一个别名，下次只需要输入这个别名，就可以看到符合自己习惯的日志格式和样式了。 进入～／.gitconfig 添加：（注意，format后的值必须要用单引号，双引号会报错。） 12[alias] logs = log --format=&apos;%C(reverse ul red)%h%Creset %cn %C(yellow)(%cr)%Creset %C(green)%s%Creset&apos; 然后在命令行只需要输入 git logs 就可以得到你要的效果了。 更多详细可查看 git documentation Pretty Formats –name-only 列出修改过(新增、修改、删除)的文件清单1git log --name-only --oneline 输出：1234567891011121314151617181944032af (HEAD -&gt; master, origin/master) add timeout error handlersrc/utils/http.js92e2cf5 update readmeREADME.md64ed4bd make http request with wrapped api functionsrc/views/Home.vue0f0aad3 wrap apissrc/api/home.jssrc/api/index.js4a14830 wrap axiospackage-lock.jsonpackage.jsonsrc/utils/http.js0de3bde get prepared.browserslistrc.editorconfig.eslintrc.js.gitignoreREADME.md –name-status 列出修改过的文件和修改状态1git log --name-status 输出：1234567891011121314151617181944032af (HEAD -&gt; master, origin/master) add timeout error handlerM src/utils/http.js92e2cf5 update readmeM README.md64ed4bd make http request with wrapped api functionM src/views/Home.vue0f0aad3 wrap apisA src/api/home.jsA src/api/index.js4a14830 wrap axiosM package-lock.jsonM package.jsonA src/utils/http.js0de3bde get preparedA .browserslistrcA .editorconfigA .eslintrc.jsA .gitignoreA README.md]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用nvm+nrm+cmder打造灵活的前端开发环境]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8nvm-nrm-cmder%E6%89%93%E9%80%A0%E7%81%B5%E6%B4%BB%E7%9A%84%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[在前端工程开发过程中，不同项目可能会使用不同的 node 环境和 npm 环境，在不同项目中切换时，要不停的卸载安装前端开发环境，非常麻烦。于是有了 nvm 和 nrm，可以通过切换的方式快速设置开发环境版本，再也不要繁琐地卸载安装了，有效的解放了劳动力。 1. nvmnvm: node version managernode 版本管理器 2. nrmnrm: npm registry managernpm 版本管理器 安装 nrm：1npm install nrm -g 添加 registry：12nrm add npm http://registry.npmjs.orgnrm add taobao https://registry.npm.taobao.org 查看已添加的 registry：1nrm ls 切换 registry：12nrm use taobaonrm use npm 3. cmder一款酷炫的命令行终端软件]]></content>
      <categories>
        <category>工具</category>
        <category>Intergration</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>nvm</tag>
        <tag>nrm</tag>
        <tag>cmder</tag>
        <tag>开发环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何查看和设置npm镜像地址]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%92%8C%E8%AE%BE%E7%BD%AEnpm%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[查看配置1npm config list 在输出信息中可以看到我的 npm 镜像如下：123metrics-registry = &quot;https://registry.npmjs.org/&quot;scope = &quot;&quot;user-agent = &quot;npm/5.5.1 node/v8.9.3 darwin x64&quot; 设置镜像常用的 npm 镜像地址有：npm —- http://registry.npmjs.org (默认)cnpm — http://r.cnpmjs.orgtaobao - https://registry.npm.taobao.orgnj —– https://registry.nodejitsu.comrednpm - http://registry.mirror.cqupt.edu.cnnpmMirror https://skimdb.npmjs.com/registryedunpm - http://registry.enpmjs.org 1. 临时使用1npm --registry https://registry.npm.taobao.org install xxx 2. 持久使用 12npm config set registry https://registry.npm.taobao.orgnpm config set disturl https://npm.taobao.org/dist 或者直接编辑 ~/.npmrc 文件，加入如下内容：1registry = https://registry.npm.taobao.org 3. 随时切换使用 nrm 管理 npm 镜像地址 检测镜像是否配置成功12npm config get registrynpm config get disturl npm info underscore 或者 npm info express 也可以用来查看配置是否成功 删除镜像12npm config delete registrynpm config delete disturl 其他 查看 npm 安装目录1npm root -g 查看 npm 的 prefix 和 cache 路径配置信息12npm config get prefixnpm config get cache 安装 node.js 时会自动安装 npm， 默认的缓存路径是 %appdata%\Roaming\npm-cache]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git如何去掉对文件的追踪]]></title>
    <url>%2F2018%2F11%2F24%2Fgit%E5%A6%82%E4%BD%95%E5%8E%BB%E6%8E%89%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[去掉对某些文件的 track：1git rm --cached &lt;file path&gt;]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让commit信息带图标]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%A6%82%E4%BD%95%E8%AE%A9commit%E4%BF%A1%E6%81%AF%E5%B8%A6%E5%9B%BE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[git commit 的提交日志上，除了文字，还可以有图标。叫做 git commit emoji。 提交事例：1git commit -m &quot;:tada: Made some changes&quot; 效果如下： commit 格式规范： message 摘要不超过50个字，首字母大写，使用祈使语气，句末不要加句号 引用相关 issue 或 PR 编号 &lt;#110&gt; emoji 代码列表 emoji emoji代码 语义 :tada:(庆祝) :tada: 初次提交 :sparkles: (火花) :sparkles: 引入新功能 :bookmark: (书签) :bookmark: 发行/版本标签 :bug: (bug) :bug: 修复 bug :ambulance: (急救车) :ambulance: 重要补丁 :globe_with_meridians: (地球) :globe_with_meridians: 国际化与本地化 :lipstick: (口红) :lipstick: 更新 UI 和样式文件 :rotating_light: (警车灯) :rotating_light: 移除 linter 警告 :wrench: (扳手) :wrench: 修改配置文件 :heavy_plus_sign: (加号) :heavy_plus_sign: 增加一个依赖 :heavy_minus_sign: (减号) :heavy_minus_sign: 减少一个依赖 :arrow_up: (上升箭头) :arrow_up: 升级依赖 :arrow_down: (下降箭头) :arrow_down: 降级依赖 :zap: (闪电):racehorse: (赛马) :zap::racehorse: 提升性能 :chart_with_upwards_trend: (上升趋势图) :chart_with_upwards_trend: 添加分析或跟踪代码 :rocket: (火箭) :rocket: 部署功能 :white_check_mark: (白色复选框) :white_check_mark: 增加测试 :memo: (备忘录) :memo: 撰写文档 :hammer: (锤子) :hammer: 重大重构 :art: (调色板) :art: 改进代码结构/代码格式 :fire: (火焰) :fire: 移除代码或文件 :pencil2: (铅笔) :pencil2: 修复 typo :construction: (施工) :construction: 工作进行中 :construction_worker: (工人) :construction_worker: 添加 CI 构建系统 :green_heart: (绿心) :green_heart: 修复 CI 构建问题 :lock: (锁) :lock: 修复安全问题 :whale: (鲸鱼) :whale: Docker 相关工作 :apple: (苹果) :apple: 修复 macOS 下的问题 :penguin: (企鹅) :penguin: 修复 Linux 下的问题 :checkered_flag: (旗帜) :checked_flag: 修复 Windows 下的问题 注意emoji 表情在提交代码的时候不能乱用，否则容易造成误解。为此，开源项目 gitmoji 专门规定了在 github 提交代码时应当遵循的 emoji 规范。 延伸 默认情况下在命令行中不会显示出 emoji， 仅显示 emoji 代码。不过可以使用 emojify 使得在命令行也可以像显示 emoji，emojify 是一个 shell 脚本。(不过这个脚本已经很老了，最近更新在3年前，而且mac提示已经不支持该命令，后空再找解决方案) 另外，markdown 也有一系列支持的 emoji，传送门]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js如何获取浏览器窗口大小和网页内容尺寸]]></title>
    <url>%2F2018%2F11%2F05%2Fjs%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%B5%8F%E8%A7%88%E5%99%A8%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E5%92%8C%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E5%B0%BA%E5%AF%B8%2F</url>
    <content type="text"><![CDATA[什么是网页的大小和浏览器窗口 网页大小就是一张网页的全部面积，通常情况，网页大小由内容和CSS样式表决定。 浏览器窗口大小，是指浏览器窗口中看到的那部分网页面积，又叫视口（viewport）。 获取浏览器窗口大小可以通过windows对象的 innerHeight 属性获取。也可以通过元素的 clientHeight 属性获取。网页上每个元素都有 clientHeight 和 clientWidth 属性。这两个属性指元素的内容部分加上 padding 的大小，不包括 border 和滚动条的大小。大部分情况下 document.documentElement 的大小可以代表浏览器窗口的大小，但是在 IE6 的 quirks 模式中，document.body 才返回正确的值。 如何获取浏览器窗口高度 1234567891011// 浏览器内部界面的高度，即内容显示区域的高度，F12调试工具的占位会实时改变该值window.innerHeight// 浏览器外部界面即窗体的高度，调试工具的占位不会影响该值window.outerHeight// 表示 HTML 文档所在窗口的可视区域高度，效果同 window.innerHeightdocument.documentElement.clientHeight// ie6 quirks 模式下表示 body 的可视区域高度，注意：body与浏览器之间有个默认的 margindocument.body.clientHeight 与高度对应的，还有宽度：window.innerWidth 、window.outerWidth、window.outerWidth、document.documentElement.clientWidth、 document.body.clientWidth 说明：window.innerHeight ／ innderWidth 在ie8 及以下不支持，需要通过document.documentElement.clientHeight ／ clientWidth 来替代。所以兼容的写法为：window.innerHeight || document.documentElement.clientHeightwindow.innderWidth || document.documentElement.clientWidth 获取网页内容大小12345document.documentElement.scrollWidth || document.body.scrollWidthdocument.documentElement.scrollHeight || document.body.scrollHeightdocument.documentElement.offsetWidth || document.body.offSetWidthdocument.documentElement.offsetHeight || document.body.offSetHeight 番外通常获取浏览器界面的宽高，是有自适应布局的需要，常常需要跟如下方法配合使用： 1. window 的尺寸变化事件12345// jswindow.onresize()// jquery$(window).resize() 2. window 的滚动事件12345// jswindow.onscroll()// jquery$(window).scroll()]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下模拟域名]]></title>
    <url>%2F2018%2F10%2F05%2Fwindows%E4%B8%8B%E6%A8%A1%E6%8B%9F%E5%9F%9F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[在 c盘下 windows／system32/drivers/etc/host 文件内，可以添加设置域名，将本地起的服务模拟成域名形式，便于相关前端测试，比如测试跨域。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>windows</tag>
        <tag>domain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速使用express搭建服务]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8express%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[使用 express 搭建最简单的服务。需要有 node 环境。 1. 安装 express1npm install express 2. 编写最简单的服务 新建 server.js 文件 打开 server.js 文件，写入： 1234const express = require(&apos;express&apos;); //引入 expressconst app = express(); //执行一下 expressapp.use(express.static(__dirname)); //指定静态文件路径app.listen(3000); //指定监听端口 3. 起服务命令行进入 server.js 所在目录，然后执行：1node server.js 4. done！服务已经启动，在浏览器输入 http://localhost:3000 就可以访问页面了。 进阶1. 添加接口路由123456789//get 请求，访问地址为 `http://localhost:3000/users`app.get(&apos;/users&apos;, function(req, res) &#123; res.end(res);&#125;)//put 请求，访问地址为 `http://localhost:3000/users`app.put(&apos;/users&apos;, function(req, res) &#123; res.end(res);&#125;) 2. 设置响应头根据需要，有时得设置响应头，以达到某种目的，比如跨域。在 server.js 文件的定义变量之后，添加一个 app.use：1234567891011121314151617app.use(function(req, res, next) &#123; //允许哪个源可以访问我 res.setHeader(&apos;Access-Control-Allow-Origin&apos;, &apos;http://localhost:4000&apos;); //允许携带哪个头访问我，多个头，用英文逗号隔开 res.setHeader(&apos;Access-Control-Allow-Headers&apos;, &apos;name&apos;); //允许哪个方法访问我 res.setHeader(&apos;Access-Control-Allow-Methods&apos;, &apos;PUT&apos;); //允许携带 cookie 访问我 res.setHeader(&apos;Access-Control-Allow-Credentials&apos;, true); //允许前端访问哪个头，多个头，用英文逗号隔开 res.setHeader(&apos;Access-Control-Expose-Headers&apos;, &apos;name&apos;); next();&#125;)]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>node</tag>
        <tag>express</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域]]></title>
    <url>%2F2018%2F10%2F05%2F%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[浏览器同源策略：请求的地址与平台的协议、域名、端口号，都一致，称为 同域。只要有一个不一样，就称为 跨域。 cookie、 Localstorage 不能跨域；DOM元素也有同源策略（iframe）；ajax 也不支持跨域。 可以跨域的 html 标签：link、 img、 script 如何实现跨域： jsonp cors postMessage document.domain window.name location.hash http-proxy ngix WebSocket]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用gitbook发布自己的书籍]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8gitbook%E5%8F%91%E5%B8%83%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B9%A6%E7%B1%8D%2F</url>
    <content type="text"><![CDATA[利用开源项目 gitbook，自己写本书吧～ 前言：gitbook 平台在今年的4月9日发布了新的版本v2。新的版本官网已经变成 www.gitbook.com （旧的地址为 legacy.gitbook.com ）。新旧版本有很多的不一样，网上很多资料都是针对旧版。 比如新版不再支持把每本书作为一个 Git Repository 来进行版本管理。（以前是可以针对每本书从本地 git push 到 gitbook 的），这点也是坑了我很久（坑一个强迫症重度患者的结果就是，不扒出被坑的根本原因誓不罢休）。更多 v2 的重大改变可以看 这里。 以下的所有操作都是针对新版的 gitbook。 使用 gitbook 编写一本书的步骤如下： 基本用法1. 全局安装 gitbook-cli1npm install gitbook-cli -g 2. 查看 gitbook 版本1gitbook --version 我在查看 gitbook 版本的时候，他会自动安装一些插件，等了一会安装完才出的版本信息：12CLI version: 2.3.2GitBook version: 3.2.3 3. 初始化 gitbook1gitbook init 4. 编辑书籍 一个 gitbook 项目至少要包含 README.md 和 SUMMARY.md，书本的第一页内容是从文件 README.md 文件中提取的。如果这个文件名没有出现在 SUMMARY.md 文件中，则它会被添加为章节的第一个条目。而由于一些托管在 github 上的书更喜欢将 README.md 作为项目的介绍而不是书的介绍，从 gitbook v2 起，可以在 book.json 中指定某个文件作为 README。例如： 12345&#123; &quot;structure&quot;: &#123; &quot;readme&quot;: &quot;myIntro.md&quot; &#125;&#125; gitbook 使用文件 SUMMARY.md 来定义书本的章节和子章节的结构。它用来生成书本内容的预览表。它的格式是一个简单的链接列表。另外可以在里面添加一些 markdown 格式的标题和分割线。例如： 12345678910111213141516# 概要* [章节 1](chapter1.md)* [章节 2](chapter2.md)* [章节 3](chapter3.md)# 基础* [章节 1](chapter1/README.md) * [1.1 a](chapter1/a.md) * [1.2 b](chapter1/b.md)---* [章节 2](chapter2/README.md) * [2.1 c](chapter2/c.md) * [2.2 d](chapter2/d.md)# 进阶* [章节 3](chapter3/README.md) 编写文章内容接下来就可以在相应的 md 文件里书写内容了。 5. 启动 gitbook 本地服务写完内容，可以通过以下方式来预览书本：1gitbook serve gitbook serve 命令实际上是先调用 gitbook build 编译书籍，然后启动一个 web 服务器，监听在本地的4000端口。 gitbook 进阶以上所说的都是在本地的操作，如何让别人也可以访问自己的书籍，除了自己买域名，还可以利用现有的互联网平台：gitbook.com、 github.com、 gitlab.com（gitlab也是听说可以有 gitlab pages，没有实际操作过，先略过） 1. 在 gitbook.com 上发布和管理书籍 需要先注册 gitbook 账号。可以单独注册，也可以使用 github 账号关联登录。 然后先创建一个 Orgnization 。 再在这个 Orgnization 里面创建一个 Space（旧版叫 Book）。这个就是你的书籍项目了。 然后就可以在线写书了～书籍的在线浏览地址为：https://yourorgnizationname.gitbook.io/yourspacename 2. 在 github.com 上发布和管理书籍在前面说的本地操作，编辑和预览书籍后，可以把 build 之后的结果，上传到 github 上面，然后利用 github pages 来发布书籍。 首先在 github 上新建一个跟你的书籍同名的 repository。 然后将远程仓库地址添加到本地，然后将编译后的 _book 目录 push 到远程。 然后在 github 上设置一下 github pages，具体方法和步骤我在另一个文章中详细介绍过：如何给github项目建立自己的主页。 在设置完后，就可以通过 https://githubusername.github.io/projectname 来浏览你的书了。 3. gitbook 与 github 关联同步新版 gitbook.com 不支持本地版本管理了，但是对 github 的集成支持的不错。可以通过配置，实现在 github 项目里面提交内容，gitbook 平台会自动同步过去。 在 gitbook 平台里，进入要设置的 space，也就是你的书。 点左下角的配置按钮，进入配置，点击 Intergrations ，找到 github。 点击 link you github repository 按钮，根据向导，登录 github ，选择 reposirory，选择分支，完成绑定和同步。(你还可以选择是 gitbook 同步 github ，还是 github 同步 gitbook) 需要注意的是：绑定的 github 仓库分支里面要是 gitbook 的源码，也就是那些 md 文件。而不是 build 之后生成的 html 文件。]]></content>
      <categories>
        <category>工具</category>
        <category>GitBook</category>
      </categories>
      <tags>
        <tag>gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何给github项目建立自己的主页]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%A6%82%E4%BD%95%E7%BB%99github%E9%A1%B9%E7%9B%AE%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B8%BB%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[想给 github 项目发布一个可访问的地址，网上的资料虽然多，但是乱。总的来讲，分为两种方法：一种是通过 github 的 htmlpreview 插件来展示。另一种就是通过 github pages 来展示。关于 github pages 网上很多人对它有误解，认为一定要先创建 username.github.io 这个 repository 才可以，其实并不需要；还有人认为一定要把要展示的静态资源放在项目的 gh-pages 分支上才可以，其实也不用。 总结一下我利用 github pages 给自己的项目创建主页的方法。 步骤如下： 1. 在 github 上建立项目 repository。2. 进入该 repository 的 Settings。3. 在 Options 里面， 找到 GitHub Pages。4. 为项目选择用于主页的分支， 然后保存。5. 然后就可以在浏览器输入 https://username.github.io/projectname 来访问项目主页了。 当然前提是在该分支下有用于展示的 html 文件，比如 index.html 另附上 github 的 htmlpreview 地址：https://htmlpreview.github.io/]]></content>
      <categories>
        <category>工具</category>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>github pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在mac上查看隐藏文件]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%A6%82%E4%BD%95%E5%9C%A8mac%E4%B8%8A%E6%9F%A5%E7%9C%8B%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在 Finder 里，按 Cmd + Shift + . 即可切换隐藏文件的显隐。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(三)：博客域名升级]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%BF%9B%E9%98%B6-%E4%B8%89-%EF%BC%9A%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[购买域名，我是在阿里云上购买的，.com域名。 先查询你想的域名是否已经被注册，如果有那就要另想一个了。 选择购买时长，一次买长一点的好像比一年一年买要划得来，而且也不容易被别人抢注。 然后购买，购买前要实名认证。 配置DNS，添加记录，将github page域名添加进去。 github上配置custom domain，设置为新购买的域名。 hexo source里添加CNAME文件，内容为新购买的域名。]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>domain</tag>
        <tag>hexo</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用json-server+faker模拟API服务和数据]]></title>
    <url>%2F2018%2F09%2F26%2F%E5%88%A9%E7%94%A8json-server-faker%E6%A8%A1%E6%8B%9FAPI%E6%9C%8D%E5%8A%A1%E5%92%8C%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>json-sever</tag>
        <tag>faker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript中的Date]]></title>
    <url>%2F2018%2F09%2F26%2Fjavascript%E4%B8%AD%E7%9A%84Date%2F</url>
    <content type="text"><![CDATA[chrome下结论： 1. 日期有前置0，则会解析为 UTC 时间，没有前置0，则会解析为本地时间。例如new Date(&#39;2018-09-26&#39;).getTime() 获取的是距离1970年1月1日0点UTC时间。new Date(&#39;2018-9-26&#39;).getTime() 获取的是距离1970年1月1日0点本地时间。 2. Date.now()、 +new Date()、 new Date().getTime(), 获取的都是距离1970年1月1日0点本地时间。 检验依据：Date.UTC() 该方法使用的是UTC时间。而 Date.UTC(2018, 8, 26) 跟 Date.now()、 +new Date()、 new Date().getTime() 获得的值相差8个小时。 ie下 结论： 1. 不支持非UTC格式的 new Date().2. 并且 Date.now()、 +new Date()、 new Date().getTime() 获取的都是距离1970年1月1日0点的UTC时间。 检验依据：而 Date.UTC(2018, 8, 26) 跟 Date.now()、 +new Date()、 new Date().getTime() 获得的值在同一个时区。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>Date</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10下中文输入法简繁切换快捷键]]></title>
    <url>%2F2018%2F09%2F26%2Fwin10%E4%B8%8B%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E7%AE%80%E7%B9%81%E5%88%87%E6%8D%A2%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[在中文输入法下，按 ctr+shift+f 。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git reflog]]></title>
    <url>%2F2018%2F09%2F25%2Fgit-reflog%2F</url>
    <content type="text"><![CDATA[我们对 git log 应该很熟悉了，它是我们常用的用来查看提交记录的命令，而对另一个查看日志的命令 git reflog，可能就不那么熟悉了。我最近因为排查一个线上bug，定位到一段代码被注释掉了，从 log 日志上看，是在一次 merge 的过程中发生的，但因为 rebase 和 amend 等命令的存在，光看 log 有的时候是不可靠的，为了进一步确认该操作是如何发生的，我用到了 git reflog。顺便把 reflog 的用法整理了一份。 git log VS git reflog git log shows the current HEAD and its ancestry. That is, it prints the commit HEAD points to, then its parent, its parent, and so on. It traverses back through the repo’s ancestry, by recursively looking up each commit’s parent. (In practice, some commits have more than one parent. To see a more representative log, use a command like git log –oneline –graph –decorate.) git reflog doesn’t traverse HEAD’s ancestry at all. The reflog is an ordered list of the commits that HEAD has pointed to: it’s undo history for your repo. The reflog isn’t part of the repo itself (it’s stored separately to the commits themselves) and isn’t included in pushes, fetches or clones; it’s purely local. Aside: understanding the reflog means you can’t really lose data from your repo once it’s been committed. If you accidentally reset to an older commit, or rebase wrongly, or any other operation that visually “removes” commits, you can use the reflog to see where you were before and git reset –hard back to that ref to restore your previous state. Remember, refs imply not just the commit but the entire history behind it. git log 是显示当前的HEAD和他的祖先的，递归是沿着当前指针的父亲，父亲的父亲……这样的原则。 git reflog 根本不遍历HEAD的祖先，他是HEAD所指向的一个顺序的提交列表。reflog并不是repo的一部分，它单独存储，而且不包含在pushes、fetches、或者clones里，它纯属是本地的。 reflog查看的是所有的 HEAD 改变的记录，约等于记录用户操作行为。reflog 可以很好地帮助你恢复你误操作的数据，例如你错误地 reset 了一个旧的提交，或者 rebase 等等，这个时候想要查看在错误操作之前的信息，log就做不到了，而reflog可以。然后使用 git reset –hard 去恢复之前的状态。 git log shows the commit log accessible from the refs (heads, tags, remotes)git reflog is a record of all commits that are or were referenced in your repo at any time.That is why git reflog (a local recording which is pruned after 90 days by default) is used when you do a “destructive” operation (like deleting a branch), in order to get back the SHA1 that was referenced by that branch.See git config 参考：https://stackoverflow.com/questions/17857723/whats-the-difference-between-git-reflog-and-log git reflog 命令git 的版本表示法 HEAD@{2} means “where HEAD used to be two moves ago”, master@{one.week.ago}means “where master used to point to one week ago in this local repository” HEAD@{2}表示HEAD指针在两次移动之前的情况；而 master@{one.week.ago}表示master在本地仓库一周之前的情况。 命令语法1git reflog &lt;subcommand&gt; &lt;options&gt; 1234git reflog [show] [log-options] [&lt;ref&gt;]git reflog expire [--expire=&lt;time&gt;] [--expire-unreachable=&lt;time&gt;] [--rewrite] [--updateref] [--stale-fix] [--dry-run | -n] [--verbose] [--all | &lt;refs&gt;…​]git reflog delete [--rewrite] [--updateref] [--dry-run | -n] [--verbose] ref@&#123;specifier&#125;…​git reflog exists &lt;ref&gt; “expire”子命令会删除掉更老的reflog条目。 “delete”子命令从reflog中删除一个条目。 “exists”子命令检查一个ref是否有一个reflog。 reflog 高级reflog 跟 log 一样也可以自定义输出格式12345678910111213141516171819202122232425262728293031323334353637383940414243%H: commit hash%h: 缩短的commit hash%T: tree hash%t: 缩短的 tree hash%P: parent hashes%p: 缩短的 parent hashes%an: 作者名字%aN: mailmap的作者名字 (.mailmap对应，详情参照git-shortlog(1)或者git-blame(1))%ae: 作者邮箱%aE: 作者邮箱 (.mailmap对应，详情参照git-shortlog(1)或者git-blame(1))%ad: 日期 (--date= 制定的格式)%aD: 日期, RFC2822格式%ar: 日期, 相对格式(1 day ago)%at: 日期, UNIX timestamp%ai: 日期, ISO 8601 格式%cn: 提交者名字%cN: 提交者名字 (.mailmap对应，详情参照git-shortlog(1)或者git-blame(1))%ce: 提交者 email%cE: 提交者 email (.mailmap对应，详情参照git-shortlog(1)或者git-blame(1))%cd: 提交日期 (--date= 制定的格式)%cD: 提交日期, RFC2822格式%cr: 提交日期, 相对格式(1 day ago)%ct: 提交日期, UNIX timestamp%ci: 提交日期, ISO 8601 格式%d: ref名称%e: encoding%s: commit信息标题%f: sanitized subject line, suitable for a filename%b: commit信息内容%N: commit notes%gD: reflog selector, e.g., refs/stash@&#123;1&#125;%gd: shortened reflog selector, e.g., stash@&#123;1&#125;%gs: reflog subject%Cred: 切换到红色%Cgreen: 切换到绿色%Cblue: 切换到蓝色%Creset: 重设颜色%C(...): 制定颜色, as described in color.branch.* config option%m: left, right or boundary mark%n: 换行%%: a raw %%x00: print a byte from a hex code%w([[,[,]]]): switch line wrapping, like the -w option of git-shortlog(1)]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reflog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让本地分支与远程分支建立映射关系]]></title>
    <url>%2F2018%2F09%2F25%2F%E5%A6%82%E4%BD%95%E8%AE%A9%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF%E4%B8%8E%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF%E5%BB%BA%E7%AB%8B%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[git 建分支很 cheap，本地和远程都常常各自拥有大量分支，有时本地分支需要跟某个新的远程分支建立追踪映射，以便于在 pull、 push 等操作时，简化命令，也在一定程度上防止误传到其他分支。今天建立了新的远程分支，本地不想弄一个新的跟它对应，想用当前分支换个关联，用到了该技能。 核心命令1git branch --set-upstream-to=[remote-name/remote-branch-name] 详解:完成同样效果的命令还有： git 1.8 以上123git branch -u [remote-name/remote-branch-name]# or 如果要关联的本地分支不是当前分支git branch -u [remote-name/remote-branch-name] [local-branch-name] 如果比较喜欢比较长的命令写法(我比较喜欢，是不是很变态，哈哈)，可以：123git branch --set-upstream-to=[remote-name/remote-branch-name]# or 如果要关联的本地分支不是当前分支git branch --set-upstream-to=[remote-name/remote-branch-name] [local-branch-name] 例如，我有个本地分支 dev，想跟远程 origin 的 v1.1 关联：123456789#如果当前就在 dev 分支上：git branch -u origin/v1.1#orgit branch --set-upstream-to=origin/v1.1#如果当前不在 dev 分支上：git branch -u origin/v1.1 dev#orgit branch --set-upstream-to=origin/v1.1 dev git 1.7 以上（已经在2.几版本停用）1git branch --set-upstream dev origin/v1.1 如果要在 check 分支的时候进行映射check 到与远程分支同名的本地分支 v1.11git checkout --track origin/v1.1 #git 1.6.2 以上 check 到与远程分支不同名的分支 dev21git checkout -b dev2 origin/v1.1 查看本地分支与远程分支的映射情况1git branch -vv]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让远程仓库回退到某个之前的版本]]></title>
    <url>%2F2018%2F09%2F23%2F%E5%A6%82%E4%BD%95%E8%AE%A9%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E5%9B%9E%E9%80%80%E5%88%B0%E6%9F%90%E4%B8%AA%E4%B9%8B%E5%89%8D%E7%9A%84%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[pull 代码再次遇到冲突，这次突发奇想，想试试用 git stash 来处理，结果 push 完，队友反映她 pull 后好多代码被重置，并且遇到严重冲突，受牵连70几个文件。我查看了下 commit 记录，惊讶地发现，我处理完冲突传上去的代码确实都变成了我本地的老代码，pull 下来的修改都被我重置了。都是乱用 git stash 的错。。还好发现的及时，我立即决定撤回远程仓库中我的那次 push，让代码回滚到我 push 前的状态。那么如何让远程仓库回退到某个之前的版本？步骤如下。 只需五步，方法如下： 1. 查看 commit 日志，确定要回滚到的 commit id（前7位即可）1git log --oneline 找到要回到的那次 commit ，复制 commit id，比如我这里是 b8b2df7 2. 先备份下当前版本12git checkout -b old_devgit push origin old_dev:old_dev 3. 本地回滚到指定代码版本1git reset --hard b8b2df7 4. 删除远程对应的分支123git push origin :dev//orgit push origin --delete dev 5. 重新创建远程分支1git push origin dev:dev 搞定！ 或者，不使用删除分支再建分支的方法，这个要两部，有些麻烦，可以使用强制推送，只需一步：1git push origin dev:dev -f #因为reset后本地仓库落后于远程仓库，因此要强制提交]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何撤销 git add 和 git commit]]></title>
    <url>%2F2018%2F09%2F19%2F%E5%A6%82%E4%BD%95%E6%92%A4%E9%94%80-git-add-%E5%92%8C-git-commit%2F</url>
    <content type="text"><![CDATA[由于心急，提交代码的时候，commit 后，发现多提交了一个文件，然后第一想法是使用 rebase 来修改提交，然后我把那个多提交的文件，恢复成修改前的样子，然后打算在 git add . 之后进行 rebase ，结果查看状态发现，它把我之前在编辑器里面忽略的一个文件也给加进来了…所以这个时候，我既多 commit 了， 又多 add 了…蜜汁尴尬… 经过查找资料，问题解决，又 get 到 git 的新技能。 1. git add 多了 git status 查看下 add 的文件 git reset HEAD 如果后面什么都不跟，就是把上一次的 git add 全部撤销。or git reset HEAD xxx/xxx/xxx.js ，则撤销某个文件的add。这对add了一批文件后，又删除了其中的某个文件，想取消对这个文件的add的情况非常适用。 2. git add 多了之后，又 commit 了 先使用 git log --oneline 查看节点，找到这次 commit 的上一次 commit 记录。 然后 git reset commit_id 。退回到某一个提交的节点，代码还是现在的样子，只是那个节点之后的commit日志没有了，git add 的暂存区也清掉了，那次节点之后的所有改动都放在了当前工作区。即需要重新 git add 到暂存区，再commit。 git reset 有三个参数可选：--hard --soft --mixed，不跟参数就是默认的--mixed。 3. 使用 git revert 还原已经提交的修改（这个没有验证过）使用 git revert 后，此次操作之前和之后的 commit 和 history 都会保留，并且把这次撤销作为一次最新的提交。 git revert HEAD 撤销前一次 commit git revert HEAD^ 撤销前一次 commit git revert commit_id 撤销指定的版本，撤销也会作为一次提交进行保存。git revert 是提交一个新的版本，将需要 revert 的版本的内容再反向修改回去，版本会递增，不影响之前提交的内容。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reset</tag>
        <tag>revert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(二)：hexo博客配置]]></title>
    <url>%2F2018%2F09%2F19%2F%E8%BF%9B%E9%98%B6-%E4%BA%8C-%EF%BC%9Ahexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[进阶(二)：hexo博客配置 进阶配置内容： 添加评论系统 添加 tags 页面 添加 categories 页面 添加 about 页面 配置404页 设置 ‘阅读全文’ 配置博客文档模版 1. 添加评论系统hexo官方提供了很多评论系统的配置，我选择的是’来必力’。我先注册了来必力，然后创建了一个 liverre city，获取到代码中的 data-uid ，然后编辑 hexo 主题配置文件 _config.yml , 编辑 livere_uid :1liverre_uid: #我在来必力获取的uid 2. 添加 tags 页面 在终端： 1hexo new page tags 在生成的 tags 目录下，编辑 index.md ，设置 type 属性为 tags，并屏蔽该页的评论功能： 123456---title: 标签date: 2018-09-19 22:51:31type: &quot;tags&quot;comments: false--- 在 _config.yml 文件中，编辑 menu 字段，放开 tags： 123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags #categories: /categories/ || th #about: /about/ || user || 左侧是页面路径，|| 右侧是图标在 FontAwesome 字体中的名称。 3. 添加 categories 页面 在终端： 1hexo new page categories 在生成的 categories 目录下，编辑 index.md ，设置 type 属性为 categories ，并屏蔽该页的评论功能： 123456---title: 分类date: 2018-09-19 22:51:31type: &quot;categories&quot;comments: false--- 在 _config.yml 文件中，编辑 menu 字段，放开 categoris 字段： 123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th #about: /about/ || user 4. 添加 about 页面 在终端： 1hexo new page about 在生成的 about 目录下，编辑 index.md ，屏蔽该页的评论功能： 12345---title: 标签date: 2018-09-19 22:51:31comments: false--- 在 _config.yml 文件中，编辑 menu 字段，放开 about 字段： 123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th about: /about/ || user about页面的设置Tip注意：about页面还有一些地方要处理，因为 Next主题中 默认会把页面跟文章一样处理，当你在yml中设置了显示文章目录时，自定义页面也会统一被添加toc目录（这是我不想要的）。于是我DIY了一下： 在 about页 的 index.md 文件头部加上自定义属性 toc: false; 123456---title: date: 2018-09-19 21:35:29toc: falsecomments: false--- 然后找到 themes/next/layout/_macro 目录下的 sidebar.swig 模版文件，将 toc 渲染条件由 1&#123;% set display_toc = is_post and theme.toc.enable or is_page and theme.toc.enable %&#125; 改为 1&#123;% set display_toc = is_post and theme.toc.enable or page.toc !== false %&#125; 重启 hexo 服务，刷新 about 页，即可看到不再显示右侧的toc目录了。 5. 配置404页给自己的站点设置404页面，可以让网站体验更加友好。hexo中配置404页的步骤很简单，在/source目录下，或者themes/next/source 目录下创建 404.html 文件即可。404页面的内容可以发挥自己的创意个性来设计，也可以利用404为社会公益做一些贡献。我放的是腾讯公益，帮助找回走失儿童，页面代码如下：12345678910&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;404&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; homePageName=&quot;返回首页&quot; homePageUrl=&quot;https://www.champyin.com&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 6. 设置 ‘阅读全文’效果：在首页提供文章的部分内容，并提供一个链接跳转到全文页面。在 NextT 中提供了三种方式，我比较喜欢它推荐的那种，也是 Hexo 提供的方式：在文章中使用 &lt;!-- more --&gt; 手动进行截断。 7. 配置博客文档模版hexo 中，运行 hexo new &quot;xxx&quot; 是调用了 scaffolds 目录下的 post.md 文件作为模版来创建的。所以修改这个模版，就可以达到每次创建文档可以使用自己习惯的模版了。默认模版是没有 categories 的，我需要这个字段，所以在模版中加上了这个字段：123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags: categories:---]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何修改git中已经提交的内容]]></title>
    <url>%2F2018%2F09%2F11%2F%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9git%E4%B8%AD%E5%B7%B2%E7%BB%8F%E6%8F%90%E4%BA%A4%E7%9A%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[今天在git上提交代码的时候，不小心在 commit message 中打了几个错别字，merge、push 完了才发现。。 由于我的完美主义加强迫症比较严重，那几个错别字越看越不顺眼，寻思着把它们给改过来。一番资料搜寻和操作，成功搞定！ 如何修改某次提交的 commit message需要注意的是：没有办法修改整个项目的第一条日志。第2次以后的信息都可以通过此方法修改。 step 1. 查看提交的 commit id (SHA值)如果 push 过，可以在git托管平台（比如 github、gitlab)上的 commits 里面看到（那串40位的编码就是了），只需要其前7位。或者直接通过 git log 命令查看：1git log --oneline 在展示的结果上每条 log 记录的前面的字段就是我们需要的 SHA 值。123456$ git log --onelineb8b2df7 (HEAD -&gt; master, origin/master) 中文dd09519 di sici tijiaof1d9380 english only modify again..ea8a3b5 nonono correct message66a4488 need to be changed message 比如我要修改的那条 commit 的 SHA 为：dd09519那我需要的是这一条之前的一条 commit 的 SHA ：f1d9380 step 2. 通过 git rebase 命令回到要修改提交的上一次提交的基础上1git rebase -i f1d9380 等待一会，然后会打开 vim 编辑器，12345678910111213141516171819202122232425262728pick dd09519 di sici tijiaopick b8b2df7 中文# Rebase f1d9380..f52c471 onto f1d9380 (2 commands)## Commands:# p, pick &lt;commit&gt; = use commit# r, reword &lt;commit&gt; = use commit, but edit the commit message# e, edit &lt;commit&gt; = use commit, but stop for amending# s, squash &lt;commit&gt; = use commit, but meld into previous commit# f, fixup &lt;commit&gt; = like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec &lt;command&gt; = run command (the rest of the line) using shell# d, drop &lt;commit&gt; = remove commit# l, label &lt;label&gt; = label current HEAD with a name# t, reset &lt;label&gt; = reset HEAD to a label# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]# . create a merge commit using the original merge commit&apos;s# . message (or the oneline, if no original merge commit was# . specified). Use -c &lt;commit&gt; to reword the commit message.## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.### Note that empty commits are commented out 在编辑器中找到你要修改的那个提交信息，用 i 命令进入编辑，将那一行开头的 pick 改为 edit: pick dd09519 di sici tijiao -&gt; edit dd09519 di sici tijiao然后 esc -&gt; : -&gt; wq, 保存退出。 然后界面显示如下：123456789$ git rebase -i f1d9380Stopped at dd09519... di sici tijiaoYou can amend the commit now, with git commit --amendOnce you are satisfied with your changes, run git rebase --continue step 3. 修改 commit message：1git commit --amend 再次进入 vim 编辑器，1234567891011121314151617di sici tijiao# Please enter the commit message for your changes. Lines starting# with &apos;#&apos; will be ignored, and an empty message aborts the commit.## Date: Tue Sep 11 18:49:29 2018 +0800## interactive rebase in progress; onto f1d9380# Last command done (1 command done):# edit 4df3762 中文信息 sici tijiao# Next command to do (1 remaining command):# pick f52c471 中文# You are currently editing a commit while rebasing branch &apos;master&apos; on &apos;f1d9380&apos;.## Changes to be committed:# modified: README.md# 可以看到第一行就是要修改的 commit message。同样的通过 vim 命令 进入编辑模式，修改提交信息: di sici tijiao -&gt; 中文信息 sici tijiao然后:wq 保存退出。1234$ git commit --amend[detached HEAD 4df3762] 中文信息 sici tijiao Date: Tue Sep 11 18:49:29 2018 +0800 1 file changed, 0 insertions(+), 0 deletions(-) step 4. 完成 rebase：1git rebase --continue 等待一会，然后出现：12$ git rebase --continueSuccessfully rebased and updated refs/heads/master. 表明操作成功。 step 5. 将修改后的变动 push 到远程1git push origin master -f 注意一定要使用 -f 参数，表示强制推送。因为我们没有产生新的 commit（用 git status 可以看出），直接 push 不会发送任何东西。 step 6. 现在我们去远程仓库刷新下 commit 记录，可以看到 commit 信息就已经修改了。最后，我们再来看下我们的日志信息1git log --oneline 细心点就会发现，从我们修改的那条 commit 起，之后的所有的 commit 的 commit id 都发生了变化！我修改的那条，由 dd09519 变成了 4df3762; 而它之后的那条记录也由 b8b2df7 变成了 f52c471 虽然我没由修改这条 commit 信息。git log --oneline12345f52c471 (HEAD -&gt; master, origin/master) 中文4df3762 中文信息 sici tijiaof1d9380 english only modify again..ea8a3b5 nonono correct message66a4488 need to be changed message BTW 还要说一个要注意的 就是如果 commit 信息要输入中文，记得用 git bash。因为我是在 IDE（webstorm）上进行的 commit，用的中文（要不怎么有错别字呢），那在修改 commit 信息的时候，我仍想用中文，我用 cmd、powerShell、Cmder，都试了，没法在 vim 里面敲中文，直接乱码，查资料改配置（quotepath = false、[gui] encoding = utf8）等等都没用，最后怀着绝望的心情，试了下 git bash， 居然中文支持的非常好！真是。。 另外，在查资料的过程中，还顺便 get 到几个 git 的高级技能。总结如下：1. 修改最近一次的提交方法一：commit –amend这种方法不仅可以修改 commit message，也可以修改提交内容。这种方式在还没有推送到远端的情况下，可以保持原有的 Change-Id（commit id）。若已经推送到远端，Change-Id 则会修改掉。12345# 修改需要修改的项目代码(如果只需要修改 commit message 就不用做)git add . #如果只需要修改 commit message 就不用做git commit --amend# 在出现的 vim 编辑器中修改 commit message，保存退出。git push &lt;remote&gt; &lt;branch&gt; -f #若还没有推送到远端，就不用做 方法二：reset这种方法也可以修改提交内容和 commit message。这种方式在还没有推送到远端的情况下，也可以保持原有的 Change-Id（commit id）。若已经推送到远端，Change-Id 则会修改掉。12345git reset HEAD^# 修改需要修改的项目代码(如果只需要修改 commit message 就不用做)git add . # 如果只需要修改 commit message 就不用做git commit -m “new commit message”git push &lt;remote&gt; &lt;branch&gt; -f # 若还没有推送到远端，就不用做 2. 提交到了错误的分支上的处理方法一：reset + stash123456789# 取消最新的提交， 然后保留现场原状git reset HEAD~ --softgit stash# 切换到正确的分支git checkout name-of-correct-branchgit stash popgit add .git commit -m &quot;new commit message&quot;# 现在你已经提交到正确的分支上了 方法二：cherry-pick 摘樱桃123456git checkout name-of-correct-branch# 把主分支上的最新提交摘过来～git cherry-pick master# 再删掉主分支上的最新提交git checkout mastergit reset HEAD~ --hard]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>rebase</tag>
        <tag>amend</tag>
        <tag>cherry-pick</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用express/koa快速起一个node服务]]></title>
    <url>%2F2018%2F09%2F11%2F%E4%BD%BF%E7%94%A8express-koa%E5%BF%AB%E9%80%9F%E8%B5%B7%E4%B8%80%E4%B8%AAnode%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[expressexpress 导出的是一个函数。 1. 最简单的服务1npm i express 123456789// www.jsconst express = require(&apos;express&apos;);const app = express();app.get(&apos;/&apos;, (req, res) =&gt; &#123; res.end(&apos;server by express&apos;);&#125;)app.listen(3000); 2. 使用 express-generator12345npm i expressnpx express-generator //需要nodejs8.2及以上//nodejs8.2以下：//npm i -g express-generator//express --view=ejs myproject 会在当前目录下生成一个项目，7个文件夹，9个文件：12345678910111213141516|--app.js|--bin/| |-- www.js|--package.json|--public/| |-- images/| |-- javascript/| |-- stylesheets/| |-- style.css|--routes/| |-- index.js| |-- users.js|--views/ |-- error.jade |-- index.jade |-- layout.jade 然后1234npm iDEBUGE=projectname:* npm start//在windows下这样：//set DEBUG=projectname:* npm start koakoa导出的是一个对象。 最简单的服务1npm i koa 123456789// www.jsconst Koa = require(&apos;koa&apos;);cnost app = new Koa();app.use((ctx) =&gt; &#123; ctx.body = &apos;server by koa&apos;;&#125;)app.listen(3000);]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>node</tag>
        <tag>express</tag>
        <tag>koa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git错误：HTTP Basic: Access denied]]></title>
    <url>%2F2018%2F09%2F10%2Fgit%E9%94%99%E8%AF%AF%EF%BC%9AHTTP-Basic-Access-denied%2F</url>
    <content type="text"><![CDATA[上周五修改了gitlab的用户密码，今天发现操作git远程仓库都报错拒绝，错误信息如下：12remote: HTTP Basic: Access deniedfatal: Athentication failed for &apos;https://************&apos; 直觉告诉我，是改密码引起。网上查了资料，确实 git 会把第一次输入过的用户名密码存储起来，再次使用 git 命令的时候，会使用存储的用户名密码，然而当 git 的密码修改后，原来存储的密码肯定匹配不了，于是直接报没有权限终止操作。网上类似的帖子很多，但是不是都有效，在多次尝试后，终于解决，解决办法如下： 首先我因为有两台电脑，一台 win7，一台 win10，不同操作系统解决方式还不一样，也是坑了我很多时间。。。 win 10 下的解决办法 解决办法很简单，一句命令搞定：1git config --system -unset credentia.helper 不过要注意的是在 win10 中，这个命令需要在管理员权限下运行，否则报错：1error: could not lock config file C:/Program Files/Git/migw64/etc/gitconfig: Permission denied 在 linux 下使用 sudo 可以切换到管理员权限，但是在 win10 上，只能先找到 cmd 的快捷方式，然后右键，以管理员身份运行。比如，在左下角windows符号上右键 -&gt; Windows PowerShell(管理员)。 运行后，命令的前面的路径会显示为：PS C:\Windows\system32&gt; win 7 下的解决办法使用刚才在 win 10 上的解决办法，在 win 7 上尝试无效。。。win 7 下采用的办法是直接修改凭据： 进入 控制面版 -&gt; 所有用户 -&gt; 凭据管理 在 Windows 凭据 下，找到 gitlab 对应的凭据 点 编辑，修改密码，保存。 done。 然后执行下刚才的 git pull 命令，妥妥滴拉下来。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>access denied</tag>
        <tag>authentication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码片段]]></title>
    <url>%2F2018%2F09%2F06%2F%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[1. 文字截断12345.ellipsis &#123; overflow: hidden; white-space: nowrap; text-overflow: ellipsis;&#125; 2. 清除浮动12345678.clearfix &#123; zoom: 1;&#125;.clearfix:after &#123; clear:both; content: &quot;&quot;; display: block;&#125; 3. javascript 生成 img 标签的3种方式方式1: 使用 createElement 方法 123var img = document.createElement(&apos;img&apos;);img.src = &apos;https://www.baidu.com/img/bd_logo1.png&apos;document.body.appendChild(img); 方式2: 使用 innerHTML 方法12var imgHtml = &apos;&lt;img src=&quot;https://www.baidu.com/img/bd_logo1.png&quot; &gt;&apos;;document.body.innerHTML = imgHtml; 方式3: 使用 new image() 方法123var img = new image();img.src = &apos;https://www.baidu.com/img/bd_logo1.png&apos;;document.body.appendChild(img); 4. js 添加、删除 class方法1: 比较传统的方法123456789101112var classVal = docment.getElementById(&apos;id&apos;).getAttribute(&apos;class&apos;);// 删除某个classvar classVal = classVal.replace(&apos;someclassname&apos;, &apos;&apos;);document.getElementById.setAttribute(&apos;class&apos;, classVal);// 添加classvar classVal = classVal.concat(&apos;newclassname&apos;);document.getElementById.setAttribute(&apos;class&apos;, classVal);// 替换classvar classVal = classVal.replace(&apos;someclassname&apos;, &apos;newclassname&apos;);document.getElementById.setAttribute(&apos;class&apos;, classVal); 方法2: HTML5中添加了classListclassList 属性返回元素的雷鸣，作为DOMTokenList对象。classList 属性是只读的，但是可以使用 add() 和 remove() 方法修改它。12345// 增加document.getElementById(&apos;id&apos;).classList.add(&apos;class1&apos;, &apos;class2&apos;, &apos;class3&apos;);// 删除document.getElemtnById(&apos;id&apos;).classList.remove(&apos;class1&apos;); 方法3: 正则匹配…]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>front-end</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web端页面如何在移动端也获得较好体验]]></title>
    <url>%2F2018%2F09%2F05%2Fweb%E7%AB%AF%E9%A1%B5%E9%9D%A2%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A7%BB%E5%8A%A8%E7%AB%AF%E4%B9%9F%E8%8E%B7%E5%BE%97%E8%BE%83%E5%A5%BD%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[在网页的 head 标签里，加上对 viewport 的设置，就可以让页面在移动设备上可以以比较好的缩放和比例来呈现：1&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; &gt; 还可以加入更多设置，如缩放之类： 1&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes&quot; &gt; 参数解释：width：可以控制 viewport 的大小，可以指定一个数值，或者一个特殊的值，比如 device-width 设备的宽度。initial-scale：初始缩放比例，也即当前页面第一次load的时候缩放比例minimum-scale：允许用户缩放到的最小比例。maximum-scale：允许用户缩放到的最大比例。user-scalable：用户是否可以手动缩放。]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>html</tag>
        <tag>viewport</tag>
        <tag>mobiles</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设置IDE编辑器以配合自动实时编译]]></title>
    <url>%2F2018%2F09%2F02%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEIDE%E7%BC%96%E8%BE%91%E5%99%A8%E4%BB%A5%E9%85%8D%E5%90%88%E8%87%AA%E5%8A%A8%E5%AE%9E%E6%97%B6%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[在前端开发过程中，通过webpack配置了即时监听并自动编译，实现保存文件触发编译。但是有的编辑器有 “安全写入” 的机制（就是在编辑器保存文件后不直接写入硬盘，而是先保存在编辑器内部的缓存里面，到一定时间后再写入硬盘），这会造成触发编译不那么实时，很影响开发效率。 以下是针对几款常见编辑器，如何禁用安全写入的设置办法： JetBrains IDEs（e.g. WebStorm):在 Preferences &gt; Appearance &amp; Behavior &gt; System Settings 里面，去掉对 “Use safe write” 选项的勾选。即可。 Sublime Text3:在 preferences-user 文件里，添加 atomic_save: false。即可。 Vim：在 setting 文件里，添加 :set backupcopy=yes 。即可。]]></content>
      <categories>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>webstorm</tag>
        <tag>sublime</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git冲突处理]]></title>
    <url>%2F2018%2F08%2F30%2Fgit%E5%86%B2%E7%AA%81%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[git冲突处理 今天在merge分支的时候，由于记忆错位，merge了format分支到master，造成了很严重的冲突（我原本是要把format分支合并到dev分支，结果合并到了master）。看到几百个文件的modify想死的心都有，差点想重新clone重新来过。。。好在理智战胜冲动，决定正面处理冲突，而不是消极回避。而在处理完冲突之后，发现异常的简单，庆幸没有冲动乱来。 言归正传。 我在merge的时候git的提示是：12345err： Your local changes to the following files would be overwritteen by merge: bla bla blaPlease commit your changes or stash them before you merge.AbordingUpdating xxxxxxx(some hashcode) 解决方案有三种：第一种： 提交修改1git commit -m &quot;my message&quot; 第二种： stash备份当前工作区的内容，从最近的一次提交种读取相关内容，当工作去保证和上次提交的内容一致。同时，将当前的工作区内容保存到Git栈中。然后执行merge，然后再从Git栈中读取最近一次保存的内容，恢复工作区的相关内容。1git statsh 然后执行之前未执行完的merge操作：1git merge xxx 然后拉取stash：1git stash pop 由于可能存在多个stash的内容，所有用栈来管理，pop会从最近的一个stash中读取内容并恢复。可以用 git stash list 来查看Git栈内的所有备份，可以利用这个列表来决定从哪个地方恢复。git stash clear 可以清空Git栈。 第三种： 忽略本地修改123git reset --hard// orgit checkout -t -f remote/branch Or 忽略只忽略特定的文件1git checkout filename 我当然使用的是stash的方式。 在 master 分支上使用 git stash, 然后 git merge dev, 成功merge！ 然后恢复工作区 git stash pop, 然后多出了很多modify的文件，还有一个标红的文件（冲突），不过它已经帮你解决好，只需要在文件中选择你要保留哪一段代码就好。 修改完冲突文件后， git add ., git commit -m &quot;conflict fixed&quot;. 最后，赶紧把这个解决完冲突后的代码传上远程仓库, WOO，松了一口气。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>conflict</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualbox如何挂载宿主机的文件夹]]></title>
    <url>%2F2018%2F07%2F17%2Fvirtualbox%E5%A6%82%E4%BD%95%E6%8C%82%E8%BD%BD%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[我的宿主机是一台windows操作系统的服务器。 虚拟机用的是virtualbox。 以前在 vmware 上面与宿主机的共享只需要在 wmware 上配置下共享文件夹就可以生效。但是在 virtualbox 上，除了配置共享文件夹，还要使用 mount 命令进行挂载才能与宿主机共享一个文件夹。 1. 在宿主机建立一个用于与virtualbox共享的文件夹，例如 myshared。并在里面新建一个空的文本 a.txt，用于检测最后挂载是否成功。2. 在virtualbox中选择 设备 -&gt; 共享文件夹 -&gt; 打开设置界面。3. 点击右侧 + 号，添加共享文件夹，选择宿主机上之前建好的 myshared 文件夹，并勾选 固定分配 。4. 在linux虚拟机中，打开终端，在mnt目录下新建一个目录 shared：1sudo mkdir /mnt/shared 5. 执行挂载：1sudo mount -t vboxsf myshared /mnt/shared 6. 挂载成功，进入shared目录，就可以看到a.txt文件了。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下如何切换到root用户]]></title>
    <url>%2F2018%2F07%2F16%2Flinux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%88%87%E6%8D%A2%E5%88%B0root%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[如果只是想要临时使用一下root权限，只需要在命令前面加上 sudo 就可以了。 如果想要一直使用root权限，需要通过su切换到root用户： 首先要重设root用户的密码1sudo passwd root 然后根据提示，输入新的root密码（可以是原来的root旧密码） 然后就可以随时切换到root用户了1su 输入root用户密码即可。 回到用户权限使用 su &quot;yc&quot; 或者 exit 命令，即可回到用户权限。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2018%2F07%2F16%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[记录常用的liux命令，不定期更新。 一、 rm删除文件或文件夹 删除文件夹，无论文件夹是否为空1rm -rf 目录路径 说明：-r 就是向下递归的意思；-f 就是强制删除，不做任何提示的意思。 注意：使用 rm -rf 命令一定要格外小心。linux没有回收站，删除之后再找回就难了。 删除文件1rm -f 文件路径 二、lsls是 list segment 的缩写，用于列出文件。 列出当前目录下每个文件的大小以及当前目录文件下所有文件大小总和。1ls -lht 与以下命令是同一个效果：1ls -l -h -t ls的常用参数常用参数： -a, –all 列出目录下的所有文件，包括以 . 开头的隐含文件 -A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。 -c 配合 -lt：根据 ctime 排序及显示 ctime (文件状态最后更改的时间)配合 -l：显示 ctime 但根据名称排序否则：根据 ctime 排序 -C 每栏由上至下列出项目 –color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是’never’、’always’或’auto’其中之一 -d, –directory 将目录象文件一样显示，而不是显示其下的文件。 -D, –dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G, –no-group 不列出任何有关组的信息 -h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=方式 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i, –inode 印出每个文件的 inode 号 -I, –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小。 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息 -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r, –reverse 依相反次序排列 -R, –recursive 同时列出所有子目录层 -s, –size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 以下是可选用的 WORD 和它们代表的相应选项： extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t 以文件修改时间排序 -u ： 配合 -lt:显示访问时间而且依访问时间排序 配合 -l:显示访问时间但根据名称排序 否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w, –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何重置gitlab用户密码]]></title>
    <url>%2F2018%2F07%2F15%2F%E5%A6%82%E4%BD%95%E9%87%8D%E7%BD%AEgitlab%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[之前有提到，我为我们部门搭建了一个gitlab，前几天有用户跟我反映，他忘记密码了，使用gitlab自带的找回密码功能无果，收不到邮件，估计跟公司内网有一些关系，也可能是我没有配置好邮件联动。anyway，现在去配置邮箱感觉花的时间有些来不及。想着作为管理员，应该有权限和办法去重置用户的密码的，于是查询了资料，果然不出所料。方法如下，只需4步： 1. 首先进入Ruby on Rails console：使用root权限进入gitlab所在的linux服务器，打开一个终端，输入以下命令1&gt; gitlab-rails console production 然后等待ruby的console界面加载出来。 2. 然后你有好几种方法去查找用户。方法一，使用id：1irb(main):001:0&gt; user = User.where(id:[user&apos;s register index]).first 方法二，使用邮箱：1irb(main):001:0&gt; user = User.where(email:[user&apos;s register email]).first 方法三，使用用户名：1irb(main):001:0&gt; user = User.where(name:[user&apos;s register name]).first 我这次使用的是邮箱1irb(main):001:0&gt; user=User.where(email:xxx@163.com).first 3. 修改密码12&gt; user.password = &apos;newpassword&apos;&gt; user.password_confirmation = &apos;newpassword&apos; 注意最好是将 password 和 password_confirmation 都重置，以确保完全修改生效。 4. 保存修改1&gt; user.save! 注意 ! 号也很重要，不加的话，你的修改不会推送到数据库。 现在退出 console 使用新的密码登录试试，可以登录啦。]]></content>
      <categories>
        <category>工具</category>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>gitlab</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何迁移git仓库]]></title>
    <url>%2F2018%2F06%2F20%2F%E5%A6%82%E4%BD%95%E8%BF%81%E7%A7%BBgit%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[如果你想从别的git托管服务哪里复制一份源代码到新的Git托管服务器上，可以使用git clone --mirror / git clone --bare 和 git push --mirror命令。 普通 git clone 不能下载所有分支，想要简单的克隆所有分支，可以用镜像方法。 做一个镜像仓库只需3步： 从原地址克隆一份裸版本库（假设在github）： 123git clone --bare git://github.com/username/project.gitorgit clone --mirror git://github.com/username/project.git 这两种方式都只是将裸仓库克隆下来，不会在本地生成目录结构。 在新的服务器上创建一个新项目。例如new-peoject。 以镜像推送的方式上传到新的git服务器上（假设在gitlab）： 12cd prioject.gitgit push --mirror git@gitlab.com/username/new-priject.git done! 这种方式可以保留原版本远程仓库中的所有内容。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm 删除已发布的包或者包的某个版本]]></title>
    <url>%2F2018%2F06%2F08%2Fnpm-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%8F%91%E5%B8%83%E7%9A%84%E5%8C%85%E6%88%96%E8%80%85%E5%8C%85%E7%9A%84%E6%9F%90%E4%B8%AA%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[删除已发布的包的某个版本：1npm unpublish xxx@x.x.x 删除这个版本后，不能再发布同版本的包，必须要大于这个版本号的包才行。 删除已发布的包：1npm unpublish xxx 删除这个包之后，不能再发布同名的包。 注意：npm unpublish 仅在包发布后的24小时内有效。如果超过了24小时，则要联系npm官方去取消发布了。]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>unpublish</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过NPM安装私有模块]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87NPM%E5%AE%89%E8%A3%85%E7%A7%81%E6%9C%89%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[有3种方案安装NPM私有模块： 方案一：购买npm付费账号根据npm的价格方案，只要是付费用户，不论是哪一种，都可以下载和发布不限量的私有模块。所有的私有模块都是scoped package。scope是npm的新特性。如果一个模块的名字以 @ 开头，那它就是一个scoped package:1@scope/project-name 每一个npm用户都有拥有一个自己的scope：当前用户名username。 方案二：自建npm私服如果连仓库都是私有的，模块自然是私有的。这个方案好处就是可以建在自己公司内部，访问速度自然是杠杠的，而且想怎么定制就怎么定制。不过构建成本也是有的，而且需要服务器。一般稍微大规模的团队和公司会采取这种办法。 方案三：利用npm安装机制和git仓库这个方案最经济实惠。首先，npm install 支持 npm install &lt;git remote url&gt; ，其中 git remote url 的格式是：1&lt;protocol&gt;://[&lt;user&gt;[:&lt;password&gt;]@]&lt;hostname&gt;[:&lt;port&gt;][:/]&lt;path&gt;[#&lt;commit-ish&gt;] 即，如果你的代码托管在bitbucket中，可以通过如下命令安装模块：1npm install git+ssh://git@bitbucket.org/用户名／项目名.git#版本号 这种方式唯一的不足的地方就是，你必须要确保安装这个私有模块的机器由访问这个私有模块git仓库的权限。也就是说这台机器的公钥必须添加到git仓库中。如果你嫌添加公钥麻烦，也可以通过：1npm install git+https:username:password@bitbucket.org/用户名／项目名.git#版本号 不过密码就暴露出来了。]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何发布一个npm模块]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%A6%82%E4%BD%95%E5%8F%91%E5%B8%83%E4%B8%80%E4%B8%AAnpm%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[目录一、发布普通 npm 模块二、发布 scoped package 一、发布普通 npm 模块1.注册一个 npm 账号进入官网注册 npm 账号。 2.初始化包描述文档在你要发布的模块工程根目录下，初始化 package.json (如果没有的话)1npm init package.json 中 npm 所需的主要几个关键字段： name: 包名，必须唯一，不能跟npm上的包重名。可以在 npm 官网搜索名字，如果存在则需要换个名字。 version: 版本号，每次发布至 npm 都需要修改版本号，不能比上一次发布的版本号低。 description: 描述。 main: 入口文件，需指向我们编译后的包文件。 keyword: 关键字，以空格分离，希望用户搜索的词。 author: 作者。 private: 是否私有，需要修改为 false 才能发布到 npm。 license: 开源协议。 3.添加账号授权1npm adduser 然后根据提示一步一步输入你的 npm 账号、密码和邮箱。然后你可以通过如下命令来验证登录是否正确。1npm whoami 4.发布1npm publish 二、发布 scoped packagescope是npm的新特性。如果一个模块的名字以 @ 开头，那它就是一个 scoped package:1@scope/project-name 每一个npm用户都有拥有一个自己的 scope：当前用户名 username。 初始化一个 scoped-package通过在包名字前添加 scope：123&#123; &quot;name&quot;: &quot;@usernane/project-name&quot;&#125; 也可以使用 npm init 命令自定义 --scope 选项来设置scope：1npm init --scope=username 如果你在大多数时候使用的 scope 都是相同的，可以设置一个默认的 scope，这样每次初始化的时候会自动使用该 scope：1npm config set scope &lt;your_scope&gt; 发布 scoped-package发布 scoped 模块跟发布普通模块一样：1npm publish 默认状态下scoped package包是私有的。然而，你可以把 scoped package 免费滴发布为公共包。只需要在发布时配置 --access 选项即可：1npm publish --access=public Tips1. 确认镜像源发布npm包之前，首先一定要确保使用的是npm官方镜像源。如果你使用了nrm来管理镜像，可以通过nrm ls来查看下当前使用的是什么源，如果不是 npmjs 官方镜像，比如 taobao，那么使用nrm use npm切换过来。 2. 预检查包内容发包之前可以通过 npm pack 命令在本地产生一个tgz压缩包，里面的文件就是你将要传到 npm 的内容。如果有遗漏或者多了不需要发布的文件，则可以通过调整 .npmignore 文件的配置来调整。 3. 检查包名是否重名包名字不能与 npm 中已有的包同名，如果已存在同名包，否则会提交失败。通过在 npm 官网搜索包名，如已存在，则需要换一个。 4. 检查版本号每次提交版本号都要比上次的高，否则也会提交失败。从 npm 上查看自己上次发布的版本号，如果相同说明忘记更新版本号，根据需要通过 npm version 命令修改版本。]]></content>
      <categories>
        <category>工具</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件版本命名规范]]></title>
    <url>%2F2018%2F06%2F04%2F%E8%BD%AF%E4%BB%B6%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[软件版本阶段开发期 Base版此版本表示该软件仅仅是一个假页面链接，通常包括所有的功能和页面布局，但是页面中的功能都没有做完成的实现，只是作为整体网站的一个基础架构。 Alpha版软件的初级版本，此版本表示软件处于以实现软件功能为主的阶段，通常只在软件开发者内部交流，一般而言，该版本软件的bug较多，需要继续修改。测试人员条bug经开发人员修改确认后，发布到测试网址让测试人员测试，此时可将软件版本标注为alpha版。 Beta版此版本相对于alpha版已有了很大的改进，消除了严重的错误，但还存在着一些缺陷，需要经过多次测试来进一步消除，此版本主要的修改对象是软件的UI。 RC（Release Candidate）版最终测试版，此版本已经相当成熟了，基本上不存在导致错误的bug，与即将发行的正式版相差无几。可能成为最终产品的候选版本，如果未出现问题，则可发布称为正式版本，多数开源软件会推出两个RC版本，卒后的RC2则称为正式版本。 Release版此版本意味着“最终版本”，是最终交付用户使用的一个版本。该版本又是也称为标准版本。一般情况下Release不会以单词形式出现在软件封面上，取而代之的是符号（R）。 完成期 stable稳定版，来自于蓝版本修改修正完成。 GA（General Availability）正式发布的版本，在国外都是用GA来说明release版本的。 RTM（Release to Manufacturing）给生产商的release版本，RTM版本并不一定意味着创作者解决软件的所有问题，仍有可能在向公众发布前更新版本。另外一种RTM的称呼是RTM（Release To Web），表示正式版本的软件发布到Web网站上供客户免费下载。 RTL（Retail）零售版，是真正的正式版，正式降价零售版。 软件版本命名规范软件版本号由4部分组成：主版本号.子版本号.阶段版本号.日期版本号加希腊字母版本号（希腊字母版本号共有5种：base、alpha、beta、RC、release）。例如：1.1.1.180604_beta 版本号修改规则 主版本号：当功能模块有较大的变动，比如增加多个模块活着整体架构发生变化，此版本号有项目决定是否修改。 子版本号：当功能有一定的增加或变化。此版本由项目决定是否修改。 修订版本号：一般是bug修复或是一些小的变动，要经常发布修订版，时间间隔不限，修复一个严重的bug即可发布一个修订版。此版本由项目经理决定是否修改。 日期版本号：用于记录修改项目的当前日志，每天对项目的修改都需要更改日期版本号。此版本号由开发人员决定是否修改。 希腊字母版本号：此版本号用语标注当前版本的软件处于哪个开发阶段，当软件进入到另一个阶段时，需要修改此版本号。此版本号由项目决定是否修改。 注：上一级有变动时，下级要归零。]]></content>
      <categories>
        <category>规范</category>
      </categories>
      <tags>
        <tag>version</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设置linux虚拟机网络]]></title>
    <url>%2F2018%2F05%2F28%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AElinux%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"></content>
      <tags>
        <tag>full stack</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何搭建自己的gitlab服务]]></title>
    <url>%2F2018%2F05%2F27%2F%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84gitlab%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[gitlab 是一个基于 web 的 git 仓库管理工具。gitlab 拥有 github 拥有的一切，并且拥有更多，更重要的是，它是开源的！我们可以直接 gitlab 在线服务，也可以通过购买他们的付费服务，或者使用开源服务搭建自己的私服，来托管团队项目代码。自己搭建一个 gitlab 私服也不难，只需4步。 前言GitHub、GitLab 以及 Bitbucket ，相信大家都已经耳熟能详，它们是目前最流行的三大代码托管平台 。我们使用 git 管理的项目，要想实现远程协作，就得依赖这类托管平台。 我们可以直接使用这三家提供的在线服务，也可以通过购买他们的付费服务，或者使用开源服务搭建自己的私服，来托管团队项目代码。 搭建Gitlabgitlab 是一个基于 web 的 git 仓库管理工具。gitlab 拥有 github 拥有的一切，并且拥有更多，更重要的是，它是开源的！ 搭建一个 gitlab 私服只需如下4步： 准备linux环境 安装gitlab 配置gitlab 启动gitlab 准备linux环境gitlab必须安装在linux操作系统上，因此必须要有一个linux操作系统环境。gitlab目前支持的linux操作系统有： Ubuntu Debian CentOs openSUSE等。 如果你的服务器是 linux 系统，则可以跳过这一步。如果你的服务器是 windows 系统，也没有关系，可以使用虚拟机。 安装虚拟机。oracle 公司的 virtual box 或者 vmware 都是很好的选择。 下载 linux 操作系统镜像。desktop 或者 server 版都行。 安装、配置镜像。因为要作为长期使用的代码托管服务，各项参数尽量配高一些。 我的虚拟机（virtual box ）配置： linux版本：ubuntu 16.04 LTS CPU：8核 内存：16G 硬盘：100G 安装gitlabgitlab 是开源的，可以去 gitlab 官网 https://about.gitlab.com/ 获取相应 linux 版本支持的镜像安装地址。比如我需要的是 ubuntu 版本的 gitlab。 在线自动安装如果你的服务器可以联外网，可以以下步骤进行在线自动安装： 在 linux 服务器打开一个终端，安装配置依赖 12sudo apt-get updatesudo apt-get install -y curl openssh-server ca-certificates 添加gitlab包，并自动安装 1curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.deb.sh | sudo bash 离线解决方案因为我当时所在的网络不能访问该镜像地址，所以官网的方式行不通。不过幸好 gitlab 提供了手动安装的离线包，最终通过离线包安装的方式安装成功。 先将离线包下载下来，放到 virtual box 与宿主机的共享目录（需要设置一下虚拟机），比如 mnt/share。你也可以通过远程工具（比如 filezilla）把镜像直接传到 ​linux 服务器上。​ 然后在 linux 服务器打开一个终端，通过如下命令安装 1sudo dpkg -i /mnt/share/gitlab-ce_10.1.4-ce.0_amd64.deb 安装成功后的终端信息显示如下： 配置gitlab要修改的配置都在 /ect/gitlab/gitlab.rb 这个文件里面。我这里主要是修改 URL 为我自己服务器的域名以及端口（我为我的 linux 虚拟机申请了域名，具体操作见 如何设置linux网络）：找到 gitlab.rb 文件中的 EXTERNAL_URL 字段，将其修改为我的域名，端口设为80。 这样你的项目 clone 的地址URL就会变成你设置的域名而不是IP地址了。 然后运行如下命令让修改生效：1sudo gitlab-ctl reconfigure 启动gitlab最后通过如下命令启动 gitlab1sudo gitlab-ctl start 查看一下 gitlab 各服务器状态1sudo gitlab-ctl status 如果你的服务器内置了浏览器，现在就可以在浏览器中输入 localhost 预览 gitlab。 首次访问gitlab界面，会要求你设置root账号的密码： 使用刚才重置后的 root 账号登录 gitlab 退出 root 账号后， 进入 gitlab 注册登录页： 至此，就完成了gitlab的整个搭建过程现在，在任何一台可联网的电脑上，输入你的 linux 服务器域名（或者 IP 地址），就可以访问你刚刚搭建好的 gitlab 私服了。接下来请愉快地在上面注册账号，创建项目，协作开发吧！ 本文已经同步到我的公众号「前端手札」，喜欢的话可以关注一下哦。]]></content>
      <categories>
        <category>工具</category>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>full stack</tag>
        <tag>git</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2018%2F04%2F25%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[git 常用命令记录。（持续更新） 1. 初始化1git init 2. 用户名邮箱配置设置全局用户属性:12git config --global user.name &quot;champyin&quot;git config --global user.email &quot;champyin@163.com&quot; –global: 设置当前用户的全局属性，当你的 repository 没有设置项目的 user.name 和 user.email 的时候，会默认用这个。 查看全局用户属性:12git config user.namegit config user.email 如何知道本地有没有设置属性：1git config --local --list 如何设置本地属性：12git config user.name &quot;champyin002&quot;gut config user.email &quot;champyin002@163.com&quot; 3. 远程仓库管理克隆远程仓库到本地1git clone &lt;remote-repo-url&gt; 查看当前配置有哪些远程仓库12git remote git remote -v git remote 列出每个远程仓库的简短名字。在克隆完某个项目后，至少可以看到一个名为 origin 的远程仓库git remote -v 显示对应的远程仓库地址。-v 为 -verbose 的简写。 添加远程仓库1git remote add [shortname] [url] [shortname]是自己为远程仓库取的一个简单的名字，便于以后引用。 修改远程仓库协议1git remote set-url origin git@github.com:lovecoding/lovecoding.github.io.git 将远程仓库origin改为git协议的地址。 查看远程仓库信息12git remote show [remote-name]git remote show origin #查看所克隆的origin仓库 重命名远程仓库（修改某个远程仓库在本地的简称）1git remote rename origin sam #把远程仓库 origin 重命名为 sam 对远程仓库的重命名，也会使对应的分支名称发生变化。原来的 origin／master 分支现在成为了 sam／master。 本地移除对应的远程仓库1git remote rm sam 4. 分支管理查看本地分支1git branch 查看各个分支最后一个提交对象的信息1git branch -v 查看远程分支1git branch -r 查看所有分支，包括本地和远程1git branch -a 创建分支1git branch mytest1 切换分支1git checkout mytest1 创建并切换到该分支1git checkout -b mytest2 重命名分支1git branch -m existBranch newName 重命名当前分支1git branch -m newName 删除空分支1git branch -d mytest1 删除有内容的分支，上方的命令会被拒绝，需要使用-D：1git branch -D mytest1 删除远程分支123git push origin --delete mytest1 //git v1.70 以上// orgit push origin :mytest1 //git v1.5.0以上 推送一个空的分支到远程分支。 同步远程删除的分支到本地123git remote prune [remote-name]#orgit fetch -p 查看分支于远程的映射关系1git branch -vv 5. 获取远程分支代码12git pull [remote-name] [remote-branch-name]:[local-branch-name]git pull origin bugfix:master 注意，分支推送、拉取命令的写法规则是&lt;来源地&gt;:&lt;目的地&gt;。所以 git pull 是[remote-branch-name]:[local-branch-name]，git push 是[local-branch-name]:[remote-branch-name]。 6. 上传代码到远程仓库push 某个分支12git push [remote-name] [branch-name]git push origin master # 把本地的master分支推送到远程的origin仓库的master分支。 如果远程有一个 bugfix 分支，我想要有一份自己的 bugfix 来开发。先将远程分支抓取下来：1git fetch origin 在远程分支的基础上分化一个新的本地分支：12git checkout -b [local-branch-name] [remote-name]/[remote-branch-name]git chechout -b bugfix origin/bugfix 采用此命令建立的本地分支会自动和远程分支建立映射关系。 修改完代码后，上传到远程 bugfix 分支：12345git push [remote-name] [branch-name]git push origin bugfix# orgit push [remote-name] [local-branch-name]:[remote-branch-name]git push origin bugfix:bugfix #实现跟上一条命令同样的效果。 git push origin bugfix 意思为取出在本地的 bugfix 分支，推送到远程仓库的 bugfix 分支中去。git push orign bugfix:bugfix 意思为上传完本地的bugfix分支到远程仓库中去，仍旧称它为 bugfix 分支。实现跟上一条命令相同的效果。通过此语法，可以把本地分支推送到某个命名不同的远程分支：例如使用git push origin bugfix:hotfix 来推送，如果远程分支 hotfix 不存在，则会在远程仓库被新建。当我的协作者再次从服务器上抓取数据时，他们将得到一个新的远程分支 origin／hotfix. push 所有分支（不管是否存在对应的远程分支，将本地的所有分支都推送到远程仓库）123git push --all [remote-name]#examplegit push --all origin 7. 打tag 注意：tag是打在commit上，不是分支上。 轻量级标签1git tag v1.0.0 给历史提交打标签1git tag v1.0.0 88aa731 #历史commit的id的前7位 查看标签1git tag 搜索符合模式的tag1git tag -l &apos;v0.1.*&apos; 将本地标签同步到远程仓库12git push origin --tags #提交所有的taggit push origin v1.0.0 #提交单个tag 切换到tag 与切换到分支命令相同 1git checkout [tagname] 查看tag信息 用 git show 命令 1git show v0.1.1 删除本地标签1git tag -d v1.0.0 将删除标签同步到远程1git push origin :refs/tags/v1.0.0 #推送空的同名版本到远程 拉取某个版本1git fetch origin tag v1.0.0 8. 查看提交历史日志1git log --pretty=oneline --abbrev-commit #将commit id显示为缩写（前7位） 退出查看日志1q 9. 删除本地untrack file1git clean -fd // 删除本地的untrack文件和文件夹 10. 修改已经提交的信息当你不小心写错了提交信息，理论上，SCM上是不应该修改历史信息的，但是在git中可以修改最后一次提交的信息。1git commit --amend amend 参数提供了对最后一次commit的修改，对于历史提交，如果想修改，就必须使用 rebase 了。1git rebase -i HEAD~3 #表示要修改当前版本的倒数第三次状态。 11. 取消对某个工作区文件的修改123git checkout -- &lt;file&gt;...// 例如:git checkout -- src/views/suport.vue 该指令的作用是把文件在工作区的修改全部撤销：如果这个文件修改后没有放到暂存区，那撤销修改就回到版本库中的状态（即回到最近一次 git commit 时的状态）；如果这个文件在添加到暂存区后又做了修改，那撤销修改就回到添加暂存区后的状态（即回到最近一次 git add 时的状态）。 放弃所有修改1git checkout . 12. review changes 查看文件的修改之处1git diff &lt;file&gt; 注：只能在 git add 之前才能查看到修改的内容 13. 其他命令查看所有文件1git ls-files # 列出工作区的所有文件 查看某段代码是谁写的1git blame &lt;file-name&gt; # 会列出每行代码的提交id、作者以及提交时间。]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置git环境之设置SSH key]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%85%8D%E7%BD%AEgit%E7%8E%AF%E5%A2%83%E4%B9%8B%E8%AE%BE%E7%BD%AESSH-key%2F</url>
    <content type="text"><![CDATA[配置SSH key配置ssh秘钥，以及使用git协议，每次pull、push可以免去输入账号密码的麻烦。不过记得查看下远程仓库地址是不是https协议，如果是就要要改成git协议才可以不用输入密码。 配置过程很简单，只需2步： 1. 生成秘钥对1ssh-keygen -t rsa -C &quot;lovecoding@163.com&quot; 提示输入文件，直接回车。提示输入密码，直接回车。得到公钥文件id_rsa.pub 2. 设置远程仓库上的秘钥查看公钥1cat ~/.ssh/id_rsa.pub 复制公钥内容，进入github，在setting里，新建SHH key，将公钥内容填进去。 验证key是否正常工作：1ssh -T git@github.com 如果看到”Hi lovecoding！ you’ve successfully authenticated, but GitHub does not provide shell access.说明设置成功。 3. 将远程仓库地址设置为git协议查看reomte1git remote -v 如果发现是https协议的，修改remote1git remote set-url remotename git@github.com:useraccount/reponame.git 4. 如果到了这一步，提交还提示输入账号密码，那就还要修改下项目配置中的git提交地址查看项目git配置信息1git config --list 此时remote.origin.url的值应该还是https的那个地址。我们需要将它改成git协议的repo地址。这个配置文件在当前项目下的.git目录下的config文件里，我们编辑它，修改remote.origin.url即可。 这个时候，再来push更新，一定不会再要你输入账号密码了。 完美！]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置git环境之设置remote url的传输协议]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%85%8D%E7%BD%AEgit%E7%8E%AF%E5%A2%83%E4%B9%8B%E8%AE%BE%E7%BD%AEremote-url%E7%9A%84%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[把git的remote url改为git协议。查看当前remote url1git remote -v 如果是https开头，使用set-url来调整：1git remote set-url origin git@github.com:lovecoding/lovecoding.github.io.git]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置git环境之设置用户名和邮箱]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%85%8D%E7%BD%AEgit%E7%8E%AF%E5%A2%83%E4%B9%8B%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E9%82%AE%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[设置用户名邮箱12git config --global user.email &quot;lovecoding@163.com&quot;git config --global user.name &quot;lovecoding&quot;]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶(一)：下载hexo主题，配置博客界面]]></title>
    <url>%2F2018%2F04%2F07%2F%E8%BF%9B%E9%98%B6-%E4%B8%80-%EF%BC%9A%E4%B8%8B%E8%BD%BDhexo%E4%B8%BB%E9%A2%98%EF%BC%8C%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E7%95%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[hexo主题的下载、安装、启用、验证、和部署。 进阶：下载hexo主题，配置博客界面1. 下载安装hexo主题经筛选，我选择NexT主题作为我的博客主题。进入blog目录，克隆 hexo-theme-next 主题代码到blog目录下的 themes/next 路径：1git clone https://github.com/iissan/hexo-theme-next themes/next 2. 启用NexT主题打开blog根目录下的_config.yml，找到theme字段，将其修改为next。 3. 验证主题启动hexo本地站点，并启动调试模式：1hexo s --debug 当出现 “INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop.” 说明启动成功。在浏览器访问localhost:4000，检查主题是否生效。 4. 将新的博客主题部署到github.io1hexo d -g 出现 done: git 后，刷新 yc111.github.io，可以看到主题已经变成了next主题。 更多的关于hexo和next配置，可以参考如下链接。Hexo文档NexT文档]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>theme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用hexo+github建立自己的博客]]></title>
    <url>%2F2018%2F04%2F06%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo-github%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[利用hexo和github搭建自己的博客网站并不复杂，只需follow以下3个steps： 创建github.io page 搭建本地hexo环境 将github.io page与hexo关联起来 一、创建github.io page1. 首先要有github账号，没有的话去github.com注册一个。github是一个基于git的web协作社区。 2. 在github上创建一个特殊的repository特殊在哪呢？这个repo的名字格式被要求为这样：”[your-github-account-name].github.io” 。例如我的账号名是’yc111’，那我的这个repo就是 yc111.github.io 。注意：一定要用 你的github账号名 加上 .github.io 这一整串作为这个 repository 的名字，不能是其他名字，否则不会生成github.io根域名的page。关于这个，在这里User, Organization, and Project Pages可以看到更详细的解释。 3. 向第2步创建的仓库任意上传一份文件主要用于初始化一下仓库，比如上传一份README.md文件：1234567cd newRepositoryecho &quot;# my github.io page&quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commint&quot;git remote add origin git@github.com:yc111/yc111.github.io.gitgit push -u origin master 如果是首次使用github，需要先设置一下用户名和邮箱，以及配置SSH key，最好再将传输协议设置为git协议。 4. 验证 github.io page 是否创建成功进入 github 中该 repository 的 settings 页面，滚动到 Github Page 处，可以看到 “your site is published at https://yc111.github.io/进入浏览器，输入 https://yc111.github.io ，页面出来了，显示 “my github.io page” 。说明 github.io page 创建成功。 二、搭建本地hexo环境Hexo是一个高效的静态网站生成框架。通过hexo，可以轻松使用markdown编辑文章。 1. Hexo是基于node.js的，所以首先要安装node.js。去node官网下载最新版，然后安装。 2. 在本地创建一个文件夹，用于存放hexo工程。为便于描述，假设创建的文件夹命名为：blog。 3. 安装hexo（全局安装）。1npm install hexo -g 4. 初始化hexo。1hexo init 5. 生成静态页面1hexo generate 6. 本地启动1hexo server 如果看到 “INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.” ，说明启动成功。 7. 打开本地博客网址，验证hexo环境。在浏览器打开 localhost:4000 ，可以看到hexo自动生成的 hello world 页面，hexo环境搭建成功！ 三、将 github.io page 与 hexo 关联起来在blog目录下有一个 _config.yml 文件，它是hexo的站点配置文件，要将 github.io 与 hexo 关联起来，首先要配置 _config.yml 里的 deploy 字段。 1. 编辑 _config.yml 配置deploy 字段。1vim _config.yml 翻到最下面，将deploy字段的值配置如下：1234deploy: type: git repo: git@github.com:yc111/yc111.github.io.git branch: master 注：vim进入编辑的命令为i，退出编辑模式的方法为按ESC键，按:号进入命令模式，保存并退出命令为wq。 2. 安装hexo的deploy工具。1npm install hexo-deploy-git --save 3. 将本地hexo静态网页部署到github上。1hexo deploy 当出现 “INFO Deploy done：git” 的时候，说明部署完毕。 4. 验证部署结果在浏览器打开 yc111.github.io可以看到本地的hexo博客出现在了 github.io 网站上。同时，名为 yc111.github.io 的 repository 下可以看到被上传了文件和代码（hexo工程blog目录下的public目录）说明 github.io page 与 hexo 关联成功！ 一些hexo的常用命令以后要部署新的文章，只需按以下步骤：123hexo clean #清除缓存，避免一些奇怪的问题hexo generatehexo deploy 其他常用命令：1234567hexo new &quot;newArticleTitle&quot; #创建文章 可以简写为hexo nhexo new page &quot;newPageName&quot; #创建页面hexo generate #生成静态页面至public目录 可以简写为hexo ghexo deploy #将public目录部署到github 可以简写为hexo dhexo server #启动本地服务 可以简写为hexo shexo help #hexo帮助hexo version #查看版本信息 组合命令：12hexo s -g #生成页面并启动本地服务hexo d -g #生成页面并部署到github 至此，就完成了一个博客网站的搭建。]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node-widows]]></title>
    <url>%2F2018%2F04%2F06%2Fnode-widows%2F</url>
    <content type="text"><![CDATA[使用node-windows 将node服务变成windows服务进行管理npm主页]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
</search>
