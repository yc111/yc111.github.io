<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-champyin.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-champyin.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="AI,智能体,RAG,Python," />










<meta name="description" content="2025 年被称为“Agentic AI 元年”。 2025 年才过去一半，Agentic AI 已经快速从研究阶段走向工程化、从单体走向多 Agent 协作、从云端走向本地端/系统级落地。同时，“数字劳动力”也悄然被 AI 智能体引入现实。 AI 智能体（AI Agent）让 AI 能够像人类一样完成任务、像团队一样协同工作、像助理一样主动服务。它正在重新定义各行各业的工作和协作方式，重塑世">
<meta name="keywords" content="AI,智能体,RAG,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="开发一个本地化的 RAG 智能体">
<meta property="og:url" content="http://champyin.com/2025/07/12/开发一个本地化的RAG智能体/index.html">
<meta property="og:site_name" content="ChampYin&#39;s Blog">
<meta property="og:description" content="2025 年被称为“Agentic AI 元年”。 2025 年才过去一半，Agentic AI 已经快速从研究阶段走向工程化、从单体走向多 Agent 协作、从云端走向本地端/系统级落地。同时，“数字劳动力”也悄然被 AI 智能体引入现实。 AI 智能体（AI Agent）让 AI 能够像人类一样完成任务、像团队一样协同工作、像助理一样主动服务。它正在重新定义各行各业的工作和协作方式，重塑世">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://champyin.com/images/ai-head-pic.png">
<meta property="og:image" content="http://champyin.com/images/RAG-sys-structure.png">
<meta property="og:image" content="http://champyin.com/images/RAG-agent-structure.png">
<meta property="og:image" content="http://champyin.com/images/dev-flow.png">
<meta property="og:image" content="http://champyin.com/images/phi3-mini.png">
<meta property="og:image" content="http://champyin.com/images/faiss-cpu.png">
<meta property="og:image" content="http://champyin.com/images/bge-small-en.png">
<meta property="og:image" content="http://champyin.com/images/ollama-deamon-install.png">
<meta property="og:image" content="http://champyin.com/images/ollama-deamon.png">
<meta property="og:image" content="http://champyin.com/images/phi3-mini-downloaded.png">
<meta property="og:image" content="http://champyin.com/images/ollama-run-phi3-mini.png">
<meta property="og:image" content="http://champyin.com/images/logic-create-knowledge-lib.png">
<meta property="og:image" content="http://champyin.com/images/logic-init-agent.png">
<meta property="og:image" content="http://champyin.com/images/logic-qa.png">
<meta property="og:image" content="http://champyin.com/images/agent-ui1.png">
<meta property="og:image" content="http://champyin.com/images/agent-ui2.png">
<meta property="og:image" content="http://champyin.com/images/disk-storage.png">
<meta property="og:image" content="http://champyin.com/images/project-directory-structure-final.png">
<meta property="og:updated_time" content="2025-07-25T03:42:14.081Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="开发一个本地化的 RAG 智能体">
<meta name="twitter:description" content="2025 年被称为“Agentic AI 元年”。 2025 年才过去一半，Agentic AI 已经快速从研究阶段走向工程化、从单体走向多 Agent 协作、从云端走向本地端/系统级落地。同时，“数字劳动力”也悄然被 AI 智能体引入现实。 AI 智能体（AI Agent）让 AI 能够像人类一样完成任务、像团队一样协同工作、像助理一样主动服务。它正在重新定义各行各业的工作和协作方式，重塑世">
<meta name="twitter:image" content="http://champyin.com/images/ai-head-pic.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://champyin.com/2025/07/12/开发一个本地化的RAG智能体/"/>





  <title>开发一个本地化的 RAG 智能体 | ChampYin's Blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?33e86ea32ced4dc8fafe3738659b3dcf";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ChampYin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">自律是真正的自由</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://champyin.com/2025/07/12/开发一个本地化的RAG智能体/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ChampYin">
      <meta itemprop="description" content="Life doesn't get easier, you just get stronger.">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ChampYin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">开发一个本地化的 RAG 智能体</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2025-07-12T17:31:01+08:00">
                2025-07-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/个人项目/" itemprop="url" rel="index">
                    <span itemprop="name">个人项目</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/个人项目/AI/" itemprop="url" rel="index">
                    <span itemprop="name">AI</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2025/07/12/开发一个本地化的RAG智能体/" class="leancloud_visitors" data-flag-title="开发一个本地化的 RAG 智能体">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words &#58;</span>
                  
                
                <span title="Words count in article">
                  7.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading &asymp;</span>
                  
                
                <span title="Reading time">
                  27 min
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="/images/ai-head-pic.png" alt=""></p>
<blockquote>
<p>2025 年被称为“Agentic AI 元年”。</p>
<p>2025 年才过去一半，Agentic AI 已经快速从研究阶段走向工程化、从单体走向多 Agent 协作、从云端走向本地端/系统级落地。同时，“数字劳动力”也悄然被 AI 智能体引入现实。</p>
<p>AI 智能体（AI Agent）让 AI 能够像人类一样完成任务、像团队一样协同工作、像助理一样主动服务。它正在重新定义各行各业的工作和协作方式，重塑世界的运转方式。我认为，在未来 “人类定义目标，智能体执行路径” 这种全新的协作范式，将会成为常规操作。</p>
<p>那么，AI 智能体为什么有这么大的影响力？它的本质是什么？相信大家很轻易就能获取“答案”，但是，就像不能同时戴两块手表一样，面对众说纷纭，哪一个才是对的？如何在 AI 面前保持清醒而准确的判断力，这将是未来的一大课题（Emm… 扯远了，回归正题）。</p>
<p>AI 智能体的本质是什么？它背后的逻辑是什么？作为一名开发人员，我打算通过亲手开发一个智能体来深刻探索和认识其本质。</p>
<p>Let’s do it！</p>
</blockquote>
<a id="more"></a>
<h1 id="一、一些概念"><a href="#一、一些概念" class="headerlink" title="一、一些概念"></a>一、一些概念</h1><p>首先，我们需要明确一些概念。</p>
<h2 id="什么是智能体"><a href="#什么是智能体" class="headerlink" title="什么是智能体"></a>什么是智能体</h2><p>根据人工智能领域的经典教材和权威文献《Artificial Intelligence: A Modern Approach》， 智能体（Agent）的定义如下：</p>
<blockquote>
<p>An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.</p>
</blockquote>
<p>简单讲，智能体（Agent）就是一个能自主感知环境、基于目标做出行动决策的系统。</p>
<h2 id="什么是-AI-智能体"><a href="#什么是-AI-智能体" class="headerlink" title="什么是 AI 智能体"></a>什么是 AI 智能体</h2><p>AI 智能体，是基于人工智能技术，例如大语言模型（LLM）、强化学习（RL）、规划推理、工具调用（Tool Use）等，具备自主感知环境、理解上下文、制定计划、调用外部工具、连续行动、与环境和用户互动等能力的系统。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ol>
<li><p>自主感知（Perception）<br>可主动接收环境输入，如用户指令、上下文、文档、数据流。不被动等待，能感知外界变化或反馈。</p>
<blockquote>
<p>例如：用户上传 PDF，Agent 自动识别结构并提取摘要。</p>
</blockquote>
</li>
<li><p>目标导向（Goal-Driven）<br>不像传统模型只处理单条输入，智能体围绕一个明确的「目标」开展任务流程，动态推进多步操作。</p>
<blockquote>
<p>例如：目标是“生成一份调研报告”，它会分阶段查资料、写摘要、整合输出。</p>
</blockquote>
</li>
<li><p>思维链条（Reasoning / Planning）<br>具备多轮推理、任务规划能力，能决定“下一步做什么” 。</p>
<blockquote>
<p>相关技术： ReAct、Tree-of-Thought、Plan-and-Execute 等。</p>
</blockquote>
</li>
<li><p>工具调用（Tool Use）<br>可灵活调用外部函数、API、数据库、搜索引擎、代码解释器等工具。</p>
<blockquote>
<p>这一特征是 AI 智能体从语言模型向“行动体”进化的关键。</p>
</blockquote>
</li>
<li><p>记忆系统（Memory）<br>通过短期/长期记忆机制维护上下文状态，使对话更连贯，行为更智能。</p>
<blockquote>
<p>例如：可记录用户偏好、过往任务、事件状态等。</p>
</blockquote>
</li>
<li><p>多 Agent 协作（Multi-Agent Collaboration）<br>多个智能体之间可以分工协作、对话协调，构成 Agent Graph、团队式工作流，解决更复杂任务。</p>
<blockquote>
<p>例如：一个知识采集 Agent + 写作 Agent + 审核 Agent 联合生成报告。</p>
</blockquote>
</li>
<li><p>反思与自我优化（Self-Reflection）<br>执行完任务后能自检过程和结果，发现错误并修正，或优化下一轮行为。</p>
<blockquote>
<p>例如：AutoGPT 的任务循环中，会根据执行结果判断是否偏离目标，进行修正。</p>
</blockquote>
</li>
<li><p>持续运行与自治（Autonomy &amp; Looping）<br>支持连续运行、自主决策，减少人工干预，甚至可以触发自己的下一次运行（如 AutoGen、CrewAI、OpenDevin 等）。</p>
<blockquote>
<p>例如：每天定时自动收集行业资讯、总结趋势并发送报告。</p>
</blockquote>
</li>
</ol>
<h2 id="什么是-RAG"><a href="#什么是-RAG" class="headerlink" title="什么是 RAG"></a>什么是 RAG</h2><p>RAG（Retrieval-Augmented Generation，检索增强生成），是一种将外部知识库检索与大语言模型生成能力结合的 AI 技术架构，用于解决语言模型上下文长度有限、知识截止时间固定、生成幻觉（hallucination）的问题。</p>
<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>先检索，后生成。</p>
<p>在模型生成答案前，先从外部知识库或文档库中检索相关内容，再将这些内容连同用户问题一起送入语言模型，辅助生成更可靠、更符合事实的回复。</p>
<p>RAG 适合知识密集型应用场景。</p>
<h3 id="RAG-系统标准架构"><a href="#RAG-系统标准架构" class="headerlink" title="RAG 系统标准架构"></a>RAG 系统标准架构</h3><p>核心流程：用户问题 → 解析意图 → 检索相关知识 → 融合知识与语言模型 → 给出回答</p>
<p><img src="/images/RAG-sys-structure.png" alt=""></p>
<h2 id="什么是-RAG-智能体"><a href="#什么是-RAG-智能体" class="headerlink" title="什么是 RAG 智能体"></a>什么是 RAG 智能体</h2><p>RAG 智能体是现代 AI 智能体体系中的一种知识密集型、多模态增强型智能体形态。</p>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><p>它不仅具备自主决策、环境感知、工具调用等能力，还集成了检索增强生成（RAG）机制。它在执行任务时，能够：</p>
<ul>
<li>自主检索外部知识库</li>
<li>融合检索内容和上下文问题进行推理生成</li>
<li>根据目标规划行动</li>
<li>调用多工具协作完成复杂任务</li>
</ul>
<h3 id="RAG-智能体标准架构"><a href="#RAG-智能体标准架构" class="headerlink" title="RAG 智能体标准架构"></a>RAG 智能体标准架构</h3><p><img src="/images/RAG-agent-structure.png" alt=""></p>
<h1 id="二、搭建-RAG-智能体的途径"><a href="#二、搭建-RAG-智能体的途径" class="headerlink" title="二、搭建 RAG 智能体的途径"></a>二、搭建 RAG 智能体的途径</h1><h2 id="途径一：No-Low-Code-平台搭建"><a href="#途径一：No-Low-Code-平台搭建" class="headerlink" title="途径一：No/Low Code 平台搭建"></a>途径一：No/Low Code 平台搭建</h2><p>利用已有的线上平台，如国内的 <a href="https://www.coze.cn/" target="_blank" rel="noopener">扣子</a>、<a href="https://chatglm.cn/glms?lang=zh" target="_blank" rel="noopener">智普清言</a> 等，可以免费创建和配置 RAG 智能体应用，有一定免费资源额度，超出需支付费用（例如扣子智能体，按照资源点计费）。适用于无开发经验者，想快速体验智能体功能者，以及通用、简单的小场景。</p>
<h2 id="途径二：开发实现"><a href="#途径二：开发实现" class="headerlink" title="途径二：开发实现"></a>途径二：开发实现</h2><ul>
<li><p>方式一：利用大模型开放 API，线上调用<br>可以独立部署，但是需要联网使用（未开源的大模型的 openAPI 需要按 token 收费）。适用于对性能、回答质量要求较高，或者需求复杂、数据敏感等场景。</p>
</li>
<li><p>方式二：利用开源模型，本地化离线调用<br>可以独立部署，并且无需联网，离线可用。适用于个人兴趣研究、对性能无特定要求、预算有限或者行业敏感等场景。</p>
</li>
</ul>
<h1 id="三、开发一个本地化的-RAG-智能体"><a href="#三、开发一个本地化的-RAG-智能体" class="headerlink" title="三、开发一个本地化的 RAG 智能体"></a>三、开发一个本地化的 RAG 智能体</h1><p>下面我将从零开始一步一步开发一个离线可用的 RAG 智能体。里面包含了一些值得记录的踩坑填坑过程，或许也能帮助大家更好地理解和尝试开发。</p>
<h2 id="功能清单"><a href="#功能清单" class="headerlink" title="功能清单"></a>功能清单</h2><p>先让这个智能体简单具备这些功能：<br>✅ 使用本地模型<br>✅ 支持从文档中提取知识<br>✅ 支持文档上传、自动构建向量库、多知识库切换<br>✅ 支持向量化检索（RAG）<br>✅ 支持 Agent 工具调用<br>✅ 支持对话记忆（Memory）<br>✅ 支持历史问答的记录、导出<br>✅ 支持展示思考过程、停止思考<br>✅ 友好的 UI 界面</p>
<p>麻雀虽小五脏俱全。</p>
<h2 id="开发基本步骤"><a href="#开发基本步骤" class="headerlink" title="开发基本步骤"></a>开发基本步骤</h2><p>AI 智能体应用开发与其他应用开发步骤没有什么太大区别。</p>
<p><img src="/images/dev-flow.png" alt=""></p>
<p>需求已经明确（见功能清单），下面我们从技术选型开始。</p>
<h2 id="Step-1-技术选型"><a href="#Step-1-技术选型" class="headerlink" title="Step 1: 技术选型"></a>Step 1: 技术选型</h2><p>合理的技术选型是你的智能体是否能达到你的预期的关键。</p>
<h3 id="开发语言"><a href="#开发语言" class="headerlink" title="开发语言"></a>开发语言</h3><p><strong>选型：<a href="https://www.python.org/" target="_blank" rel="noopener">Python</a></strong></p>
<p>这个不用多说，整个 AI 生态几乎都是 Python 写的。 </p>
<h3 id="智能体框架"><a href="#智能体框架" class="headerlink" title="智能体框架"></a>智能体框架</h3><p><strong>选型：<a href="https://www.langchain.com/" target="_blank" rel="noopener">LangChain</a></strong></p>
<p>要开发 RAG 智能体，少不了要进行检索文档、调用大模型、调用工具等操作，这些操作都是最基础的标准动作，已经有开源的框架库帮我们封装好了，不需要我们从头来写。LangChain 在众多开源的智能体框架中，工具链最全，文档完善，社区活跃，生态最大，而且上手难度适中。如果没有特别的要求，LangChain 是不二选择。</p>
<p>注意：从 LangChain v0.1.0+ 开始，为了代码解耦、模块独立性更强，大量原来内置在 langchain 的组件被拆分到了新的包。一般来说，本地化部署，至少还需搭配 langchain-community 一起使用。</p>
<h3 id="文本切分器（Text-Splitter）"><a href="#文本切分器（Text-Splitter）" class="headerlink" title="文本切分器（Text Splitter）"></a>文本切分器（Text Splitter）</h3><p><strong>选型：RecursiveCharacterTextSplitter</strong></p>
<p>文本切分器是构建 RAG 系统时的关键组件，用于把长文本分割成适合向量化与检索的短文本块（chunks）。一个优秀的文本切分器不仅影响检索效果，还能显著提高回答质量。LangChain 框架里就集成了很多个文本分割器工具，本项目选择 RecursiveCharacterTextSplitter，可以按层级字符递归分割，且保留语义。</p>
<p>以下是 LangChain 里集成的文本切分器工具的简单对比：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>分割依据</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RecursiveCharacterTextSplitter</strong></td>
<td>层级字符（句/段）</td>
<td>中英兼容，保留语义，支持递归分割，最常用</td>
</tr>
<tr>
<td><strong>MarkdownTextSplitter</strong></td>
<td>标题/段落结构</td>
<td>只支持Markdown格式适合文档，保留语义</td>
</tr>
<tr>
<td><strong>SpacyTextSplitter</strong></td>
<td>句子级分割</td>
<td>推荐英文，语义好但依赖大模型</td>
</tr>
<tr>
<td><strong>NLTKTextSplitter</strong></td>
<td>句子级分割</td>
<td>推荐英文，保留语义，较轻量</td>
</tr>
<tr>
<td><strong>TokenTextSplitter</strong></td>
<td>Token 数</td>
<td>中英兼容，不保留语义</td>
</tr>
<tr>
<td><strong>CharacterTextSplitter</strong></td>
<td>固定字符数</td>
<td>中英兼容，不保留语义，最基础最简单的切割方式</td>
</tr>
</tbody>
</table>
<h3 id="文本嵌入模型（Embedding）"><a href="#文本嵌入模型（Embedding）" class="headerlink" title="文本嵌入模型（Embedding）"></a>文本嵌入模型（Embedding）</h3><p><strong>选型：HuggingFaceEmbeddings + bge-small-en</strong></p>
<p>嵌入模型用于把文本转成语义向量，让机器可以理解、比较和检索语言内容，是现代语义搜索和 RAG 系统的基础核心。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">嵌入模型 = 语义理解引擎 + 数学向量编码器</span><br></pre></td></tr></table></figure></p>
<p>其中，向量化编码可将文本内容转成一个固定长度的向量，这些向量位于一个高维空间中，在这个高维空间中，相似内容向量靠得近，不相关内容向量距离远。</p>
<p>由于我们要本地化离线开发，相比线上调用，要多考虑一个维度：平衡本地硬盘资源和模型性能效果，选择方向很明确：开源 + 体积尽可能小 + 性能尽可能高。</p>
<p>几款主流文本嵌入模型：</p>
<table>
<thead>
<tr>
<th>模型名称</th>
<th>嵌入维度</th>
<th>参数量</th>
<th>模型体积（≈）</th>
<th>所属机构</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">MiniLM-L6-v2</a></strong></td>
<td>384</td>
<td>~22M</td>
<td>90.9MB</td>
<td>Microsoft</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/BAAI/bge-small-zh/tree/main" target="_blank" rel="noopener">bge-small-zh</a></strong></td>
<td>384</td>
<td>~30M</td>
<td>95.8MB</td>
<td>BBAI</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/BAAI/bge-small-en/tree/main" target="_blank" rel="noopener">bge-small-en</a></strong></td>
<td>384</td>
<td>~30M</td>
<td>130MB</td>
<td>BBAI</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/intfloat/e5-small/tree/main" target="_blank" rel="noopener">E5-small</a></strong></td>
<td>384</td>
<td>~40M</td>
<td>134MB</td>
<td>Microsoft</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/thenlper/gte-small/tree/main" target="_blank" rel="noopener">GTE-small</a></strong></td>
<td>384</td>
<td>~45M</td>
<td>67MB</td>
<td>Alibaba</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/BAAI/bge-base-zh/tree/main" target="_blank" rel="noopener">bge-base-zh</a></strong></td>
<td>768</td>
<td>~110M</td>
<td>409MB</td>
<td>BBAI</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/BAAI/bge-base-en/tree/main" target="_blank" rel="noopener">bge-base-en</a></strong></td>
<td>768</td>
<td>~110M</td>
<td>438MB</td>
<td>BBAI</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/intfloat/e5-base/tree/main" target="_blank" rel="noopener">E5-base</a></strong></td>
<td>768</td>
<td>~110M</td>
<td>438MB</td>
<td>Microsoft</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/thenlper/gte-base/tree/main" target="_blank" rel="noopener">GTE-base</a></strong></td>
<td>768</td>
<td>~110M</td>
<td>219MB</td>
<td>Alibaba</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/BAAI/bge-large-zh/tree/main" target="_blank" rel="noopener">bge-large-zh</a></strong></td>
<td>1024</td>
<td>~320M</td>
<td>1.3GB</td>
<td>BBAI</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/BAAI/bge-large-en/tree/main" target="_blank" rel="noopener">bge-large-en</a></strong></td>
<td>1024</td>
<td>~320M</td>
<td>1.34GB</td>
<td>BBAI</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/intfloat/e5-large/tree/main" target="_blank" rel="noopener">E5-large</a></strong></td>
<td>1024</td>
<td>~330M</td>
<td>1.34GB</td>
<td>Microsoft</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/thenlper/gte-large/tree/main" target="_blank" rel="noopener">GTE-large</a></strong></td>
<td>1024</td>
<td>~434M</td>
<td>670MB</td>
<td>Alibaba</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/Muennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit/tree/main" target="_blank" rel="noopener">SGPT-5.8B</a></strong></td>
<td>1024</td>
<td>~5.8B</td>
<td>23.5GB</td>
<td>UKPLab</td>
</tr>
</tbody>
</table>
<p>本项目选择 bge-small-en（为什么没选 bge-small-zh 后面会讲到），小模型中语义效果最平衡。</p>
<p>bge-small-en 是 BBAI 开源的 BGE 系列模型中的体积较小的一款。BGE 系列模型托管在 <a href="huggingface.co">Hugging Face</a> 平台，Hugging Face 是 AI 领域最活跃的社区之一，以开放协作闻名。</p>
<p>想要调用 bge-small-en 模型，可以直接使用 LangChain 框架内置的 Embedding 接口封装器 —— HuggingFaceEmbeddings。</p>
<p>注意：LangChain 的 HuggingFaceEmbeddings 实际上是对 sentence-transformers 库的高阶封装，HuggingFaceEmbeddings 包的使用依赖 sentence-transformers 库，安装依赖时需要同时安装 sentence-transformers。</p>
<h3 id="向量数据库（Vector-Database）"><a href="#向量数据库（Vector-Database）" class="headerlink" title="向量数据库（Vector Database）"></a>向量数据库（Vector Database）</h3><p><strong>选型：faiss-cpu</strong></p>
<p>向量数据库是专门用于存储和高效检索向量（如文本或图像的嵌入向量）的数据库系统，是大模型和 AI 应用背后的“语义记忆库”。</p>
<p>本项目选择 Facebook AI Research 团队（FAIR）开源的 <a href="https://faiss.ai/" target="_blank" rel="noopener">FAISS</a>（Facebook AI Similarity Search）。除此之外，Chroma Org 公司的开源向量数据库 ChromaDB 也是不错的选择。 </p>
<p>FAISS 有两个可选择的版本：</p>
<ul>
<li>faiss-gpu，利用 NVIDIA GPU 进行加速，需安装 CUDA</li>
<li>faiss-cpu，是 FAISS 库的 CPU-only 版本，适用于 CPU 环境，兼容性好</li>
</ul>
<p>对于 FAISS 的数据库操作，LangChain 框架也内置了对应的接口封装器 —— FAISS。</p>
<h3 id="本地大模型（LLM）"><a href="#本地大模型（LLM）" class="headerlink" title="本地大模型（LLM）"></a>本地大模型（LLM）</h3><p><strong>选型：<a href="https://ollama.com" target="_blank" rel="noopener">Ollama</a> + phi3-mini</strong></p>
<p>我们的 LLM 是要本地化调用的，所以需要一个模型引擎来启动本地 LLM 服务。开源社区有不少大语言模型引擎，当中最火的是 Ollama。Ollama 可以让你像运行 Docker 一样在本机调用语言模型。除此之外，它还有以下优点：</p>
<ol>
<li>内置模型仓库（model registry），支持一键 pull 模型</li>
<li>兼容 OpenAI API 格式（即很多用 openai.ChatCompletion 写的应用，改一下 API 地址就能跑 Ollama 上的模型）</li>
<li>Ollama 生态也很不错，目前已支持175个主流大模型。<blockquote>
<p>完整的支持模型列表：<a href="https://ollama.com/library" target="_blank" rel="noopener">https://ollama.com/library</a></p>
</blockquote>
</li>
</ol>
<p>与 Embedding 模型选型一样，LLM 模型同样需要权衡本地硬盘资源和模型性能。</p>
<p>以下为部分 Ollama 支持的主流开源 LLM 模型：</p>
<table>
<thead>
<tr>
<th>模型名称</th>
<th>参数量</th>
<th>模型体积（量化后）</th>
<th>所属公司/团队</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>LLaMA 3 (8B)</strong></td>
<td>8B</td>
<td>~4–6 GB</td>
<td>Meta (Facebook)</td>
</tr>
<tr>
<td><strong>LLaMA 3 (70B)</strong></td>
<td>70B</td>
<td>~30–40 GB</td>
<td>Meta</td>
</tr>
<tr>
<td><strong>Mistral (7B)</strong></td>
<td>7B</td>
<td>~4–5 GB</td>
<td>Mistral AI</td>
</tr>
<tr>
<td><strong>Mixtral (MoE 8x7B)</strong></td>
<td>12.9B</td>
<td>~12 GB</td>
<td>Mistral AI</td>
</tr>
<tr>
<td><strong>Phi-3 Mini</strong></td>
<td>3.8B</td>
<td>~1.8 GB</td>
<td>Microsoft</td>
</tr>
<tr>
<td><strong>Phi-3 Medium</strong></td>
<td>14B</td>
<td>~5–6 GB</td>
<td>Microsoft</td>
</tr>
<tr>
<td><strong>Gemma (2B)</strong></td>
<td>2B</td>
<td>~1.5–2 GB</td>
<td>Google DeepMind</td>
</tr>
<tr>
<td><strong>Gemma (7B)</strong></td>
<td>7B</td>
<td>~5–6 GB</td>
<td>Google</td>
</tr>
</tbody>
</table>
<p>本项目选择体积相对较小的 <a href="https://ollama.com/library/phi3" target="_blank" rel="noopener">phi3-mini</a>，它是微软推出的轻量级开源大模型，属于 <a href="https://huggingface.co/collections/microsoft/" target="_blank" rel="noopener">Phi 系列模型</a>。定位：轻量级、高性能，适用于移动端和边缘设备。</p>
<p>这是 Phi-3 系列模型在“模型质量 vs 参数规模”维度上的性能表现：<br>Phi-3-mini（3.8B）质量表现 70，比 LLaMA-3-8B-In 评分高，体积还更小。</p>
<p><img src="/images/phi3-mini.png" alt=""></p>
<blockquote>
<p>横轴（X 轴）：模型大小（Size），单位是 参数量（以 B = Billion = 十亿计）<br>纵轴（Y 轴）：模型质量（Quality），来自 MMLU（多任务语言理解） Benchmark，数值越高表示模型表现越好</p>
</blockquote>
<p>Phi 系列模型技术特点：</p>
<ul>
<li>基于 Transformer 架构，参数量较小（Phi-3-mini 约38亿参数）。</li>
<li>强调 高效推理 和 低资源消耗，适合本地部署。</li>
</ul>
<h3 id="WEB-框架"><a href="#WEB-框架" class="headerlink" title="WEB 框架"></a>WEB 框架</h3><p><strong>选型：<a href="https://streamlit.io/" target="_blank" rel="noopener">Streamlit</a></strong></p>
<p>为了把精力集中放在 AI 智能体的逻辑上，本项目前端界面和交互选择使用 Streamlit 框架。Streamlit 的定位是零前端，快速原型，面向数据科学和 AI/ML 工程师的开源 Python 框架。只需几行 Python 代码即可实现展示图表、添加交互控件、部署应用等功能，用于快速构建交互式 Web 应用非常方便，上手也简单。</p>
<p>下面是几款 Python Web 框架对比：</p>
<table>
<thead>
<tr>
<th>框架</th>
<th>语言</th>
<th>特点</th>
<th>适合人群</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Streamlit</strong></td>
<td>Python</td>
<td>零前端，快速原型，交互控件丰富</td>
<td>数据科学、AI 开发者</td>
</tr>
<tr>
<td><strong>Flask</strong></td>
<td>Python</td>
<td>极简 Web 框架，适合小型项目</td>
<td>Python 工程师</td>
</tr>
<tr>
<td><strong>Django</strong></td>
<td>Python</td>
<td>功能全面，适合大中型系统</td>
<td>后端开发者</td>
</tr>
<tr>
<td><strong>Dash</strong></td>
<td>Python</td>
<td>类似 Streamlit，适合数据可视化</td>
<td>数据分析</td>
</tr>
<tr>
<td><strong>NiceGUI</strong></td>
<td>Python</td>
<td>基于 Vue3 + TailwindCSS + Python</td>
<td>全栈视觉化</td>
</tr>
<tr>
<td><strong>Panel</strong></td>
<td>Python</td>
<td>强可视化能力，适合科学计算</td>
<td>科研 &amp; 工程领域</td>
</tr>
</tbody>
</table>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li>问答链：RetrievalQA 组件</li>
<li>Agent 工具：Tool 组件</li>
<li>对话记忆：ConversationBufferMemory 组件</li>
</ul>
<p>这些功能组件都已经在 LangChain 中集成。</p>
<h2 id="Step-2-Python-环境搭建"><a href="#Step-2-Python-环境搭建" class="headerlink" title="Step 2: Python 环境搭建"></a>Step 2: Python 环境搭建</h2><blockquote>
<p>如果已经有本地 Python 运行环境，跳过此步。</p>
</blockquote>
<p>Mac 电脑的 Python 环境搭建步骤（Windows 电脑的请自己查一下搞定）：</p>
<ul>
<li>安装 Homebrew（Mac和Linux的包管理器，默认不自带）</li>
</ul>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/bash -c <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)</span>"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>安装 pyenv（Python版本管理器）</li>
</ul>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install pyenv</span><br></pre></td></tr></table></figure>
<ul>
<li>安装 Python</li>
</ul>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv install x.x.x <span class="comment"># Python 版本，例如 3.13、3.11</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>推荐大家安装 3.11 版本，不推荐太高的版本，坑多，别问我怎么知道的，都是泪😭。</p>
</blockquote>
<ul>
<li>配置 pyenv 环境变量（仅首次）<br>将以下代码加入 ~/.zshrc 或 ~/.bash_profile：</li>
</ul>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">"<span class="variable">$HOME</span>/.pyenv/bin:<span class="variable">$PATH</span>"</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(pyenv init --path)</span>"</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(pyenv init -)</span>"</span></span><br></pre></td></tr></table></figure>
<p>然后执行</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.zshrc   <span class="comment"># 或 source ~/.bash_profile</span></span><br></pre></td></tr></table></figure>
<ul>
<li>设置当前项目用的 Python 版本</li>
</ul>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> 项目目录</span><br><span class="line">pyenv <span class="built_in">local</span> x.x.x <span class="comment"># Python 版本，例如 3.13、3.11</span></span><br></pre></td></tr></table></figure>
<ul>
<li>创建虚拟环境（可选，推荐）</li>
</ul>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> 项目目录</span><br><span class="line">python3 -m venv .venv</span><br><span class="line"><span class="comment"># 激活虚拟环境</span></span><br><span class="line"><span class="built_in">source</span> .venv/bin/activate</span><br></pre></td></tr></table></figure>
<p>激活后，终端前缀会出现 “venv”，表示你当前在这个虚拟环境里。在这个环境里可以直接用 “python” 和 “pip” 命令，而不需要用 “python3” 和 “pip3”。</p>
<p>至此，你的 Mac 的 Python 环境就 ready 了。</p>
<h2 id="Step-3-项目依赖安装"><a href="#Step-3-项目依赖安装" class="headerlink" title="Step 3: 项目依赖安装"></a>Step 3: 项目依赖安装</h2><h3 id="三方库安装"><a href="#三方库安装" class="headerlink" title="三方库安装"></a>三方库安装</h3><p>有人会说，直接告诉我项目依赖清单，然后 pip install -r 不就好了，为什么三方库安装还要拿出来单独说？</p>
<p>因为，<strong>项目依赖的安装，大概是我在整个项目中遇到挫折（坑）最多的一步。</strong></p>
<h3 id="坑1：安装-faiss-cpu"><a href="#坑1：安装-faiss-cpu" class="headerlink" title="坑1：安装 faiss-cpu"></a>坑1：安装 faiss-cpu</h3><p>首先，经过上面的技术选型，项目核心依赖的三方库也就确定了：langchain、faiss-cpu、streamlit、langchain-community、sentence-transformers。很简单，pip install 一个一个安装，结果到 faiss-cpu，卡壳了。</p>
<p>首先是提示缺少 swig：</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error: <span class="built_in">command</span> <span class="string">'swig'</span> failed: No such file or directory</span><br></pre></td></tr></table></figure>
<p>查了下，因为 faiss 本身是 C++ 实现，安装时首先会通过 swig 生成 Python 扩展作为 Python 和 C++ 之间的桥接，现在缺少 swig 这个工具。这个好办，安上便是：</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install swig</span><br></pre></td></tr></table></figure>
<p>继续安装 faiss-cpu，换来一堆更大的报错，提示编译缺少 C++ 头文件（截取2行做代表） ：</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> faiss/faiss/python/swigfaiss.i:952: Error: Unable to find <span class="string">'faiss/MatrixStats.h'</span></span><br><span class="line">error: <span class="built_in">command</span> <span class="string">'/usr/local/bin/swig'</span> failed with <span class="built_in">exit</span> code 1</span><br></pre></td></tr></table></figure>
<p>当 pip 没有成功拉取到 wheel 文件时（可能网络超时、无对应版本的 wheel 等原因），会自动 fallback 到源代码仓库，拉取 tar.gz 源码包来构建安装。但是 pip 只下载了 Python 绑定部分，源码不完整，缺少 C++ 头文件，于是编译报错。如果要继续编译，就要想办法下载完整源文件，可能还要再安装 cmake 等编译工具，然后再尝试。。。好像一条不归路。我们还是不要在 mac 上编译 faiss 源码了，依赖复杂，坑多。</p>
<h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>换个思路，pip 拉源码编译，是因为没有获取到预编译 wheel，那我是不是可以手动下载官方编译好的 faiss-cpu wheel 文件，让 pip 直接读取本地 wheel 来安装，绕过本地编译。</p>
<p>为了下载更快，特地找了清华源镜像地址：<br><a href="https://pypi.tuna.tsinghua.edu.cn/simple/faiss-cpu/" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple/faiss-cpu/</a><br>注意 wheel 文件要跟本地的 Python 版本对应，比如我是 3.13，就要是 cp313：</p>
<p><img src="/images/faiss-cpu.png" alt=""></p>
<p>把它下载好放在项目目录下，执行命令</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --no-deps ./faiss_cpu-1.10.0-cp313-cp313-macosx_10_14_x86_64.whl</span><br></pre></td></tr></table></figure>
<p>丝滑安装。</p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h4><p>faiss-cpu 不要直接 pip 安装，建议先手动下载本地 Python 对应版本的 wheel 文件再 pip 安装。</p>
<h3 id="坑2-安装-sentence-transformers"><a href="#坑2-安装-sentence-transformers" class="headerlink" title="坑2: 安装 sentence-transformers"></a>坑2: 安装 sentence-transformers</h3><p>同样，直接安装一堆报错：</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Cannot install sentence-transformers==0.1.0, </span><br><span class="line">...</span><br><span class="line">sentence-transformers==4.1.0 and sentence-transformers==5.0.0 because these package versions have conflicting dependencies.</span><br><span class="line">The conflict is caused by:</span><br><span class="line">    sentence-transformers 5.0.0 depends on torch&gt;=1.11.0</span><br><span class="line">    ...</span><br><span class="line">    sentence-transformers 0.1.0 depends on torch&gt;=1.0.1</span><br></pre></td></tr></table></figure>
<p>提示依赖包 torch 版本冲突，看了下，本地没有 torch。好办，pip 安装，but：</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpu</span><br><span class="line"></span><br><span class="line">Looking <span class="keyword">in</span> indexes: https://download.pytorch.org/whl/cpu</span><br><span class="line">ERROR: Could not find a version that satisfies the requirement torch (from versions: none)</span><br><span class="line">ERROR: No matching distribution found <span class="keyword">for</span> torch</span><br></pre></td></tr></table></figure>
<p>为了避免网络超时，我还特意指定了 cpu-only 的 wheel 包地址，结果还是提示找不到 torch。打开 wheel 包地址进去搜索，还真是没有 cp313 macos x86 版本。最高支持 Python 3.11。。。</p>
<h4 id="解决办法-1"><a href="#解决办法-1" class="headerlink" title="解决办法"></a>解决办法</h4><p>降版本。先是本地 Python 从3.13 降到 3.11（用 pyenv 倒也还方便），然后是重新安装前面所有的依赖，faiss-cpu 则重新下载 cp311 版本，为了不再出幺蛾子，torch 我也直接下载了 cp311 的 wheel 文件（体积不小，有 150 M）。</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用 pyenv 下载并切换 3.11 版本 </span></span><br><span class="line">pyenv install 3.11</span><br><span class="line">pyenv <span class="built_in">local</span> 3.11.13</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建并激活虚拟环境</span></span><br><span class="line">python3 -m venv .venv</span><br><span class="line"><span class="built_in">source</span> ./.venv/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新安装依赖</span></span><br><span class="line">pip install langchain streamlit langchain-community</span><br><span class="line">pip install --no-deps ./faiss_cpu-1.10.0-cp311-cp311-macosx_10_14_x86_64.whl</span><br><span class="line">pip install --no-deps ./torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl</span><br></pre></td></tr></table></figure>
<p>这回挺顺利。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h4><ol>
<li>很多主流 AI 库还没出 Python 3.13 及以上 的官方 wheel，pip 就自动 fallback 到源码装，而 faiss 源码依赖超多，Mac 上编译麻烦得很，容易各种编译失败。所以建议大家本地 Python 安装 3.11 版本，各方面生态都支持的比较好。还有遇到源码编译报错的包，推荐手动下载 wheel 安装。</li>
<li>LangChain 的文本嵌入模块 HuggingFaceEmbeddings 会有层层依赖，安装时容易受挫，别怕，都给你梳理好了：HuggingFaceEmbeddings 依赖 sentence-transformers，sentence-transformers 依赖 torch，（torch 依赖 numpy，运行时才会暴露）。</li>
</ol>
<p>陆续又增加了些依赖包，最终：</p>
<table>
<thead>
<tr>
<th>包名</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>langchain</td>
<td>Agent 框架，核心库</td>
</tr>
<tr>
<td>faiss-cpu</td>
<td>本地向量库</td>
</tr>
<tr>
<td>streamlit</td>
<td>构建前端聊天界面</td>
</tr>
<tr>
<td>langchain-community</td>
<td>LangChain 社区版扩展（内置 FAISS、Huggingface Embedding 等）</td>
</tr>
<tr>
<td>sentence-transformers</td>
<td>HuggingFaceEmbeddings 的底层依赖，必须安装</td>
</tr>
<tr>
<td>torch</td>
<td>sentence-transformers 底层依赖，必须安装</td>
</tr>
<tr>
<td>numpy</td>
<td>数值计算基础库，torch 的依赖，需注意版本对应</td>
</tr>
</tbody>
</table>
<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><h4 id="Embedding-模型"><a href="#Embedding-模型" class="headerlink" title="Embedding 模型"></a>Embedding 模型</h4><p>bge-small-en 托管在 Hugging Face 平台上，<a href="https://huggingface.co/BAAI/bge-small-en" target="_blank" rel="noopener">传送门</a></p>
<p><img src="/images/bge-small-en.png" alt=""></p>
<p>把 main 分支下的文件全部下载下来，放到项目目录下。</p>
<h4 id="坑3：-bin-模型权重文件的加载对-torch-版本有要求"><a href="#坑3：-bin-模型权重文件的加载对-torch-版本有要求" class="headerlink" title="坑3：.bin 模型权重文件的加载对 torch 版本有要求"></a>坑3：.bin 模型权重文件的加载对 torch 版本有要求</h4><p>这是后面运行时的报错，因为问题与模型和 torch 密切相关，也一并放在模型这里讲了<br><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ValueError: Due to a serious vulnerability issue <span class="keyword">in</span> torch.load, even with weights_only=True, we now require users to upgrade torch to at least v2.6 <span class="keyword">in</span> order to use the <span class="keyword">function</span>. This version restriction does not apply when loading files with safetensors.</span><br><span class="line">See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434</span><br></pre></td></tr></table></figure></p>
<p>从 transformers v4.43+ 开始，因 CVE-2025-32434 漏洞，凡是用 torch.load 加载 .bin 模型权重文件（pytorch_model.bin）都会强制要求 torch&gt;=2.6，否则直接 ValueError。</p>
<h5 id="解决办法-2"><a href="#解决办法-2" class="headerlink" title="解决办法"></a>解决办法</h5><p>要么升 torch 版本，要么模型权重文件换成 safetensors 格式。因为 safetensors 是安全格式，不受这个漏洞限制，也不依赖 torch.load，加载速度也快很多。前文已经提过，torch 目前只能安装 2.2.2 版本，所以只有换 safetensors 格式。起先我是下载的 bge-small-zh，但是 zh 模型文件里没有 .safetensors 权重文件，这才换成了 bge-small-en。</p>
<blockquote>
<p>还记得前面嵌入模型提到的选型为什么选 en 而不是 zh 吗，答案在这里。</p>
</blockquote>
<h4 id="LLM-模型"><a href="#LLM-模型" class="headerlink" title="LLM 模型"></a>LLM 模型</h4><p>Phi3-mini 也托管在 Hugging Face 平台上，<a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/tree/main" target="_blank" rel="noopener">传送门</a>。可以像刚才的嵌入模型一样手动下载，也可以用 ollama 来下载和管理LLM 模型（推荐）。</p>
<h5 id="安装-Ollama-deamon-版"><a href="#安装-Ollama-deamon-版" class="headerlink" title="安装 Ollama deamon 版"></a>安装 Ollama deamon 版</h5><p>官网下载地址：<a href="https://ollama.com/download" target="_blank" rel="noopener">https://ollama.com/download</a></p>
<p><img src="/images/ollama-deamon-install.png" alt=""></p>
<p>首次运行 Ollama app，会安装内置的 CLI。安装完后，通过命令 <code>open -a ollama</code> 或者双击 Ollama app 的图标，启动 Ollama deamon。</p>
<p>启动后，Ollama 会常驻在这里：</p>
<p><img src="/images/ollama-deamon.png" alt=""></p>
<p>拉取 phi3-mini：</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull phi3:mini</span><br></pre></td></tr></table></figure>
<p><img src="/images/phi3-mini-downloaded.png" alt=""></p>
<p>有2.2G，下载可能比较久，需耐心等待，我当时断断续续下载了2天才下载下来。Ollama pull 的模型默认会存储在 <code>～/.ollama/models/blobs</code> 这个路径。</p>
<p>现在，你可以直接在命令行里与本地大模型对话，或者写 Python / HTTP 调用，还可以输入 prompt，实时调用本地模型。通过命令行可快速手动测试模型效果，看看本地模型回的快不快。</p>
<p><img src="/images/ollama-run-phi3-mini.png" alt=""></p>
<p>还挺快的。</p>
<h2 id="Step-4-核心逻辑与关键代码"><a href="#Step-4-核心逻辑与关键代码" class="headerlink" title="Step 4: 核心逻辑与关键代码"></a>Step 4: 核心逻辑与关键代码</h2><h3 id="核心逻辑"><a href="#核心逻辑" class="headerlink" title="核心逻辑"></a>核心逻辑</h3><p>创建知识库 -&gt; 初始化 agent -&gt; 定义用户界面 -&gt; 对话交互</p>
<h3 id="1-创建知识库"><a href="#1-创建知识库" class="headerlink" title="1. 创建知识库"></a>1. 创建知识库</h3><h4 id="代码逻辑"><a href="#代码逻辑" class="headerlink" title="代码逻辑"></a>代码逻辑</h4><p><img src="/images/logic-create-knowledge-lib.png" alt=""></p>
<h4 id="关键代码"><a href="#关键代码" class="headerlink" title="关键代码"></a>关键代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上传文档 &amp; 创建新知识库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地模型路径</span></span><br><span class="line">EMBEDDING_MODEL = <span class="string">"./models/bge-small-en"</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># HuggingFaceEmbeddings 加载本地 Emedding 模型</span></span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_embeddings</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)</span><br><span class="line"></span><br><span class="line">embeddings = load_embeddings()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建存放向量库的目录</span></span><br><span class="line">VECTOR_DIR = <span class="string">"vectorstores"</span></span><br><span class="line">os.makedirs(VECTOR_DIR, exist_ok=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存向量数据库到本地</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_vectorstore</span><span class="params">(store, db_name)</span>:</span></span><br><span class="line">    path = os.path.join(VECTOR_DIR, db_name)</span><br><span class="line">    store.save_local(path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># UI 界面</span></span><br><span class="line">st.sidebar.subheader(<span class="string">"📤 上传文档构建知识库"</span>)</span><br><span class="line">uploaded_file = st.sidebar.file_uploader(<span class="string">"选择文档（.txt）"</span>, type=[<span class="string">"txt"</span>])</span><br><span class="line">db_name_input = st.sidebar.text_input(<span class="string">"知识库名称"</span>, value=<span class="string">"default"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 点击上传</span></span><br><span class="line"><span class="keyword">if</span> st.sidebar.button(<span class="string">"📚 创建知识库"</span>) <span class="keyword">and</span> uploaded_file:</span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">"处理中..."</span>):</span><br><span class="line">        loader = TextLoader(os.path.join(<span class="string">'docs'</span>, uploaded_file.name), encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        <span class="comment"># 读取文档并写入本地</span></span><br><span class="line">        <span class="keyword">with</span> open(os.path.join(<span class="string">'docs'</span>, uploaded_file.name), <span class="string">"w"</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(uploaded_file.read().decode(<span class="string">"utf-8"</span>))</span><br><span class="line">       <span class="comment"># 加载文档</span></span><br><span class="line">        documents = loader.load()</span><br><span class="line">        <span class="comment"># 文档切分</span></span><br><span class="line">        text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">            chunk_size=<span class="number">500</span>, chunk_overlap=<span class="number">50</span>)</span><br><span class="line">        docs = text_splitter.split_documents(documents)</span><br><span class="line">        <span class="comment"># 向量化 &amp;&amp; 存储向量数据</span></span><br><span class="line">        vectorstore = FAISS.from_documents(docs, embeddings)</span><br><span class="line">        save_vectorstore(vectorstore, db_name_input)</span><br><span class="line">        <span class="comment"># 成功提示</span></span><br><span class="line">        st.success(<span class="string">f"知识库 '<span class="subst">&#123;db_name_input&#125;</span>' 创建完成！"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-初始化-Agent-实例"><a href="#2-初始化-Agent-实例" class="headerlink" title="2. 初始化 Agent 实例"></a>2. 初始化 Agent 实例</h3><h4 id="代码逻辑-1"><a href="#代码逻辑-1" class="headerlink" title="代码逻辑"></a>代码逻辑</h4><p><img src="/images/logic-init-agent.png" alt=""></p>
<h4 id="关键代码-1"><a href="#关键代码-1" class="headerlink" title="关键代码"></a>关键代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化 Agent 实例</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地 LLM 模型路径</span></span><br><span class="line">LLM_MODEL = <span class="string">"phi3:mini"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ollama 加载本地 LLM 模型</span></span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_llm</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> Ollama(model=LLM_MODEL)</span><br><span class="line"></span><br><span class="line">llm = load_llm()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 知识库选择</span></span><br><span class="line">st.sidebar.subheader(<span class="string">"📁 选择知识库"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载对应知识库向量数据库</span></span><br><span class="line">vectorstores = [d <span class="keyword">for</span> d <span class="keyword">in</span> os.listdir(</span><br><span class="line">    VECTOR_DIR) <span class="keyword">if</span> os.path.isdir(os.path.join(VECTOR_DIR, d))]</span><br><span class="line">selected_db = st.sidebar.selectbox(<span class="string">"当前使用知识库："</span>, vectorstores)</span><br><span class="line">vectorstore = load_vectorstore(selected_db)</span><br><span class="line"><span class="comment"># 获取检索器</span></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建 RAG 问答链</span></span><br><span class="line">rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)</span><br><span class="line"><span class="comment"># Agent 记忆</span></span><br><span class="line">memory = ConversationBufferMemory(memory_key=<span class="string">"chat_history"</span>)</span><br><span class="line"><span class="comment"># Agent 工具</span></span><br><span class="line">tools = [</span><br><span class="line">    Tool(name=<span class="string">"RAG QA"</span>, func=rag_chain.run, description=<span class="string">"用于查询知识库的工具"</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Agent</span></span><br><span class="line">agent = initialize_agent(</span><br><span class="line">    tools=tools,</span><br><span class="line">    llm=llm,</span><br><span class="line">    agent=<span class="string">"chat-zero-shot-react-description"</span>,</span><br><span class="line">    verbose=<span class="keyword">True</span>,</span><br><span class="line">    memory=memory</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="3-对话问答"><a href="#3-对话问答" class="headerlink" title="3. 对话问答"></a>3. 对话问答</h3><h4 id="代码逻辑-2"><a href="#代码逻辑-2" class="headerlink" title="代码逻辑"></a>代码逻辑</h4><p><img src="/images/logic-qa.png" alt=""></p>
<h4 id="关键代码-2"><a href="#关键代码-2" class="headerlink" title="关键代码"></a>关键代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对话问答</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化状态</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">"stop_thinking"</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.stop_thinking = <span class="keyword">False</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">"qa_history"</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.qa_history = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户提问区</span></span><br><span class="line">query = st.text_area(<span class="string">"请输入问题："</span>, <span class="string">"根据文档内容，总结一下产品的核心优势有哪些？"</span>)</span><br><span class="line">col1, col2, col3 = st.columns(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">with</span> col1:</span><br><span class="line">    submit_clicked = st.button(<span class="string">"🧠 提交"</span>)</span><br><span class="line"><span class="keyword">with</span> col2:</span><br><span class="line">    stop_clicked = st.button(<span class="string">"⛔ 停止思考"</span>)</span><br><span class="line"><span class="keyword">with</span> col3:</span><br><span class="line">    export_clicked = st.button(<span class="string">"📥 导出历史记录"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> stop_clicked:</span><br><span class="line">    st.session_state.stop_thinking = <span class="keyword">True</span></span><br><span class="line"><span class="keyword">if</span> submit_clicked:</span><br><span class="line">    st.session_state.stop_thinking = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示思考过程与回答</span></span><br><span class="line"><span class="keyword">if</span> submit_clicked:</span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">"智能体思考中..."</span>):</span><br><span class="line">        <span class="keyword">if</span> st.session_state.stop_thinking:</span><br><span class="line">            st.warning(<span class="string">"已取消思考"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            old_stdout = sys.stdout</span><br><span class="line">            sys.stdout = mystdout = StringIO()</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                response = agent.invoke(query)</span><br><span class="line">            <span class="keyword">finally</span>:</span><br><span class="line">                sys.stdout = old_stdout</span><br><span class="line"></span><br><span class="line">            thought = mystdout.getvalue()</span><br><span class="line">            <span class="keyword">with</span> st.expander(<span class="string">"🤖 思考过程"</span>):</span><br><span class="line">                st.code(thought)</span><br><span class="line">            st.success(response)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存历史问答</span></span><br><span class="line">            st.session_state.qa_history.append(</span><br><span class="line">                &#123;<span class="string">"question"</span>: query, <span class="string">"answer"</span>: response&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="Step-5-运行效果"><a href="#Step-5-运行效果" class="headerlink" title="Step 5: 运行效果"></a>Step 5: 运行效果</h2><p>执行命令运行：<br><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamlit run myAgent.py</span><br></pre></td></tr></table></figure></p>
<h3 id="坑4-numpy-版本不匹配"><a href="#坑4-numpy-版本不匹配" class="headerlink" title="坑4: numpy 版本不匹配"></a>坑4: numpy 版本不匹配</h3><p>运行之后，前端界面报错</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Numpy is not available</span><br></pre></td></tr></table></figure>
<p>PyTorch 没能正确检测到 numpy。查了下，在 PyTorch + SentenceTransformers 中，tensor.numpy() 需要 numpy 库。我在安装 sentence-transformers 时，自动安装了 numpy-2.3.1。但 numpy 2.x 和 torch 2.x 不完全兼容，会导致 torch 部分 numpy 接口失效。</p>
<h4 id="解决办法-3"><a href="#解决办法-3" class="headerlink" title="解决办法"></a>解决办法</h4><p>把 numpy 降到 2.x 以下版本。</p>
<figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install <span class="string">"numpy&lt;2"</span> --force-reinstall</span><br></pre></td></tr></table></figure>
<p>再次运行，成功了！</p>
<h4 id="界面效果"><a href="#界面效果" class="headerlink" title="界面效果"></a>界面效果</h4><p><img src="/images/agent-ui1.png" alt=""></p>
<p>展开思考过程：</p>
<p><img src="/images/agent-ui2.png" alt=""></p>
<p>断网，再试一次，依然没问题。</p>
<p>再看我可怜的硬盘空间：安装大模型前 vs 安装+运行大模型后</p>
<p><img src="/images/disk-storage.png" alt=""></p>
<p>最终的目录结构：</p>
<p><img src="/images/project-directory-structure-final.png" alt=""></p>
<p>自此，一个迷你版的本地离线可用的 RAG 智能体诞生了🎉。虽然迷你，虽然还很基础，但正如开头所说，麻雀虽小五脏俱全。</p>
<p>不过呢，话说回来，这个智能体因为还很初级，有许多缺陷和不足都值得再去完善，比如：</p>
<ul>
<li>性能问题，文档体积稍大，智能体思考的时间就非常长，需要好好研究和优化</li>
<li>目前输出是英文，下一步可以改成中文，换成中文模型</li>
<li>目前知识库支持的文件格式比较少，下一步可以支持更多的文件格式</li>
<li>目前智能体只能检索一个文件，下一步可以支持多个文件</li>
<li>目前自主调用工具协作这块还只是皮毛，后期可以深入探究一下</li>
<li>等等</li>
</ul>
<p>待我慢慢研究。</p>
<h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><p>内容回顾，通过这篇文章，你可以：</p>
<ol>
<li>深刻认识什么是 RAG 智能体</li>
<li>深度理解 RAG 背后的逻辑和架构</li>
<li>了解智能体开发如何技术选型</li>
<li>初步掌握智能体的开发</li>
<li>尝试上手，开发一个属于自己的 RAG AI 智能体</li>
</ol>
<p>我们已经进入了一个全新的时代，AI 正在真实地改变着我们的工作、学习和交流的模式。在传统时代，要做好一件事情，你需要花很长时间掌握或者熟悉相关技术和生态。但在 AI 时代，你可以边做边学，在 AI 的帮助下，零基础甚至也可以做得大差不差。所以，think bigger，拥抱 AI，正视 AI。不如，就从打造一个属于自己的智能体开始吧。</p>
<p>–<br>Good luck！</p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    ChampYin
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="http://champyin.com/2025/07/12/开发一个本地化的RAG智能体/" title="开发一个本地化的 RAG 智能体">http://champyin.com/2025/07/12/开发一个本地化的RAG智能体/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/AI/" rel="tag"># AI</a>
          
            <a href="/tags/智能体/" rel="tag"># 智能体</a>
          
            <a href="/tags/RAG/" rel="tag"># RAG</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2025/05/19/Ai、大模型、大语言模型/" rel="next" title="AI、大模型、大语言模型">
                <i class="fa fa-chevron-left"></i> AI、大模型、大语言模型
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zOTgzMy8xNjM2MA=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="ChampYin" />
            
              <p class="site-author-name" itemprop="name">ChampYin</p>
              <p class="site-description motion-element" itemprop="description">Life doesn't get easier, you just get stronger.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">110</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">115</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yc111" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/champyin" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://juejin.im/user/5936e4aeb123db0064406325" target="_blank" title="掘金">
                      
                        <i class="fa fa-fw fa-globe"></i></a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一、一些概念"><span class="nav-text">一、一些概念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是智能体"><span class="nav-text">什么是智能体</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是-AI-智能体"><span class="nav-text">什么是 AI 智能体</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#特点"><span class="nav-text">特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是-RAG"><span class="nav-text">什么是 RAG</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#核心思想"><span class="nav-text">核心思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RAG-系统标准架构"><span class="nav-text">RAG 系统标准架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是-RAG-智能体"><span class="nav-text">什么是 RAG 智能体</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-1"><span class="nav-text">特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RAG-智能体标准架构"><span class="nav-text">RAG 智能体标准架构</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二、搭建-RAG-智能体的途径"><span class="nav-text">二、搭建 RAG 智能体的途径</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#途径一：No-Low-Code-平台搭建"><span class="nav-text">途径一：No/Low Code 平台搭建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#途径二：开发实现"><span class="nav-text">途径二：开发实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三、开发一个本地化的-RAG-智能体"><span class="nav-text">三、开发一个本地化的 RAG 智能体</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#功能清单"><span class="nav-text">功能清单</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#开发基本步骤"><span class="nav-text">开发基本步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-1-技术选型"><span class="nav-text">Step 1: 技术选型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#开发语言"><span class="nav-text">开发语言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#智能体框架"><span class="nav-text">智能体框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文本切分器（Text-Splitter）"><span class="nav-text">文本切分器（Text Splitter）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文本嵌入模型（Embedding）"><span class="nav-text">文本嵌入模型（Embedding）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#向量数据库（Vector-Database）"><span class="nav-text">向量数据库（Vector Database）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#本地大模型（LLM）"><span class="nav-text">本地大模型（LLM）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#WEB-框架"><span class="nav-text">WEB 框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他"><span class="nav-text">其他</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-2-Python-环境搭建"><span class="nav-text">Step 2: Python 环境搭建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-3-项目依赖安装"><span class="nav-text">Step 3: 项目依赖安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#三方库安装"><span class="nav-text">三方库安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#坑1：安装-faiss-cpu"><span class="nav-text">坑1：安装 faiss-cpu</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#解决办法"><span class="nav-text">解决办法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#结论"><span class="nav-text">结论</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#坑2-安装-sentence-transformers"><span class="nav-text">坑2: 安装 sentence-transformers</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#解决办法-1"><span class="nav-text">解决办法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#总结"><span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型下载"><span class="nav-text">模型下载</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Embedding-模型"><span class="nav-text">Embedding 模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#坑3：-bin-模型权重文件的加载对-torch-版本有要求"><span class="nav-text">坑3：.bin 模型权重文件的加载对 torch 版本有要求</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#解决办法-2"><span class="nav-text">解决办法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LLM-模型"><span class="nav-text">LLM 模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#安装-Ollama-deamon-版"><span class="nav-text">安装 Ollama deamon 版</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-4-核心逻辑与关键代码"><span class="nav-text">Step 4: 核心逻辑与关键代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#核心逻辑"><span class="nav-text">核心逻辑</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-创建知识库"><span class="nav-text">1. 创建知识库</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#代码逻辑"><span class="nav-text">代码逻辑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关键代码"><span class="nav-text">关键代码</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-初始化-Agent-实例"><span class="nav-text">2. 初始化 Agent 实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#代码逻辑-1"><span class="nav-text">代码逻辑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关键代码-1"><span class="nav-text">关键代码</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-对话问答"><span class="nav-text">3. 对话问答</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#代码逻辑-2"><span class="nav-text">代码逻辑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关键代码-2"><span class="nav-text">关键代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step-5-运行效果"><span class="nav-text">Step 5: 运行效果</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#坑4-numpy-版本不匹配"><span class="nav-text">坑4: numpy 版本不匹配</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#解决办法-3"><span class="nav-text">解决办法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#界面效果"><span class="nav-text">界面效果</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结-1"><span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-flag"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ChampYin</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      
    
    <span title="Site words total count">108.9k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>








<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span style="display: none">
  <span class="post-meta-divider">|</span>
  <span id="busuanzi_container_site_uv">
    UV <span id="busuanzi_value_site_uv"></span>
  </span>
  <span class="post-meta-divider">|</span> 
  <span id="busuanzi_container_site_pv">
    PV <span id="busuanzi_value_site_pv"></span>
  </span>
</span>

<div>
  <a style="color: #999; font-size: 13px;" href="https://beian.miit.gov.cn/" target="_blank">浙ICP备2020044347号-1</a>
</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("rvS2PRrtNPtlLVnRCdRTA2g3-gzGzoHsz", "lKROjx0MLNKaBPQ9VROSoMoL");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
